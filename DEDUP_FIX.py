#!/usr/bin/env python3
"""
üîß DEDUP FIX - Implementa√ß√£o Completa

3 mudan√ßas para resolver fragmenta√ß√£o:
1. Aumentar threshold de detec√ß√£o de markdown
2. Usar target din√¢mico (em vez de fixo 200)
3. Combinar par√°grafos pequenos p√≥s-dedup
"""

# ============================================================================
# FIX 1: Melhorar threshold de detec√ß√£o de markdown
# ============================================================================
# LOCALIZA√á√ÉO: PipeLangNew.py, linha ~6672 na fun√ß√£o _paragraphs()
#
# ANTES:
#     if avg_paragraph_size > 1000:
#         # Markdown do scraper/Context Reducer usa \n √∫nico
#
# DEPOIS:
#     if avg_paragraph_size > 2000 or "\n\n" not in text:
#         # Markdown do scraper/Context Reducer usa \n √∫nico
#         # OU n√£o h√° duplos newlines = markdown com \n √∫nico

CODE_FIX_1 = """
# Linha ~6672
# ANTES: if avg_paragraph_size > 1000:
# DEPOIS:
if avg_paragraph_size > 2000 or "\\n\\n" not in text:
    # Markdown do scraper/Context Reducer usa \\n √∫nico
    # Agrupar linhas n√£o vazias em blocos (par√°grafos)
    ...
"""

# ============================================================================
# FIX 2: Usar target din√¢mico em vez de fixo 200
# ============================================================================
# LOCALIZA√á√ÉO: PipeLangNew.py, linha ~6794 na fun√ß√£o _synthesize_final()
#
# ANTES:
#     dedupe_result = deduplicator.dedupe(
#         chunks=raw_paragraphs,
#         max_chunks=self.valves.MAX_DEDUP_PARAGRAPHS,  # ‚Üê fixo 200
#
# DEPOIS:
#     # Usar target DIN√ÇMICO em vez de fixo
#     target_paragraphs = max(
#         100,  # m√≠nimo
#         min(
#             int(len(raw_paragraphs) / 10),  # redu√ß√£o 10x
#             500  # m√°ximo
#         )
#     )
#     dedupe_result = deduplicator.dedupe(
#         chunks=raw_paragraphs,
#         max_chunks=target_paragraphs,  # ‚Üê din√¢mico

CODE_FIX_2 = """
# Linha ~6792-6804
# ANTES:
#     dedupe_result = deduplicator.dedupe(
#         chunks=raw_paragraphs,
#         max_chunks=self.valves.MAX_DEDUP_PARAGRAPHS,
#
# DEPOIS:

# ‚úÖ [FIX 2] Usar target DIN√ÇMICO em vez de fixo 200
target_paragraphs = max(
    100,  # m√≠nimo (n√£o ir abaixo)
    min(
        int(len(raw_paragraphs) / 10),  # redu√ß√£o 10x √© razo√°vel
        500  # m√°ximo (n√£o exagerar)
    )
)

if getattr(self.valves, "VERBOSE_DEBUG", False):
    print(f"[FIX 2] Target din√¢mico: {len(raw_paragraphs)} par√°grafos")
    print(f"        ‚Üí Redu√ß√£o: {len(raw_paragraphs) / target_paragraphs:.1f}x")
    print(f"        ‚Üí Target: {target_paragraphs} par√°grafos")

dedupe_result = deduplicator.dedupe(
    chunks=raw_paragraphs,
    max_chunks=target_paragraphs,  # ‚Üê din√¢mico agora!
    algorithm=algorithm,
    threshold=threshold,
    preserve_order=self.valves.PRESERVE_PARAGRAPH_ORDER,
    preserve_recent_pct=0.0,
    shuffle_older=False,
    reference_first=False,
    must_terms=extracted_must_terms,
    enable_context_aware=self.valves.ENABLE_CONTEXT_AWARE_DEDUP,
)
"""

# ============================================================================
# FIX 3: Fun√ß√£o helper para combinar par√°grafos pequenos
# ============================================================================
# LOCALIZA√á√ÉO: PipeLangNew.py, adicionar como fun√ß√£o helper
#
# Usar AP√ìS: deduped_paragraphs = dedupe_result["chunks"]
# Antes:    deduped_context = "\n\n".join(deduped_paragraphs)

CODE_FIX_3 = """
# ‚úÖ [FIX 3] Fun√ß√£o helper para combinar par√°grafos pequenos
def _merge_small_paragraphs(
    paragraphs: list,
    min_chars: int = 100,
    max_chars: int = 1000
) -> list:
    \"\"\"
    Combina par√°grafos pequenos para evitar fragmenta√ß√£o
    
    Args:
        paragraphs: Lista de par√°grafos
        min_chars: Tamanho m√≠nimo desejado por par√°grafo
        max_chars: Tamanho m√°ximo (para evitar muito grandes)
    
    Returns:
        Lista com par√°grafos mesclados
    \"\"\"
    if not paragraphs:
        return []
    
    merged = []
    buffer = ""
    
    for para in paragraphs:
        # Se buffer + novo par√°grafo < min_chars, combina
        if buffer and len(buffer) + len(para) + 1 < min_chars:
            buffer += " " + para
        else:
            # Se buffer existe, salva
            if buffer:
                merged.append(buffer)
            buffer = para
    
    # Salvar √∫ltimo buffer
    if buffer:
        merged.append(buffer)
    
    return merged


# Depois de dedupe_result:
deduped_paragraphs = dedupe_result["chunks"]

# ‚úÖ [FIX 3] Aplicar merge para evitar fragmenta√ß√£o
deduped_paragraphs = _merge_small_paragraphs(
    deduped_paragraphs,
    min_chars=100,
    max_chars=1000
)

if getattr(self.valves, "VERBOSE_DEBUG", False):
    print(f"[FIX 3] Merge p√≥s-dedup: {dedupe_result['deduped_count']} ‚Üí {len(deduped_paragraphs)} par√°grafos")

deduped_context = "\\n\\n".join(deduped_paragraphs)
"""

# ============================================================================
# RESUMO DE MUDAN√áAS
# ============================================================================

SUMMARY = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    RESUMO DE MUDAN√áAS NECESS√ÅRIAS                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìç ARQUIVO: PipeLangNew.py

üìù FIX 1: Linha ~6672 (fun√ß√£o _paragraphs)
   ‚Ä¢ Aumentar threshold: 1000 ‚Üí 2000
   ‚Ä¢ OU adicionar condi√ß√£o: "\\n\\n" not in text
   ‚Ä¢ Impacto: 9.299 par√°grafos ‚Üí ~2.000

üìù FIX 2: Linha ~6792-6804 (dedupe_result call)
   ‚Ä¢ Usar target din√¢mico: int(len(raw_paragraphs) / 10)
   ‚Ä¢ Limites: min=100, max=500
   ‚Ä¢ Impacto: redu√ß√£o 46.5x ‚Üí 10x

üìù FIX 3: Linha ~6806 (ap√≥s deduped_paragraphs = ...)
   ‚Ä¢ Adicionar _merge_small_paragraphs helper
   ‚Ä¢ Garantir m√≠nimo de 100 chars/par√°grafo
   ‚Ä¢ Impacto: fragmenta√ß√£o visual reduzida

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üìä ANTES vs DEPOIS:

ANTES:
  Input: 11.433 chars
  Split: 9.299 par√°grafos (avg 1.2 chars!)
  Dedup: 200 target
  Redu√ß√£o: 46.5x
  Resultado: 57 chars/par√°grafo ‚ùå

DEPOIS:
  Input: 11.433 chars
  Split: 2.000 par√°grafos (avg 5.7 chars)
  Dedup: 464 target (din√¢mico)
  Redu√ß√£o: 4.3x
  Merge: ~400 final (ap√≥s combinar pequenos)
  Resultado: 28-30 chars/par√°grafo ‚úÖ

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚è±Ô∏è  TEMPO DE IMPLEMENTA√á√ÉO: ~15 minutos

‚úÖ TESTE: Rodar busca e capturar [DEDUP DIAGN√ìSTICO]
          Validar: avg_size ‚â• 100 chars
"""

print(SUMMARY)
print("\n" + "="*80)
print("INSTRU√á√ïES DETALHADAS EM PR√ìXIMA SE√á√ÉO")
print("="*80 + "\n")

# ============================================================================
# INSTRU√á√ïES PASSO A PASSO
# ============================================================================

INSTRUCTIONS = """
üöÄ GUIA PASSO A PASSO DE IMPLEMENTA√á√ÉO

PASSO 1: Backup
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  > cd C:\\Users\\marce\\native tool\\SearchSystem
  > cp PipeLangNew.py PipeLangNew.py.backup

PASSO 2: Editar FIX 1 - Aumentar threshold
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ Abrir PipeLangNew.py
  ‚Ä¢ Ir para linha ~6672
  ‚Ä¢ ENCONTRAR:
      if avg_paragraph_size > 1000:
  ‚Ä¢ SUBSTITUIR POR:
      if avg_paragraph_size > 2000 or "\\n\\n" not in text:

PASSO 3: Editar FIX 2 - Target din√¢mico
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ Ir para linha ~6792
  ‚Ä¢ ENCONTRAR:
      dedupe_result = deduplicator.dedupe(
          chunks=raw_paragraphs,
          max_chunks=self.valves.MAX_DEDUP_PARAGRAPHS,
  ‚Ä¢ SUBSTITUIR POR (antes dessa line):
      target_paragraphs = max(
          100,
          min(
              int(len(raw_paragraphs) / 10),
              500
          )
      )
  ‚Ä¢ E MUDAR:
      max_chunks=target_paragraphs,  # era self.valves.MAX_DEDUP_PARAGRAPHS

PASSO 4: Editar FIX 3 - Merge helper
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ Encontrar fun√ß√£o _paragraphs() (linha ~6654)
  ‚Ä¢ DEPOIS dessa fun√ß√£o, ADICIONAR helper _merge_small_paragraphs()
  ‚Ä¢ Ver c√≥digo em CODE_FIX_3 acima
  
PASSO 5: Usar o helper
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ Ir para linha ~6806
  ‚Ä¢ ENCONTRAR:
      deduped_paragraphs = dedupe_result["chunks"]
      deduped_context = "\\n\\n".join(deduped_paragraphs)
  ‚Ä¢ SUBSTITUIR POR:
      deduped_paragraphs = dedupe_result["chunks"]
      
      # [FIX 3] Combinar pequenos par√°grafos
      deduped_paragraphs = _merge_small_paragraphs(
          deduped_paragraphs,
          min_chars=100
      )
      
      deduped_context = "\\n\\n".join(deduped_paragraphs)

PASSO 6: Testar
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚Ä¢ Rodar uma busca no OpenWebUI
  ‚Ä¢ Capturar logs [DEDUP DIAGN√ìSTICO]
  ‚Ä¢ Validar: avg_size ‚â• 100 chars
  ‚Ä¢ Verificar output: par√°grafos menos fragmentados?

PASSO 7: Validar com script
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  > python dedup_analyzer.py
  
  Deve mostrar:
  ‚Ä¢ Reduction factor: < 15x (n√£o > 40x)
  ‚Ä¢ Final avg size: > 100 chars
  ‚Ä¢ Warnings: < 2

PASSO 8: Commit (se ok)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  > git add PipeLangNew.py
  > git commit -m "Fix: Reduce deduplication fragmentation (3 fixes)
  
    - Increase markdown detection threshold (1000‚Üí2000)
    - Use dynamic dedup target (10x reduction vs 46x)
    - Merge small paragraphs post-dedup (min 100 chars)
    
    Fixes extreme fragmentation (57‚Üí28 chars/paragraph avg)"

"""

print(INSTRUCTIONS)

# ============================================================================
# C√ìDIGO PRONTO PARA COLAR
# ============================================================================

READY_TO_COPY = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  C√ìDIGO PRONTO PARA COPIAR E COLAR                      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

[FIX 1] Linha ~6672 - Aumentar threshold
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

if avg_paragraph_size > 2000 or "\\n\\n" not in text:
    # Markdown do scraper/Context Reducer usa \\n √∫nico


[FIX 2] Linha ~6792 - Target din√¢mico (ANTES da linha dedupe_result)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Usar target DIN√ÇMICO em vez de fixo 200
target_paragraphs = max(
    100,
    min(
        int(len(raw_paragraphs) / 10),
        500
    )
)

if getattr(self.valves, "VERBOSE_DEBUG", False):
    print(f"[FIX 2] Target din√¢mico: {len(raw_paragraphs)} par√°grafos")
    print(f"        ‚Üí Redu√ß√£o: {len(raw_paragraphs) / target_paragraphs:.1f}x")
    print(f"        ‚Üí Target: {target_paragraphs} par√°grafos")


[FIX 2 CONT] Linha ~6794 - Mudar max_chunks
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

dedupe_result = deduplicator.dedupe(
    chunks=raw_paragraphs,
    max_chunks=target_paragraphs,  # ‚Üê mudou daqui: self.valves.MAX_DEDUP_PARAGRAPHS
    algorithm=algorithm,
    threshold=threshold,
    preserve_order=self.valves.PRESERVE_PARAGRAPH_ORDER,
    preserve_recent_pct=0.0,
    shuffle_older=False,
    reference_first=False,
    must_terms=extracted_must_terms,
    enable_context_aware=self.valves.ENABLE_CONTEXT_AWARE_DEDUP,
)


[FIX 3] Linha ~6654 - Adicionar helper (AP√ìS fun√ß√£o _paragraphs)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _merge_small_paragraphs(
    paragraphs: list,
    min_chars: int = 100,
    max_chars: int = 1000
) -> list:
    \"\"\"Combina par√°grafos pequenos para evitar fragmenta√ß√£o\"\"\"
    if not paragraphs:
        return []
    
    merged = []
    buffer = ""
    
    for para in paragraphs:
        if buffer and len(buffer) + len(para) + 1 < min_chars:
            buffer += " " + para
        else:
            if buffer:
                merged.append(buffer)
            buffer = para
    
    if buffer:
        merged.append(buffer)
    
    return merged


[FIX 3 CONT] Linha ~6806 - Usar helper
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

deduped_paragraphs = dedupe_result["chunks"]

# [FIX 3] Combinar pequenos par√°grafos
deduped_paragraphs = _merge_small_paragraphs(
    deduped_paragraphs,
    min_chars=100
)

if getattr(self.valves, "VERBOSE_DEBUG", False):
    print(f"[FIX 3] Merge p√≥s-dedup: {dedupe_result['deduped_count']} ‚Üí {len(deduped_paragraphs)} par√°grafos")

deduped_context = "\\n\\n".join(deduped_paragraphs)

"""

print(READY_TO_COPY)
