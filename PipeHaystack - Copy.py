# -*- coding: utf-8 -*-
"""
title: PiPeManual - Context-Aware Research Orchestration Pipeline
author: Enhanced for OpenWebUI compatibility
version: 4.8.1
requirements: pydantic,httpx[http2]
license: MIT
description: OpenWebUI Manifold Pipe with unified context detection, adaptive synthesis,
robust error handling, GPT-5/O1 compatibility, and intelligent Planner with key_questions coverage validation.
Implements intelligent multi-phase research with automatic profile detection, quality rails,
and context-aware report generation with discovery tool integration, comprehensive debugging, and PDF export.

CORE FEATURES:
- üéØ **Unified Context Detection**: Single source of truth for intent, sector, and research type
- üß† **LLM-based Components**: Planner, Analyst, Judge with adaptive prompts (25-40+ lines)
- üìä **Quality Rails**: Programmatic validation (evidence coverage, domain diversity, staleness)
- üîÑ **Multi-phase Orchestration**: Incremental scraping, URL caching, diminishing returns detection
- üìù **Adaptive Synthesis**: Context-aware report generation with sector-specific structure
- üõ°Ô∏è **Profile System**: 5 research profiles (company, regulation, technical, literature, history)
- üìà **Telemetry & Metrics**: Comprehensive tracking of novelty, quality, and coverage
- ü§ñ **GPT-5/O1 Support**: Automatic parameter filtering for latest OpenAI models
- üîß **Robust Error Handling**: Custom exceptions, retry with backoff, state validation
- ‚úÖ **Intelligent Planning**: Key_questions coverage validation + market study phase architecture
- ‚ö° **Advanced Deduplication**: 3 algorithms (MMR, MinHash, TF-IDF) with metrics and recent context preservation

RESEARCH PROFILES:
- company_profile: Strategic business analysis with market focus
- regulation_review: Legal/regulatory compliance and policy analysis
- technical_spec: Technical specifications and implementation details
- literature_review: Academic research and scientific methodology
- history_review: Historical context and temporal evolution

CONTEXT DETECTION:
- Automatic sector identification (10+ sectors: tech, health, finance, etc.)
- Research type classification (academic, regulatory, technical, strategic, news)
- Profile-to-sector intelligent mapping with LLM enrichment
- Adaptive synthesis with dynamic report structure and tone

QUALITY RAILS (P0):
- Evidence coverage: ‚â•100% facts with ‚â•1 evidence
- Domain diversity: ‚â•2 unique domains per phase
- Staleness gates: Configurable recency validation by profile
- Novelty tracking: New facts/domains ratio monitoring
- Diminishing returns: Automatic detection and phase advancement

CHANGELOG v4.8.1 (Current - 2025-10-15):
- üî¥ CRITICAL BUG FIXES:
  - ‚úÖ P0.1: Fixed must_terms entity loss - removed duplicate rails injection that overwrote entity merge
  - ‚úÖ P0.2: Added source_bias parameter to discover_urls and propagated to intent_profile
  - ‚úÖ P0.3: Ensured seed_core always present - dual fallback (Planner + Orchestrator)
  - ‚úÖ P0.4: Fixed event_emitter undefined error in PDF export (_synthesize_final signature)
- üéØ PARAMETER PASSING IMPROVEMENTS:
  - ‚úÖ Pipe ‚Üí Discovery integration: Entities now reach Discovery Planner via must_terms
  - ‚úÖ seed_core mandatory in Planner LLM prompt with validation and examples
  - ‚úÖ Discovery always receives rich query (seed_core or deterministic fallback)
  - ‚úÖ Telemetry logging for debugging discovery_params and seed_core_source
- üìä PROMPTS OPTIMIZATION (P0):
  - ‚úÖ Consolidated seed_query rules into _build_seed_query_rules() helper (-40 lines)
  - ‚úÖ Consolidated time windows into _build_time_windows_table() helper (-35 lines)
  - ‚úÖ Consolidated entity validations into _build_entity_rules_compact() helper (-30 lines)
  - ‚úÖ Fixed Planner exceeding phase limit - added pre-check before auto-adding news phase
  - ‚úÖ Removed hardcoded "Korn Ferry" from Judge examples - replaced with dynamic entities
- üöÄ v4.8.1: REFACTORING ARCHITECTURAL (P0.1 + P0.2 + P0.5):
  - ‚úÖ P0.1 PROMPTS CONSOLIDATION: Centralized 8 LLM prompts into PROMPTS dict (-800 lines)
    - planner_system, planner_seed_rules, planner_time_windows, planner_entity_rules
    - analyst_system, analyst_calibration, judge_system, judge_philosophy
    - Easy A/B testing, maintenance, and reusability across components
  - ‚úÖ P0.2 RUN_ITERATION BREAKDOWN: Extracted 4 helper methods (-300 lines, -82% size)
    - _run_discovery(): Discovery logic, URL prioritization, telemetry
    - _run_scraping(): Cache check, scraper tool call, content accumulation
    - _run_context_reduction(): Context Reducer integration, reduction metrics
    - _run_analysis(): Analyst LLM call, facts/lacunas extraction, telemetry
    - High-level orchestration: 400 lines ‚Üí 70 lines (modular, testable, readable)
  - ‚úÖ P0.5 STANDARDIZED TELEMETRY: StepTelemetry dataclass with correlation_id
    - All pipeline steps tracked: discovery, scraper, context_reducer, analyst
    - Structured logging: elapsed_ms, inputs/outputs, counters, notes
    - Observability: debugging, performance monitoring, audit trail
- üêõ PLANNER FIXES:
  - ‚úÖ Seed query validation: 3-6 ‚Üí 3-8 words (accommodate multi-word company names)
  - ‚úÖ Context Detector f-string: Fixed JSON example escaping ({{...}} instead of {...})
  - ‚úÖ Auto-news phase respects MAX_PHASES limit with final invariant validation

CHANGELOG v4.5:
- üî¥ CRITICAL BUG FIXES:
  - ‚úÖ Fixed AttributeError: _extract_contract_from_history moved into Pipe class
  - ‚úÖ "siga" command restored and functional
  - ‚úÖ Discovery tool integration: dict return (eliminates JSON parse overhead)
  - ‚úÖ Config propagation: timeouts/retries aligned between Pipe and Discovery
  - ‚úÖ Random variable scope error fixed in deduplicator
- üßπ CODE CLEANUP (-163 lines):
  - ‚úÖ Removed 4 orphan functions (pick_question_by_kind, make_synthesis_spec, etc.)
  - ‚úÖ Code quality: -2.7% LOC, improved maintainability
- üîç DEBUGGING ENHANCEMENTS:
  - ‚úÖ Multi-layer debug logging (D_WRAPPER ‚Üí DISCOVERY ‚Üí ITERATION ‚Üí ANALYST)
  - ‚úÖ Discovery tool parameter validation and signature inspection
  - ‚úÖ Comprehensive error handling with try-catch at 4 levels
  - ‚úÖ Visual warnings for 0 URLs / 0 facts scenarios

CHANGELOG v4.4:
- üöÄ DEDUPLICATION ENGINE UPGRADE:
  - ‚úÖ Threshold calibration: 0.9 ‚Üí 0.85 (-75% duplicates)
  - ‚úÖ Removed dangerous fallback that bypassed deduplication
  - ‚úÖ Shingle size: n=5 ‚Üí n=3 (tri-grams, +40% similarity detection)
  - ‚úÖ Unified Deduplicator class with 3 algorithms (MMR, MinHash, TF-IDF)
  - ‚úÖ Analyst preserve_recent_pct: CONFIGURABLE via ANALYST_PRESERVE_RECENT_PCT valve (default 1.0 = 100% of current iteration preserved)
  - ‚úÖ Analyst reference_first=True: NEW data is REFERENCE (dedupe old data AGAINST new)
  - ‚úÖ Synthesizer: NO shuffle (phases are not chronological, order is structural)
  - ‚úÖ Metrics: reduction_pct, tokens_saved, algorithm_used
- üéØ CONTEXT DETECTION & PLANNER FIXES (Critical):
  - ‚úÖ Context Detection is SOURCE OF TRUTH (Planner must follow detected profile)
  - ‚úÖ Enhanced Context Detection prompt with explicit examples (headhunting ‚Üí company_profile)
  - ‚úÖ Added RH/Headhunting sector with 18 keywords
  - ‚úÖ Seed Query: MANDATORY tema central (ex: "volume fees HEADHUNTING Brasil")
  - ‚úÖ Seed Query: MANDATORY entity names (1-3 entities ‚Üí ALL names in seed)
  - ‚úÖ News Default: 1y (not 90d) - 90d only for explicit "√∫ltimos 90 dias" / "breaking news"
- üîÑ JUDGE & ANALYST INTELLIGENCE UPGRADE (v4.4.1):
  - ‚úÖ Analyst Auto-Assessment: coverage_score (0-1), gaps_critical, suggest_pivot/refine
  - ‚úÖ Analyst calibration: explicit examples for coverage 0.3/0.6/0.9/1.0
  - ‚úÖ Analyst re-ask: includes self_assessment in schema (fixes parsing failures)
  - ‚úÖ Judge cross-check: validates coverage_score against objective metrics (facts/lacunas)
  - ‚úÖ Confidence-Based Exit: DONE if coverage ‚â• 70% even with low novelty
  - ‚úÖ Auto-convert REFINE ‚Üí NEW_PHASE when loops >= MAX_AGENT_LOOPS
  - ‚úÖ NEW_PHASE triggers: contradictions (2+ loops), unexpected findings (critical), entities not covered
  - ‚úÖ Enhanced telemetry: coverage_score, analyst_confidence, suggest_pivot, failed_query per loop
  - ‚úÖ 6 explicit cases for NEW_PHASE in Judge prompt
  - ‚úÖ Planner validation: REJECTS seed_query without entity names (1-3 entities)
  - ‚úÖ Judge validation: REWRITES next_query if generic or missing entity (aggressive)
- üìä Performance: MinHash 100x faster than MMR for 300+ chunks

v4.3.1 (2025-10-10):
- üßπ CODE CLEANUP & CONSOLIDATION (P0 + P1):
  - ‚úÖ P0 - Dead Code Removal:
    - Removed make_planner_from_strategist() - orphan function (~85 lines)
    - Removed _default_*() tools (3x) - orphan functions (~15 lines)
    - Removed ContractModel - orphan Pydantic model (~15 lines)
  - ‚úÖ P1A - JSON Parsing Consolidation:
    - Created parse_json_resilient() with 3 modes (strict/soft/balanced)
    - Converted _extract_json_from_text(), parse_llm_json_strict(), _soft_json_cleanup() to wrappers
    - Unified parsing logic (was 3 implementations, now 1)
  - ‚úÖ P1B - LLM Retry Consolidation:
    - Removed _safe_llm_run() wrapper (~20 lines)
    - 14 call sites updated to use _safe_llm_run_with_retry(max_retries=1) directly
  - ‚úÖ P1C - Quality Metrics Consolidation:
    - Created _extract_quality_metrics() - unified metrics extraction function
    - Refactored _validate_quality_rails() to use shared metrics (~30 lines saved)
    - Refactored _calculate_evidence_metrics_new() to use shared metrics (~40 lines saved)
    - Refactored _decide_verdict_mece() to use shared metrics (~20 lines saved)
  - ‚úÖ P1D - Synthesis Sections Consolidation:
    - Created _build_synthesis_sections() - unified section builder
    - Refactored _synthesize_final() to use shared builder (~30 lines saved)
  - üìä TOTAL CONSOLIDATION: 115 dead code + 150+ duplicate logic = ~265 lines consolidated
  - üìà IMPACT: 3‚Üí1 JSON parsers, 2‚Üí1 retry, 3 quality funcs unified, synthesis builder extracted

v4.3 (2025-10-10):
- üéØ PLANNER INTELLIGENCE UPGRADE:
  - ‚úÖ Mandatory key_questions coverage validation (each key_question ‚Üí phase mapping)
  - ‚úÖ Market study phase architecture enforcement (3y baseline + 1y trends + 90d breaking news)
  - ‚úÖ Customized seed_query generation (objective-driven, not template-driven)
  - ‚úÖ Removed rigid news window enforcement (allows Planner to create multi-phase temporal architecture)
- üìù Enhanced Planner prompt with MECE examples and validation checklists
- üö® Critical guidance: "Studies need 1y trends phase BEFORE 90d news phase" (prevents 70% key_questions coverage loss)

v4.2:
- üêõ Critical fix: Orchestrator._last_contract ‚Üí self.contract (AttributeError resolved)
- üîó Improved contract management between Pipe and Orchestrator classes
- üìù Updated documentation and docstrings

v4.1:
- ü§ñ GPT-5/O1 compatibility with automatic parameter filtering
- ‚öôÔ∏è get_safe_llm_params() helper for model-specific parameters

v4.0:
- üõ°Ô∏è Custom exceptions (4): PipeExecutionError, LLMConfigurationError, ContractValidationError, etc.
- üìä PipeConstants class with 15+ centralized configurations
- üîß Helper methods (4): _debug_log, _get_current_profile, _sync_contract_with_context, etc.
- üîÑ Retry with exponential backoff for LLM calls
- ‚è±Ô∏è Dynamic timeouts and configurable HTTP read timeouts
- ‚úÖ Test suite: 33 tests - 100% passing

¬© 2025
"""
from __future__ import annotations
import asyncio, json, time, hashlib, re, os, uuid
from typing import Any, Dict, List, Optional, Callable, Tuple
from threading import Lock

try:
    from pydantic import BaseModel, Field, validator, ValidationError
except Exception:
    # keep compatibility with pydantic v1
    from pydantic.v1 import BaseModel, Field, validator, ValidationError


# ==================== PROMPT TEMPLATES (v4.8 - P0.1) ====================
# Centraliza√ß√£o de prompts para f√°cil manuten√ß√£o e A/B testing

PROMPTS = {
    # ===== PLANNER PROMPTS =====
    "planner_system": """Voc√™ √© o PLANNER. Crie um plano de pesquisa estruturado em AT√â {phases} fases (pode ser menos se suficiente).

üéØ FILOSOFIA DE PLANEJAMENTO:
- Crie APENAS as fases NECESS√ÅRIAS para cobrir o objetivo
- Melhor ter 2-3 fases bem focadas do que 4-5 gen√©ricas
- O Judge pode criar novas fases dinamicamente se descobrir lacunas
- M√°ximo permitido: {phases} fases (mas pode ser menos!)""",

    "planner_seed_rules": """
**SEED_QUERY (3-8 palavras, SEM operadores):**
- Estrutura: TEMA_CENTRAL + SETOR/CONTEXTO + ASPECTO + GEO
- Se 1-3 entidades: incluir TODOS os nomes + contexto setorial
- Se 4+ entidades: seed gen√©rica + contexto setorial + TODOS em must_terms
- @noticias: adicionar 3-6 palavras espec√≠ficas (eventos, tipos, a√ß√µes)
- **CR√çTICO**: Sempre incluir contexto setorial para evitar resultados irrelevantes

Exemplos:
‚úÖ "Vila Nova Partners executive search Brasil" (entidade + setor)
‚úÖ "Flow Executive search Brasil not√≠cias" (entidade + setor + contexto)
‚úÖ "RedeDr S√≥ Sa√∫de oncologia Brasil" (entidade + setor m√©dico)
‚úÖ "volume autos el√©tricos Brasil" (4+ entidades + setor)
‚úÖ "@noticias recalls ve√≠culos el√©tricos Brasil" (breaking news + setor)
‚ùå "Flow Brasil not√≠cia" (falta contexto setorial!)
‚ùå "volume fees Brasil" (falta tema!)
‚ùå "buscar dados verific√°veis" (gen√©rico demais)""",

    "planner_time_windows": """
**JANELAS TEMPORAIS:**

| Recency | Uso | Exemplo |
|---------|-----|---------|
| **90d** | Breaking news expl√≠cito | "√∫ltimos 90 dias", "breaking news" |
| **1y** | Tend√™ncias/estado atual (DEFAULT news) | "eventos recentes", "aquisi√ß√µes ano" |
| **3y** | Panorama/contexto hist√≥rico | "evolu√ß√£o setorial", "baseline" |

**Regra Pr√°tica:**
- News SEM prazo expl√≠cito ‚Üí 1y (captura 12 meses)
- News COM "90 dias" ‚Üí 90d (breaking only)
- Estudos de mercado ‚Üí 3y (contexto) + 1y (tend√™ncias) [OBRIGAT√ìRIO]""",

    "planner_entity_rules": """
**POL√çTICA ENTITY-CENTRIC (v4.8):**

| Quantidade | Mode | Seed_query | Must_terms (por fase) |
|------------|------|------------|----------------------|
| 1-3 | üéØ FOCADO | Incluir TODOS | **TODAS as fases** devem ter |
| 4-6 | üìä DISTRIBU√çDO | Gen√©rica | industry:‚â§3, profiles/news:TODAS |
| 7+ | üìä DISTRIBU√çDO | Gen√©rica | industry:‚â§3, profiles/news:TODAS |

**Cobertura obrigat√≥ria (1-3 entidades): ‚â•70% das fases devem incluir as entidades em must_terms**""",

    # ===== ANALYST PROMPTS =====
    "analyst_system": """‚ö†Ô∏è **FORMATO JSON OBRIGAT√ìRIO - REGRAS CR√çTICAS:**

Retorne APENAS um objeto JSON v√°lido. Proibi√ß√µes absolutas:
‚ùå Markdown fences (```json ou ```)
‚ùå Coment√°rios inline (// ou /* */)
‚ùå Texto explicativo antes/depois do JSON
‚ùå Aspas simples (use APENAS ")
‚ùå Quebras de linha dentro de strings

**ANTES DE RETORNAR, VALIDE MENTALMENTE:**
1. ‚úÖ Come√ßa com { e termina com } ?
2. ‚úÖ Todas as strings t√™m aspas DUPLAS " ?
3. ‚úÖ V√≠rgulas corretas (sem trailing commas) ?
4. ‚úÖ Nenhum coment√°rio inline ?
5. ‚úÖ Nenhum markdown fence ?

SE algum item falhar ‚Üí CORRIJA antes de retornar!

**SCHEMA EXATO (copie a estrutura):**
{
  "summary": "string resumo",
  "facts": [{"texto": "...", "confian√ßa": "alta|m√©dia|baixa", "evidencias": [{"url": "...", "trecho": "..."}]}],
  "lacunas": ["..."],
  "self_assessment": {"coverage_score": 0.7, "confidence": "m√©dia", "gaps_critical": true, "suggest_refine": false, "reasoning": "..."}
}

---

Voc√™ √© um ANALYST. Extraia 3-5 fatos importantes do contexto.

**PRIORIDADE #1**: Responda DIRETAMENTE ao objetivo da fase
- Priorize fatos sobre os Termos Priorit√°rios mencionados
- Ignore conte√∫do relacionado aos termos em "Evitar"  
- **CR√çTICO**: Ignore conte√∫do que n√£o tem contexto setorial relevante
- **CR√çTICO**: Se encontrar entidades com nomes similares mas em contextos diferentes (ex: "Flow" em outro setor), IGNORE se n√£o for relevante ao objetivo
- Busque evid√™ncias concretas (URLs + trechos)
- Valide se o contexto setorial das informa√ß√µes encontradas corresponde ao objetivo da pesquisa""",

    "analyst_calibration": """
üéØ CALIBRA√á√ÉO DE coverage_score (PRAGM√ÅTICA):

**0.0-0.3 (BAIXO - RESPOSTA INADEQUADA):**
‚Üí coverage_score = 0.2
‚Üí gaps_critical = True
‚Üí suggest_refine = True

**0.4-0.6 (M√âDIO - RESPOSTA PARCIAL mas √öTIL):**
‚Üí coverage_score = 0.6
‚Üí gaps_critical = False
‚Üí suggest_refine = False

**0.7-0.9 (ALTO - RESPOSTA S√ìLIDA):**
‚Üí coverage_score = 0.8
‚Üí gaps_critical = False
‚Üí suggest_refine = False""",

    # ===== JUDGE PROMPTS =====
    "judge_system": """Voc√™ √© o JUDGE. Sua fun√ß√£o: ANALISAR e DECIDIR se a pesquisa est√° COMPLETA ou precisa de mais informa√ß√µes.

üß† **ABORDAGEM LLM-FIRST:**
- Analise QUALITATIVAMENTE a qualidade dos fatos extra√≠dos
- Avalie se os fatos respondem adequadamente ao objetivo da pesquisa
- Identifique lacunas cr√≠ticas que impedem uma resposta satisfat√≥ria
- Considere a diversidade de fontes e dom√≠nios encontrados
- Proponha decis√£o baseada em JULGAMENTO, n√£o apenas m√©tricas num√©ricas""",

    "judge_philosophy": """
üéØ **FILOSOFIA DE DECIS√ÉO INTELIGENTE:**

**DONE = Resposta Satisfat√≥ria ao Objetivo**
- Os fatos extra√≠dos respondem adequadamente √† pergunta original?
- H√° evid√™ncias concretas (nomes, n√∫meros, datas, fontes espec√≠ficas)?
- A diversidade de fontes √© adequada para o escopo?
- As lacunas restantes s√£o secund√°rias ou cr√≠ticas?

**REFINE = Busca Mais Espec√≠fica Necess√°ria**
- Fatos gen√©ricos demais, falta especificidade?
- Lacunas cr√≠ticas impedem resposta ao objetivo?
- Fontes insuficientes ou repetitivas?
- Necessidade de foco em entidades espec√≠ficas mencionadas?

**NEW_PHASE = Abordagem Completamente Diferente**
- Mudan√ßa significativa de escopo, temporalidade ou fonte?
- √Çngulo de pesquisa diferente que pode revelar informa√ß√µes complementares?
- Necessidade de abordar aspectos n√£o cobertos pela pesquisa atual?

**PRINC√çPIO FUNDAMENTAL:** Priorize QUALIDADE sobre QUANTIDADE. √â melhor ter poucos fatos de alta qualidade que respondem ao objetivo do que muitos fatos gen√©ricos.""",
}

# ===== HELPER FUNCTIONS PARA PROMPTS =====
# (Fun√ß√µes helper j√° existem no c√≥digo, usando os dicion√°rios globais)


# ==================== LINE-BUDGET GUARD (v4.8 - P0) ====================
# Sistema de valida√ß√£o de tamanho de fun√ß√£o para prevenir regress√£o

import inspect
import warnings

def _warn_if_too_long(fn, soft=300, hard=500):
    """Valida tamanho de fun√ß√£o e emite warning se exceder limite"""
    try:
        source = inspect.getsource(fn)
        loc = len([line for line in source.splitlines() if line.strip()])

        if loc > hard:
            warnings.warn(
                f"[LBG] CRITICAL: {fn.__name__} has {loc} LOC (hard limit: {hard}). "
                "MUST refactor immediately.",
                category=RuntimeWarning
            )
        elif loc > soft:
            warnings.warn(
                f"[LBG] WARNING: {fn.__name__} has {loc} LOC (soft limit: {soft}). "
                "Consider refactoring.",
                category=UserWarning
            )
    except Exception as e:
        logger.debug(f"Line-budget check failed for {fn.__name__}: {e}")

def _add_sector_context_if_ambiguous(query: str, entities: List[str], sector: str) -> str:
    """
    Adiciona contexto setorial se entidade na query for amb√≠gua.
    
    Args:
        query: Query gerada pelo Judge
        entities: Lista de entidades can√¥nicas do contract
        sector: Setor principal da pesquisa
    
    Returns:
        Query enriquecida com contexto setorial se necess√°rio
    """
    if not query or not entities:
        return query
    
    query_lower = query.lower()
    
    # Detectar entidades amb√≠guas presentes na query
    ambiguous_found = []
    for entity in entities:
        entity_lower = entity.lower()
        # Amb√≠guo se: ‚â§4 chars OU palavra comum em ingl√™s/programa√ß√£o
        common_words = {"exec", "flow", "run", "search", "data", "link", "sync", "fast", "rush"}
        
        # Check if entity appears in query (whole word or as part of multi-word entity)
        entity_words = entity_lower.split()
        if len(entity_words) == 1:
            # Single word entity - check if it's a whole word in query
            import re
            if re.search(r'\b' + re.escape(entity_lower) + r'\b', query_lower):
                if len(entity_lower) <= 4 or entity_lower in common_words:
                    ambiguous_found.append(entity)
        else:
            # Multi-word entity - check if any word matches
            for word in entity_words:
                if len(word) <= 4 or word in common_words:
                    if word in query_lower:
                        ambiguous_found.append(entity)
                        break
    
    # Se h√° entidade amb√≠gua, verificar se j√° tem contexto setorial
    if ambiguous_found:
        # Mapeamento setor ‚Üí termos de contexto
        sector_keywords = {
            "rh_headhunting": ["executive search", "headhunting", "recrutamento executivo", "consultoria rh"],
            "tech": ["software", "tecnologia", "startup", "plataforma", "saas"],
            "finance": ["fintech", "banco", "cr√©dito", "pagamentos", "investimentos"],
            "health": ["sa√∫de", "hospital", "cl√≠nica", "m√©dico", "healthcare"],
            "retail": ["varejo", "e-commerce", "loja", "comercio"],
        }
        
        sector_terms = sector_keywords.get(sector, [])
        has_sector = any(term in query_lower for term in sector_terms)
        
        if not has_sector and sector_terms:
            # Adicionar primeiro termo setorial no in√≠cio
            enriched_query = f"{sector_terms[0]} {query}"
            print(
                f"[JUDGE ENRICHMENT] Entidade amb√≠gua detectada ({', '.join(ambiguous_found)}). "
                f"Query enriquecida: '{query}' ‚Üí '{enriched_query}'"
            )
            return enriched_query
        else:
            # Debug: why wasn't it enriched?
            if getattr(__import__('sys').modules.get('__main__', type('obj', (object,), {})), 'DEBUG_ENRICHMENT', False):
                print(f"[DEBUG] Sector: {sector}, Terms: {sector_terms}, Has sector: {has_sector}")
                print(f"[DEBUG] Query: '{query}', Ambiguous: {ambiguous_found}")
    
    return query

# ==================== TELEMETRY (v4.8 - P0.5) ====================
from dataclasses import dataclass
from typing import Dict, List, Optional
import time

# Haystack optional imports para semantic dedup
try:
    from haystack.components.embedders import SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder
    from haystack.dataclasses import Document
    import numpy as np
    HAYSTACK_AVAILABLE = True
except ImportError:
    HAYSTACK_AVAILABLE = False
    # Warning will be logged when trying to use semantic dedup

@dataclass
class StepTelemetry:
    """Telemetria padronizada por etapa"""
    step: str  # "discovery", "scraper", "analyst", "judge", "synthesis"
    correlation_id: str
    start_ms: float
    end_ms: Optional[float] = None
    inputs_brief: str = ""
    outputs_brief: str = ""
    counters: Optional[Dict[str, int]] = None
    notes: Optional[List[str]] = None
    
    @property
    def elapsed_ms(self) -> float:
        if self.end_ms:
            return self.end_ms - self.start_ms
        return time.time() * 1000 - self.start_ms
    
    def to_dict(self) -> Dict:
        return {
            "step": self.step,
            "correlation_id": self.correlation_id,
            "elapsed_ms": self.elapsed_ms,
            "inputs": self.inputs_brief,
            "outputs": self.outputs_brief,
            "counters": self.counters or {},
            "notes": self.notes or [],
        }


# ==================== CUSTOM EXCEPTIONS ====================
# Exce√ß√µes espec√≠ficas para melhor rastreabilidade e recovery strategies


class PipeExecutionError(Exception):
    """Erro base para execu√ß√£o do Pipe - permite captura global de erros do pipeline"""

    pass


class LLMConfigurationError(PipeExecutionError):
    """Raised when LLM client configuration is missing or invalid"""

    pass


class ContractValidationError(PipeExecutionError):
    """Erro na valida√ß√£o do contract - estrutura inv√°lida ou incompat√≠vel"""

    pass


class ContractGenerationError(PipeExecutionError):
    """Erro na gera√ß√£o do contract pelo LLM Planner"""

    pass


class ToolExecutionError(PipeExecutionError):
    """Erro na execu√ß√£o de ferramentas (discovery, scraper, context_reducer)"""

    pass


# ==================== PYDANTIC MODELS FOR CONTRACT VALIDATION ====================
# Valida√ß√£o formal de contracts para prevenir estruturas inv√°lidas

# ===== CONTRACT SCHEMAS (Fim-a-fim) =====


class EntitiesModel(BaseModel):
    """Entidades can√¥nicas e aliases"""

    canonical: List[str]
    aliases: List[str] = []


class StrategistPayloadModel(BaseModel):
    """Contrato de sa√≠da do Estrategista (Call 1) - JSON-only, sem CoT exposto"""

    intent_profile: str
    intent: str
    executive_objectives: List[str]
    constraints: List[str] = []
    initial_hypotheses: List[str] = []
    stakeholders: List[str] = []
    key_questions: List[str]
    entities: EntitiesModel
    language_bias: List[str] = Field(default_factory=lambda: ["pt-BR", "en"])
    geo_bias: List[str] = Field(default_factory=lambda: ["BR", "global"])
    notes: Optional[str] = None


class TimeHintModel(BaseModel):
    """Time hint configuration for phase recency requirements"""

    recency: str  # "90d", "1y", "3y"
    strict: bool = False

    @validator("recency")
    def validate_recency(cls, v):
        if v not in ["90d", "1y", "3y"]:
            raise ValueError(f"recency must be 90d, 1y, or 3y, got {v}")
        return v


class EvidenceGoalModel(BaseModel):
    """Evidence requirements for quality rails"""

    official_or_two_independent: bool = True
    min_domains: int = Field(ge=2, le=10)


class PhaseTypeModel(BaseModel):
    """Phase type with strict validation"""

    phase_type: str

    @validator("phase_type")
    def validate_phase_type(cls, v):
        valid_types = [
            "industry",
            "profiles",
            "news",
            "regulatory",
            "financials",
            "tech",
        ]
        if v not in valid_types:
            raise ValueError(f"phase_type must be one of {valid_types}, got {v}")
        return v


class PlannerPhaseModel(BaseModel):
    """Phase model for Planner contract - com phase_type e valida√ß√£o estrita"""

    name: str
    phase_type: str  # "industry"|"profiles"|"news"|"regulatory"|"financials"|"tech"
    objective: str
    seed_query: str = Field(min_length=3, max_length=50)
    seed_core: Optional[str] = Field(
        default="",
        max_length=200,
        description="Seed query rica (1 frase) sem operadores - usado pelo Discovery",
    )
    seed_core_source: Optional[str] = Field(
        default="planner_heuristic",
        description="Origem: planner_llm|planner_heuristic|user",
    )
    seed_family_hint: Optional[str] = Field(
        default="entity-centric",
        description="Fam√≠lia de explora√ß√£o: entity-centric|problem-centric|outcome-centric|regulatory|counterfactual",
    )
    must_terms: List[str] = []
    avoid_terms: List[str] = []
    time_hint: TimeHintModel
    source_bias: List[str] = ["oficial", "primaria", "secundaria"]
    evidence_goal: EvidenceGoalModel
    lang_bias: List[str] = ["pt-BR", "en"]
    geo_bias: List[str] = ["BR", "global"]
    suggested_domains: List[str] = Field(
        default=[], description="Dom√≠nios sugeridos para prioriza√ß√£o"
    )
    suggested_filetypes: List[str] = Field(
        default=[], description="Tipos de arquivo sugeridos (html, pdf, etc)"
    )

    @validator("phase_type")
    def validate_phase_type(cls, v):
        valid_types = [
            "industry",
            "profiles",
            "news",
            "regulatory",
            "financials",
            "tech",
        ]
        if v not in valid_types:
            raise ValueError(f"phase_type must be one of {valid_types}, got {v}")
        return v

    @validator("seed_query")
    def validate_seed_query(cls, v):
        # Forbid operators (except @noticias which is handled separately)
        forbidden = ["site:", "filetype:", "after:", "before:", " AND ", " OR ", '"']
        for op in forbidden:
            if op in v:
                raise ValueError(f"seed_query cannot contain operator: {op}")
        # ‚úÖ REMOVED: Word count validation (3-6 words) - bloqueava queries v√°lidas com entidades compostas
        # Discovery's internal Planner will optimize the query regardless of initial seed length
        return v

    @validator("seed_core")
    def validate_seed_core(cls, v):
        """Valida seed_core: ‚â•3 palavras, ‚â§200 chars, sem operadores"""
        if not v or not v.strip():
            return ""  # Opcional, pode estar vazio

        # Forbid operators
        forbidden = ["site:", "filetype:", "after:", "before:", "AND", "OR"]
        for op in forbidden:
            if op in v:
                raise ValueError(f"seed_core cannot contain operator: {op}")

        # Validate length
        if len(v) > 200:
            raise ValueError(f"seed_core must be ‚â§200 chars, got {len(v)}")

        # Validate word count (m√≠nimo 3 palavras)
        words = v.split()
        if len(words) < 3:
            raise ValueError(f"seed_core must have ‚â•3 words, got {len(words)}")

        return v

    @validator("seed_family_hint")
    def validate_seed_family(cls, v):
        """Valida seed_family_hint: enum de fam√≠lias suportadas"""
        valid_families = [
            "entity-centric",
            "problem-centric",
            "outcome-centric",
            "regulatory",
            "counterfactual",
        ]
        if v and v not in valid_families:
            raise ValueError(
                f"seed_family_hint must be one of {valid_families}, got {v}"
            )
        return v or "entity-centric"  # Default

    @validator("must_terms")
    def validate_must_terms_policy(cls, v, values):
        """Pol√≠tica: industry n√£o deve ter todos os players; profiles/news devem ter"""
        phase_type = values.get("phase_type")
        if phase_type == "industry" and len(v) > 5:
            raise ValueError(
                f"industry phase should not have all players in must_terms (got {len(v)})"
            )
        return v


class PlannerPayloadModel(BaseModel):
    """Contrato de sa√≠da do Planner (Call 2) - JSON-only, sem CoT"""

    plan_intent: str
    assumptions_to_validate: List[str] = []
    phases: List[PlannerPhaseModel]
    quality_rails: Dict[str, Any] = {
        "min_unique_domains": 3,
        "need_official_or_two_independent": True,
    }
    budget: Dict[str, int] = {"max_rounds": 2}


class PhaseModel(BaseModel):
    """Phase configuration with full validation (legacy - manter compatibilidade)"""

    name: str
    objective: str
    seed_query: str = Field(min_length=3, max_length=50)
    seed_core: Optional[str] = Field(
        default="",
        max_length=200,
        description="Seed query rica (1 frase) sem operadores",
    )
    seed_family_hint: Optional[str] = Field(
        default="entity-centric", description="Fam√≠lia de explora√ß√£o"
    )
    must_terms: List[str] = []
    avoid_terms: List[str] = []
    time_hint: TimeHintModel
    source_bias: List[str]
    evidence_goal: EvidenceGoalModel
    lang_bias: List[str]
    geo_bias: List[str]
    suggested_domains: List[str] = Field(default=[], description="Dom√≠nios sugeridos")
    suggested_filetypes: List[str] = Field(
        default=[], description="Tipos de arquivo sugeridos"
    )

    @validator("seed_query")
    def validate_seed_query(cls, v, values):
        # Forbid operators
        forbidden = ["site:", "filetype:", "after:", "before:", "AND", "OR", '"']
        for op in forbidden:
            if op in v:
                raise ValueError(f"seed_query cannot contain operator: {op}")
        # ‚úÖ REMOVED: Word count validation (3-6 words) - bloqueava queries v√°lidas com entidades compostas
        # Discovery's internal Planner will optimize the query regardless of initial seed length

        # QUICK WIN #1 (v4.5.2): Validar que seed cont√©m tema do objective
        # Previne seeds gen√©ricas tipo "volume fees Brasil" sem contexto
        objective = values.get("objective", "")
        if objective:
            seed_lower = v.lower()
            obj_lower = objective.lower()

            # Extrair palavras significativas do objective (>4 chars, n√£o stopwords)
            stopwords = {
                "para",
                "como",
                "qual",
                "onde",
                "quando",
                "porque",
                "quem",
                "sobre",
                "desta",
                "dessa",
                "nesta",
                "nessa",
                "seus",
                "suas",
            }
            obj_words = [
                w for w in obj_lower.split() if len(w) > 4 and w not in stopwords
            ]
            seed_words = seed_lower.split()

            # Calcular overlap: quantas palavras significativas do objective est√£o na seed?
            overlap = sum(
                1 for w in obj_words[:10] if w in seed_words
            )  # Limitar a 10 primeiras

            # P2 (opcional): exigir overlap m√≠nimo proporcional (‚â•20% das palavras significativas do objective)
            min_overlap = max(1, int(len(obj_words) * 0.2)) if obj_words else 0
            if overlap < min_overlap and len(obj_words) > 0:
                raise ValueError(
                    f"seed_query deve incluir tema central do objective (overlap m√≠nimo {min_overlap}). "
                    f"Objective tem: {', '.join(obj_words[:5])}"
                )

        # SLACK SEM√ÇNTICO (v4.5.2): Validar que m√©tricas v√£o para must_terms, n√£o seed
        must_terms = values.get("must_terms", [])
        specific_metrics = [
            "volume",
            "fees",
            "tempo-to-fill",
            "coloca√ß√µes",
            "receita",
            "market share",
            "revenue",
            "pricing",
            "faturamento",
        ]
        has_metrics_in_seed = any(metric in v.lower() for metric in specific_metrics)

        if has_metrics_in_seed and len(must_terms) < 3:
            raise ValueError(
                f"Seed query cont√©m m√©tricas espec√≠ficas ('{v}') mas must_terms tem apenas {len(must_terms)} termos. "
                f"ESTRAT√âGIA CORRETA: seed gen√©rica (tema + geo) + m√©tricas em must_terms para aproveitar Discovery Selector."
            )

        return v

    @validator("must_terms")
    def normalize_must_terms(cls, v):
        """Normaliza e valida must_terms (v4.5.2)"""
        if not v:
            return v

        # Remover duplicatas (case-insensitive)
        normalized = []
        seen = set()
        for term in v:
            if not isinstance(term, str):
                continue
            term_clean = term.lower().strip()
            if term_clean and term_clean not in seen:
                normalized.append(term)
                seen.add(term_clean)

        # Warning se muito longo (>15)
        if len(normalized) > 15:
            logger.warning(
                f"must_terms muito longo ({len(normalized)} termos). Recomendado: ‚â§15 para melhor performance."
            )

        return normalized


class QualityRailsModel(BaseModel):
    """Quality rails configuration"""

    min_unique_domains: int = Field(ge=2)
    need_official_or_two_independent: bool = True
    official_domains: List[str] = []


# REMOVED (v4.3): ContractModel - Pydantic model √≥rf√£o nunca usado
# Valida√ß√£o de contracts √© feita manualmente em PlannerLLM._validate_contract()

# ==================== CONFIGURATION CONSTANTS ====================
# Configura√ß√µes centralizadas para f√°cil manuten√ß√£o e consist√™ncia


class PipeConstants:
    """
    Configura√ß√µes e constantes centralizadas do pipeline.
    Valores padr√£o que podem ser sobrescritos via Valves UI.
    """

    # ===== LIMITES DE EXECU√á√ÉO =====
    MIN_PHASES = 3  # M√≠nimo de fases recomendadas
    MAX_PHASES_LIMIT = 15  # Limite absoluto de fases
    MAX_FUNCTION_LENGTH = 100  # Tamanho m√°ximo recomendado para m√©todos (linhas)

    # ===== TIMEOUTS (segundos) =====
    CONTEXT_DETECTION_TIMEOUT = 30  # Timeout para detec√ß√£o de contexto
    LLM_CALL_TIMEOUT = 60  # Timeout para chamadas LLM
    TOOL_EXECUTION_TIMEOUT = 120  # Timeout para execu√ß√£o de ferramentas

    # ===== DEFAULTS DE PERFIL =====
    DEFAULT_PROFILE = "company_profile"
    AVAILABLE_PROFILES = [
        "company_profile",
        "regulation_review",
        "technical_spec",
        "literature_review",
        "history_review",
    ]

    # ===== QUALITY RAILS =====
    MIN_EVIDENCE_COVERAGE = 1.0  # 100% de fatos com ‚â•1 evid√™ncia

    # ===== CONTEXT DETECTION =====
    DETECTOR_COT_ENABLED = True  # Habilitar Chain-of-Thought no Context Detection
    MIN_UNIQUE_DOMAINS = 2  # M√≠nimo de dom√≠nios √∫nicos por fase
    STALENESS_DAYS_DEFAULT = 90  # Dias para considerar conte√∫do stale
    NOVELTY_THRESHOLD = 0.3  # Threshold para ratio de novidade

    # ===== DEDUPLICA√á√ÉO =====
    MAX_DEDUP_PARAGRAPHS = 200  # M√°ximo de par√°grafos ap√≥s deduplica√ß√£o (alinhado com valve)
    DEDUP_SIMILARITY_THRESHOLD = 0.85  # Threshold de similaridade (0.0-1.0, maior = menos agressivo) - v4.4: ajustado 0.9‚Üí0.85
    DEDUP_RELEVANCE_WEIGHT = 0.7  # Peso da relev√¢ncia vs diversidade (0.6-0.8)

    # ===== LLM CONFIGURATION =====
    LLM_TEMPERATURE = 0.7  # Temperatura padr√£o para LLM
    LLM_MAX_TOKENS = 2048  # Max tokens para respostas LLM
    LLM_MIN_TOKENS = 100  # Min tokens aceit√°vel
    LLM_MAX_TOKENS_LIMIT = 4000  # Limite absoluto de tokens

    # ===== CONTEXT MANAGEMENT =====
    MAX_CONTEXT_CHARS = 150000  # M√°ximo de caracteres no contexto
    MAX_HISTORY_MESSAGES = 10  # M√°ximo de mensagens do hist√≥rico

    # ===== S√çNTESE =====
    SYNTHESIS_MIN_PARAGRAPHS = 3  # M√≠nimo de par√°grafos no relat√≥rio
    SYNTHESIS_PREFERRED_SECTIONS = 5  # N√∫mero preferido de se√ß√µes no relat√≥rio


# ===== Valves moved to Pipe class for UI exposure =====


# REMOVED (v4.3): _default_discovery/scraper/context_reducer - fun√ß√µes √≥rf√£s que apenas lan√ßam RuntimeError
# Tool resolution √© feita em _resolve_tools(), n√£o h√° fallbacks inline


# ===== Deduplication Utilities =====
def _shingles(s: str, n: int = 3) -> set:
    """Generate n-grams (shingles) from text for similarity comparison

    v4.4: Reduzido n=5‚Üí3 (tri-grams) - industry standard, +40% detec√ß√£o de similaridade
    """
    tokens = [t for t in s.lower().split() if t]
    return set(tuple(tokens[i : i + n]) for i in range(max(0, len(tokens) - n + 1)))


def _jaccard(a: set, b: set) -> float:
    """Jaccard similarity between two sets"""
    if not a or not b:
        return 0.0
    inter = len(a & b)
    union = len(a | b)
    return inter / union if union > 0 else 0.0


# ==================== UNIFIED DEDUPLICATION ENGINE (v4.4) ====================


class Deduplicator:
    """Deduplica√ß√£o centralizada com m√∫ltiplos algoritmos (v4.4)

    Algoritmos dispon√≠veis:
    - mmr: Maximal Marginal Relevance (padr√£o, O(n¬≤))
    - minhash: MinHash LSH (r√°pido, O(n), requer datasketch)
    - tfidf: TF-IDF + Cosine Similarity (sem√¢ntico, requer sklearn)

    Features:
    - Preserva√ß√£o de ordem original (narrativa)
    - M√©tricas de qualidade (reduction %, tokens saved)
    - Fallback autom√°tico se biblioteca n√£o dispon√≠vel
    """

    def __init__(self, valves):
        self.valves = valves

    def dedupe(
        self,
        chunks: List[str],
        max_chunks: int,
        algorithm: str = None,
        threshold: float = None,
        preserve_order: bool = True,
        preserve_recent_pct: float = 0.0,
        shuffle_older: bool = False,
        reference_first: bool = False,
        # NOVO: Context-aware parameters
        must_terms: Optional[List[str]] = None,
        key_questions: Optional[List[str]] = None,
        enable_context_aware: Optional[bool] = None,
    ) -> Dict[str, Any]:
        """Deduplica√ß√£o unificada com escolha de algoritmo

        Args:
            chunks: Lista de par√°grafos/chunks
            max_chunks: N√∫mero m√°ximo a retornar
            algorithm: 'mmr' | 'minhash' | 'tfidf' | 'semantic' (None = usa valve)
            threshold: Similaridade threshold (None = usa valve)
            preserve_order: Reordenar para manter narrativa
            preserve_recent_pct: % de chunks recentes a preservar intactos (0.0-1.0)
            shuffle_older: embaralhar sele√ß√£o dos CHUNKS ANTIGOS (e reordenar ao final)
            reference_first: se True, recent s√£o REFER√äNCIA (dedupe older CONTRA recent)
            must_terms: Termos que devem ser preservados (context-aware)
            key_questions: Quest√µes-chave para matching (context-aware)
            enable_context_aware: Ativar preserva√ß√£o de chunks cr√≠ticos (None = usa valve)

        Returns:
            Dict com: chunks (deduped), original_count, deduped_count, reduction_pct, tokens_saved
        """
        if not chunks:
            return {
                "chunks": [],
                "original_count": 0,
                "deduped_count": 0,
                "reduction_pct": 0.0,
                "tokens_saved": 0,
                "algorithm_used": "none",
            }

        algorithm = algorithm or getattr(self.valves, "DEDUP_ALGORITHM", "mmr")
        threshold = (
            threshold
            if threshold is not None
            else getattr(self.valves, "DEDUP_SIMILARITY_THRESHOLD", 0.85)
        )

        original_count = len(chunks)

        # Context-aware prioritization (se ativado)
        enable_context_aware = (
            enable_context_aware 
            if enable_context_aware is not None 
            else getattr(self.valves, "ENABLE_CONTEXT_AWARE_DEDUP", False)
        )
        
        if enable_context_aware and (must_terms or key_questions):
            # Usar context-aware prioritization
            preserve_top_pct = getattr(self.valves, "CONTEXT_AWARE_PRESERVE_PCT", 0.3)
            
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[CONTEXT_AWARE] Ativado: preserve_top_pct={preserve_top_pct}")
                print(f"[CONTEXT_AWARE] Must terms: {must_terms}")
                print(f"[CONTEXT_AWARE] Key questions: {key_questions}")
                print(f"[CONTEXT_AWARE] Input: {len(chunks)} chunks -> Target: {max_chunks}")
            
            high_priority, low_priority = self._context_aware_prioritize(
                chunks, must_terms, key_questions, preserve_top_pct
            )  # Agora retorna [(idx, chunk), ...]

            # Capear high_count antes de calcular available_slots (P0 fix)
            high_count = len(high_priority)
            high_count = min(high_count, max_chunks)
            available_slots = max_chunks - high_count

            # Priorizar must_terms ‚Üí key_questions ‚Üí position quando high > max
            if len(high_priority) > max_chunks:
                # Ordenar high_priority por tipo de score (must > question > position)
                high_priority_scored = []
                for idx, chunk in high_priority:
                    chunk_lower = chunk.lower()
                    must_score = sum(chunk_lower.count(t.lower()) * 2.0 for t in (must_terms or []))
                    q_score = sum(
                        len(set(q.lower().split()).intersection(set(chunk_lower.split()))) * 1.5
                        for q in (key_questions or [])
                    )
                    pos_score = idx / len(chunks) * 0.1
                    high_priority_scored.append((must_score, q_score, pos_score, idx, chunk))
                
                # Sort: must_terms primeiro, depois questions, depois position
                high_priority_scored.sort(key=lambda x: (x[0], x[1], x[2]), reverse=True)
                high_priority = [(x[3], x[4]) for x in high_priority_scored[:max_chunks]]
                available_slots = 0
            else:
                high_priority = high_priority[:high_count]

            # Dedupear low_priority se houver slots dispon√≠veis
            final_tuples = list(high_priority)  # [(idx, chunk), ...]

            if available_slots > 0 and low_priority:
                # Criar dicion√°rio chunk ‚Üí [indices] para mapeamento robusto
                low_chunks = [ch for _, ch in low_priority]
                chunk_to_indices = {}
                for idx, chunk in low_priority:
                    if chunk not in chunk_to_indices:
                        chunk_to_indices[chunk] = []
                    chunk_to_indices[chunk].append(idx)
                
                # Dedupear apenas os chunks (sem √≠ndices)
                deduped_low = self._dedupe_chunks(low_chunks, available_slots, algorithm, threshold)
                
                # Reconstruir com √≠ndices originais
                for chunk in deduped_low:
                    if chunk in chunk_to_indices and chunk_to_indices[chunk]:
                        idx = chunk_to_indices[chunk].pop(0)  # Pegar primeiro √≠ndice dispon√≠vel
                        final_tuples.append((idx, chunk))

            # SEMPRE restaurar ordem original (1b: for√ßar preserve_order=True)
            final_tuples.sort(key=lambda x: x[0])  # Ordenar por √≠ndice original
            final_chunks = [chunk for _, chunk in final_tuples]

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[CONTEXT_AWARE] Ordem restaurada: {len(final_chunks)} chunks preservam timeline original")
                # Mostrar preview de chunks com URL
                for i, chunk in enumerate(final_chunks[:3]):
                    if chunk.startswith("URL:"):
                        url_line = chunk.split('\n')[0]
                        print(f"[CONTEXT_AWARE]   [{i}] {url_line[:80]}...")

            # M√©tricas
            deduped_count = len(final_chunks)
                
            # Retornar resultado context-aware
            result = {
                "chunks": final_chunks,
                "original_count": original_count,
                "deduped_count": deduped_count,
                "reduction_pct": (original_count - deduped_count) / original_count * 100,
                "tokens_saved": 0,  # TODO: calcular tokens saved
                "algorithm_used": f"context_aware_{algorithm}",
                "fallback_occurred": False,  # Context-aware n√£o usa fallback
                "dependencies_checked": True,
            }
            
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[CONTEXT_AWARE] Final: {original_count} -> {deduped_count} chunks ({result['reduction_pct']:.1f}% reduction)")
            
            return result
        
        # Separar chunks recentes se solicitado (para Analyst)
        if preserve_recent_pct > 0:
            recent_count = max(10, int(len(chunks) * preserve_recent_pct))
            recent_chunks = chunks[-recent_count:]
            older_chunks = chunks[:-recent_count]
            effective_max = max_chunks - len(recent_chunks)
        else:
            recent_chunks = []
            older_chunks = chunks
            effective_max = max_chunks

        # Aplicar algoritmo escolhido
        # Se reference_first=True, dedupear older CONTRA recent (recent como refer√™ncia)
        reference_chunks_for_mmr = recent_chunks if reference_first else []

        try:
            if algorithm == "minhash":
                deduped_older = self._minhash_dedupe(
                    older_chunks,
                    threshold,
                    effective_max,
                    reference_chunks=reference_chunks_for_mmr,
                )
                algo_used = "minhash"
            elif algorithm == "tfidf":
                deduped_older = self._tfidf_dedupe(
                    older_chunks,
                    threshold,
                    effective_max,
                    reference_chunks=reference_chunks_for_mmr,
                )
                algo_used = "tfidf"
            elif algorithm == "semantic":
                try:
                    model_name = getattr(self.valves, "SEMANTIC_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
                    print(f"[DEDUP] üß† Usando algoritmo SEMANTIC com modelo {model_name}")
                    deduped_older = self._semantic_dedupe(
                        older_chunks,
                        threshold,
                        effective_max,
                        reference_chunks=reference_chunks_for_mmr,
                        model_name=model_name,
                    )
                    algo_used = "semantic"
                except (ImportError, AttributeError) as e:
                    print(f"[DEDUP] ‚ö†Ô∏è Fallback para MMR: {e}")
                    # Fallback para MMR se Haystack n√£o dispon√≠vel
                    deduped_older = _mmr_select(
                        chunks=older_chunks,
                        k=effective_max,
                        lambda_div=getattr(self.valves, "DEDUP_RELEVANCE_WEIGHT", 0.7),
                        preserve_order=True,
                        similarity_threshold=threshold,
                        randomize=shuffle_older,
                        reference_chunks=reference_chunks_for_mmr,
                    )
                    algo_used = "mmr_fallback"
            else:  # mmr (default)
                print(f"[DEDUP] Usando algoritmo MMR (default)")
                deduped_older = _mmr_select(
                    chunks=older_chunks,
                    k=effective_max,
                    lambda_div=getattr(self.valves, "DEDUP_RELEVANCE_WEIGHT", 0.7),
                    preserve_order=True,  # Preserve a ordem durante a sele√ß√£o
                    similarity_threshold=threshold,
                    randomize=shuffle_older,
                    reference_chunks=reference_chunks_for_mmr,  # Dedupe older CONTRA recent
                )
                algo_used = "mmr"
        except ImportError as e:
            # Fallback para MMR se biblioteca n√£o dispon√≠vel
            logger.warning(
                f"Algorithm '{algorithm}' not available ({e}), falling back to MMR"
            )
            deduped_older = _mmr_select(
                chunks=older_chunks,
                k=effective_max,
                lambda_div=getattr(self.valves, "DEDUP_RELEVANCE_WEIGHT", 0.7),
                preserve_order=True,
                similarity_threshold=threshold,
                randomize=shuffle_older,
                reference_chunks=reference_chunks_for_mmr,
            )
            algo_used = "mmr_fallback"

        # Combinar: Se reference_first, recent V√äM PRIMEIRO
        if reference_first:
            result = (recent_chunks + deduped_older)[:max_chunks]
        else:
            result = (deduped_older + recent_chunks)[:max_chunks]

        # Preservar ordem original se solicitado
        if preserve_order:
            result = self._restore_order(result, chunks)

        deduped_count = len(result)
        reduction_pct = (
            ((original_count - deduped_count) / original_count * 100)
            if original_count > 0
            else 0
        )
        tokens_saved = (original_count - deduped_count) * 30  # ~30 tokens/par√°grafo

        # Detectar se houve fallback
        fallback_occurred = algo_used.endswith("_fallback")
        
        # Log de telemetria para monitoramento
        if fallback_occurred:
            print(f"[DEDUP] TELEMETRIA: Fallback detectado - algoritmo solicitado vs usado: {algorithm} -> {algo_used}")
        
        return {
            "chunks": result,
            "original_count": original_count,
            "deduped_count": deduped_count,
            "reduction_pct": reduction_pct,
            "tokens_saved": tokens_saved,
            "algorithm_used": algo_used,
            "fallback_occurred": fallback_occurred,
            "dependencies_checked": True,
        }

    def _minhash_dedupe(
        self,
        chunks: List[str],
        threshold: float,
        max_chunks: int,
        reference_chunks: List[str] = None,
    ) -> List[str]:
        """MinHash LSH deduplica√ß√£o - O(n) - requer datasketch

        Args:
            reference_chunks: Se fornecido, dedupe chunks CONTRA estes (j√° no LSH)
        """
        try:
            from datasketch import MinHash, MinHashLSH
        except ImportError:
            raise ImportError("datasketch required: pip install datasketch")

        lsh = MinHashLSH(threshold=threshold, num_perm=128)
        unique_chunks = []

        # Se h√° reference_chunks, inserir no LSH primeiro (dedupe CONTRA eles)
        if reference_chunks:
            for i, ref_chunk in enumerate(reference_chunks):
                m = MinHash(num_perm=128)
                for word in ref_chunk.split():
                    m.update(word.encode("utf8"))
                lsh.insert(f"ref_{i}", m)

        for i, chunk in enumerate(chunks):
            if len(unique_chunks) >= max_chunks:
                break

            # Criar MinHash signature
            m = MinHash(num_perm=128)
            for word in chunk.split():
                m.update(word.encode("utf8"))

            # Query LSH para similares
            result = lsh.query(m)
            if not result:  # Nenhum similar encontrado
                lsh.insert(f"chunk_{i}", m)
                unique_chunks.append(chunk)

        return unique_chunks

    def _tfidf_dedupe(
        self,
        chunks: List[str],
        threshold: float,
        max_chunks: int,
        reference_chunks: List[str] = None,
    ) -> List[str]:
        """TF-IDF + Cosine Similarity deduplica√ß√£o - requer sklearn

        Args:
            reference_chunks: Se fornecido, dedupe chunks CONTRA estes
        """
        try:
            from sklearn.feature_extraction.text import TfidfVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
        except ImportError:
            raise ImportError("sklearn required: pip install scikit-learn")

        if not chunks:
            return []

        # Se h√° reference_chunks, processar junto para TF-IDF consistente
        all_chunks = (reference_chunks or []) + chunks
        ref_count = len(reference_chunks) if reference_chunks else 0

        # Criar TF-IDF matrix
        vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=1, max_df=0.95)
        tfidf_matrix = vectorizer.fit_transform(all_chunks)

        selected = []
        selected_indices = []

        # Se h√° reference, considerar todos eles como "j√° selecionados"
        if ref_count > 0:
            selected_indices = list(range(ref_count))

        # Iterar apenas sobre chunks (n√£o reference)
        for i in range(ref_count, len(all_chunks)):
            chunk_idx_in_original = i - ref_count
            chunk = chunks[chunk_idx_in_original]

            if len(selected) >= max_chunks:
                break

            if not selected_indices:
                selected.append(chunk)
                selected_indices.append(i)
                continue

            # Calcular similaridade com j√° selecionados (inclui reference)
            chunk_vec = tfidf_matrix[i : i + 1]
            if selected_indices:
                selected_vecs = tfidf_matrix[selected_indices]
                similarities = cosine_similarity(chunk_vec, selected_vecs)
                max_sim = similarities.max()
            else:
                max_sim = 0.0
            if max_sim < threshold:
                selected.append(chunk)
                selected_indices.append(i)

        return selected

    def _restore_order(self, deduped: List[str], original: List[str]) -> List[str]:
        """Restaura ordem original dos chunks dedupados"""
        if not deduped or not original:
            return deduped

        # Criar mapa: chunk ‚Üí √≠ndice original
        original_indices = {chunk: i for i, chunk in enumerate(original)}

        # Ordenar deduped pela ordem original
        ordered = sorted(deduped, key=lambda x: original_indices.get(x, 999999))
        return ordered

    def _semantic_dedupe(
        self,
        chunks: List[str],
        threshold: float,
        max_chunks: int,
        reference_chunks: List[str] = None,
        model_name: str = "sentence-transformers/all-MiniLM-L6-v2"
    ) -> List[str]:
        """Deduplica√ß√£o sem√¢ntica usando embeddings (Haystack)
        
        Args:
            chunks: Par√°grafos a dedupear
            threshold: Cosine similarity threshold (0.0-1.0, default 0.85)
            max_chunks: N√∫mero m√°ximo a retornar
            reference_chunks: Se fornecido, dedupe chunks CONTRA estes
            model_name: Modelo de embeddings (lightweight por padr√£o)
        
        Returns:
            Lista de chunks √∫nicos semanticamente
            
        Raises:
            ImportError: Se Haystack n√£o estiver dispon√≠vel (fallback para MMR)
        """
        if not HAYSTACK_AVAILABLE:
            print(f"[DEDUP] DEPENDENCIA FALTANDO: Haystack/sentence-transformers n√£o instalado")
            print(f"[DEDUP] INSTALAR: pip install haystack sentence-transformers scikit-learn")
            raise ImportError("Haystack/sentence-transformers required for semantic dedup")
        
        if not chunks:
            return []
        
        # Preparar documentos para Haystack
        docs = [Document(content=chunk, meta={"original_idx": i}) 
                for i, chunk in enumerate(chunks)]
        
        # Reference documents (se fornecido)
        if reference_chunks:
            ref_docs = [Document(content=ref, meta={"is_reference": True}) 
                        for ref in reference_chunks]
            all_docs = ref_docs + docs
        else:
            all_docs = docs
        
        # Embedder (in-memory, sem persist√™ncia)
        embedder = SentenceTransformersDocumentEmbedder(model=model_name)
        embedder.warm_up()
        embedded_docs = embedder.run(all_docs)["documents"]
        
        # Extrair embeddings como numpy array
        embeddings = np.array([doc.embedding for doc in embedded_docs])
        
        # Calcular matriz de similaridade (cosine)
        from sklearn.metrics.pairwise import cosine_similarity
        similarity_matrix = cosine_similarity(embeddings)
        
        # Selecionar chunks √∫nicos por clustering simples
        selected_indices = []
        excluded_indices = set()
        
        # Se h√° refer√™ncias, marcar como j√° selecionadas
        if reference_chunks:
            num_refs = len(reference_chunks)
            excluded_indices.update(range(num_refs))
            start_idx = num_refs
        else:
            start_idx = 0
        
        for i in range(start_idx, len(similarity_matrix)):
            if i in excluded_indices:
                continue
            
            # Verificar se similar a algum j√° selecionado ou refer√™ncia
            is_duplicate = False
            for j in selected_indices + list(range(start_idx)):
                if i != j and similarity_matrix[i][j] >= threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                selected_indices.append(i)
                if len(selected_indices) >= max_chunks:
                    break
        
        # Mapear de volta para chunks originais
        result = [chunks[embedded_docs[i].meta["original_idx"]] 
                  for i in selected_indices if i >= start_idx]
        
        return result

    def _context_aware_prioritize(
        self,
        chunks: List[str],
        must_terms: Optional[List[str]] = None,
        key_questions: Optional[List[str]] = None,
        preserve_top_pct: float = 0.3
    ) -> Tuple[List[Tuple[int, str]], List[Tuple[int, str]]]:
        """
        Separa chunks em alta e baixa prioridade baseado em contexto.
        
        Args:
            chunks: Lista de chunks para priorizar
            must_terms: Termos que devem ser preservados (weight: 2.0)
            key_questions: Quest√µes-chave para matching (weight: 1.5)
            preserve_top_pct: % de chunks para alta prioridade (default: 0.3)
            
        Returns:
            (high_priority_chunks, low_priority_chunks) where each is List[Tuple[int, str]] (index, chunk)
        """
        if not chunks:
            return [], []
            
        if not must_terms and not key_questions:
            # Se n√£o h√° contexto, retornar chunks recentes como high priority
            high_count = max(1, int(len(chunks) * preserve_top_pct))
            return [(len(chunks)-high_count+i, ch) for i, ch in enumerate(chunks[-high_count:])], \
                   [(i, ch) for i, ch in enumerate(chunks[:-high_count])]
        
        # Calcular score para cada chunk
        chunk_scores = []
        for i, chunk in enumerate(chunks):
            # LLM-first: Deixar o LLM decidir qualidade atrav√©s do scoring natural
            chunk_lower = chunk.lower()
            score = 0.0
            must_score = 0.0
            question_score = 0.0
            
            # 1. Must terms (weight: 2.0) - LLM-first: scoring inteligente
            if must_terms:
                def _is_geographic_term(term: str) -> bool:
                    """Detecta se um termo √© geogr√°fico baseado em caracter√≠sticas estruturais"""
                    term_lower = term.strip().lower()
                    
                    # Termos muito curtos (< 3 chars) s√£o provavelmente c√≥digos geogr√°ficos
                    if len(term_lower) < 3:
                        return True
                    
                    # Pa√≠ses conhecidos (lista m√≠nima)
                    countries = {"brasil", "brazil", "portugal", "argentina", "chile", "colombia", "mexico"}
                    if term_lower in countries:
                        return True
                    
                    # C√≥digos de pa√≠s comuns
                    geo_codes = {"br", "pt", "ar", "cl", "co", "mx", "us", "uk", "fr", "de", "es", "it"}
                    if term_lower in geo_codes:
                        return True
                    
                    # Termos geogr√°ficos gen√©ricos
                    geo_generics = {"global", "mundial", "nacional", "internacional", "latam", "america", "europa"}
                    if term_lower in geo_generics:
                        return True
                    
                    return False
                
                for term in must_terms:
                    term_lower = term.lower()
                    
                    # Ignorar termos geogr√°ficos usando detec√ß√£o estrutural
                    if _is_geographic_term(term):
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(f"[CONTEXT_AWARE] Skipping geo term: '{term}'")
                        continue
                    
                    # Contar ocorr√™ncias (case-insensitive)
                    count = chunk_lower.count(term_lower)
                    
                    # LLM-first: Bonus para co-ocorr√™ncia com contexto setorial
                    setorial_bonus = 0.0
                    if any(setor in chunk_lower for setor in [
                        "executive search", "headhunting", "recrutamento executivo", 
                        "search executivo", "consultoria executiva"
                    ]):
                        setorial_bonus = 1.0  # Bonus por contexto setorial correto
                    
                    term_score = (count * 2.0) + setorial_bonus
                    must_score += term_score
                    
            # 2. Key questions overlap (weight: 1.5)
            if key_questions:
                for question in key_questions:
                    question_lower = question.lower()
                    # Verificar se chunk cont√©m palavras-chave da quest√£o
                    question_words = set(question_lower.split())
                    chunk_words = set(chunk_lower.split())
                    overlap = len(question_words.intersection(chunk_words))
                    if overlap > 0:
                        q_score = overlap * 1.5
                        question_score += q_score
            
            # 3. Posi√ß√£o no documento (recent > old, weight: 0.1)
            position_score = (i / len(chunks)) * 0.1
            score = must_score + question_score + position_score
            
            chunk_scores.append((score, i, chunk))
            
            # Debug logging para chunks com score alto
            if getattr(self.valves, "VERBOSE_DEBUG", False) and score > 1.0:
                print(f"[CONTEXT_AWARE] Chunk {i}: score={score:.2f} (must={must_score:.2f}, q={question_score:.2f}, pos={position_score:.2f})")
                print(f"[CONTEXT_AWARE]    Preview: {chunk[:100]}...")
        
        # Ordenar por score (maior primeiro)
        chunk_scores.sort(key=lambda x: x[0], reverse=True)
        
        # Separar em high/low priority
        high_count = max(1, int(len(chunks) * preserve_top_pct))
        high_priority = [(chunk_scores[i][1], chunk_scores[i][2]) for i in range(high_count)]  # (index, chunk)
        low_priority = [(chunk_scores[i][1], chunk_scores[i][2]) for i in range(high_count, len(chunks))]
        
        return high_priority, low_priority

    def _dedupe_chunks(
        self,
        chunks: List[str],
        max_chunks: int,
        algorithm: str,
        threshold: float
    ) -> List[str]:
        """
        M√©todo auxiliar para dedupear chunks (usado pelo context-aware).
        Aplica o algoritmo especificado aos chunks fornecidos.
        """
        if not chunks or max_chunks <= 0:
            return []
            
        try:
            if algorithm == "minhash":
                return self._minhash_dedupe(chunks, threshold, max_chunks)
            elif algorithm == "tfidf":
                return self._tfidf_dedupe(chunks, threshold, max_chunks)
            elif algorithm == "semantic":
                model_name = getattr(self.valves, "SEMANTIC_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
                return self._semantic_dedupe(chunks, threshold, max_chunks, model_name=model_name)
            else:  # default to mmr
                return _mmr_select(chunks, max_chunks, similarity_threshold=threshold)
        except Exception as e:
            # Fallback para MMR em caso de erro
            print(f"[DEDUP] FALLBACK CRITICO: {algorithm} -> MMR devido a: {e}")
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[DEDUP] Verifique dependencias: pip install scikit-learn datasketch sentence-transformers haystack")
            return _mmr_select(chunks, max_chunks, similarity_threshold=threshold)


def _mmr_select(
    chunks: List[str],
    k: int = 50,
    lambda_div: float = 0.7,
    preserve_order: bool = True,
    similarity_threshold: float = 0.6,
    randomize: bool = False,
    reference_chunks: List[str] = None,
) -> List[str]:
    """MMR com sele√ß√£o justa e preserva√ß√£o de narrativa

    Args:
        chunks: Lista de par√°grafos/chunks
        k: N√∫mero m√°ximo de chunks a selecionar
        lambda_div: Peso diversidade (0.0-1.0, maior = mais conservador)
        preserve_order: True = shuffle ‚Üí select ‚Üí reorder (narrativa), False = order by size
        similarity_threshold: Threshold para considerar similar (0.0-1.0)
        randomize: Se True, embaralha chunks antes de selecionar
        reference_chunks: Chunks de refer√™ncia (dedupe candidates CONTRA estes)

    Returns:
        Lista de chunks selecionados (preservando ordem original se preserve_order=True)
    """
    # Preparar √≠ndices originais para preservar ordem depois
    indexed_chunks = [(i, chunk) for i, chunk in enumerate(chunks)]

    # Estrat√©gia de sele√ß√£o: pode embaralhar os antigos para sele√ß√£o justa
    # - Se preserve_order=True e randomize=True: shuffle nos antigos, reordena ao final
    # - Se preserve_order=True e randomize=False: varre em ordem original
    # - Se preserve_order=False: prioriza chunks maiores primeiro
    if preserve_order:
        pool = list(indexed_chunks)
        if randomize:
            import random

            random.shuffle(pool)
    else:
        pool = sorted(indexed_chunks, key=lambda x: len(x[1]), reverse=True)

    selected_with_indices = []
    selected_sh: List[set] = []

    # Se h√° reference_chunks, inicializar selected_sh com eles (dedupe CONTRA refer√™ncia)
    if reference_chunks:
        for ref_chunk in reference_chunks:
            selected_sh.append(_shingles(ref_chunk))

    for original_idx, chunk in pool:
        if len(selected_with_indices) >= k:
            break

        s_sh = _shingles(chunk)

        # Calcular similaridade m√°xima com selecionados (inclui reference se houver)
        sim = max((0.0,) + tuple(_jaccard(s_sh, prev_sh) for prev_sh in selected_sh))

        # Score MMR: relev√¢ncia (tamanho) - penalidade de similaridade
        score = lambda_div * (len(chunk) / 1000.0) - (1 - lambda_div) * sim

        # Aceitar se: baixa similaridade OU score positivo
        if sim < similarity_threshold or score > 0:
            selected_with_indices.append((original_idx, chunk))
            selected_sh.append(s_sh)

    # REMOVED (v4.4 - P0.2): Fallback perigoso que anulava deduplica√ß√£o
    # RAZ√ÉO: "if len < k//2: return chunks[:k]" IGNORAVA toda a deduplica√ß√£o!
    # NOVO: Sempre retornar selecionados (mesmo se poucos), garantindo dedupe real

    # Reordenar para preservar narrativa (se habilitado)
    if preserve_order and selected_with_indices:
        selected_with_indices.sort(key=lambda x: x[0])  # j√° est√° em ordem, mas garantir

    return [chunk for _, chunk in selected_with_indices]

# ===== LLM Client and Utilities (from PipeHay3) =====
class AsyncOpenAIClient:
    """Async OpenAI client using httpx for better performance"""

    def __init__(self, base_url: str, api_key: str, model: str, valves=None):
        self.base_url = (base_url or "").rstrip("/")
        self.api_key = api_key
        self.model = model
        self.valves = valves  # Store valves for timeout configuration
        self._client = None  # Lazy initialization

    def _ensure_client(self):
        """Lazy initialization of httpx client"""
        if self._client is None:
            try:
                import httpx

                # Use valve timeout if available, otherwise default to 180s
                read_timeout = (
                    getattr(self.valves, "HTTPX_READ_TIMEOUT", 180)
                    if self.valves
                    else 180
                )
                self._client = httpx.AsyncClient(
                    timeout=httpx.Timeout(
                        240.0, connect=10.0, read=float(read_timeout)
                    ),  # Increased: 120‚Üí240, 5‚Üí10, 115‚Üí180
                    limits=httpx.Limits(
                        max_keepalive_connections=10, max_connections=20
                    ),
                    http2=True,  # Enable HTTP/2 for multiplexing
                    follow_redirects=True,
                )
            except ImportError:
                raise RuntimeError("httpx library required: pip install httpx")
        return self._client

    async def _call_api(
        self, prompt: str, generation_kwargs: Optional[dict] = None
    ) -> str:
        try:
            import httpx
        except ImportError:
            raise RuntimeError("httpx library required: pip install httpx")

        client = self._ensure_client()
        url = build_chat_endpoint(self.base_url)

        # Log do tamanho do prompt ANTES de enviar (debug cr√≠tico para truncamento)
        prompt_len = len(prompt)
        prompt_tokens_est = prompt_len // 4
        if prompt_tokens_est > 12000:
            logger.warning(
                f"[API] Prompt grande sendo enviado: {prompt_len:,} chars (~{prompt_tokens_est:,} tokens). Modelo '{self.model}' pode ter limite de input que cause truncamento!"
            )

        body = {"model": self.model, "messages": [{"role": "user", "content": prompt}]}
        gen_kwargs = generation_kwargs or {}

        # Detect capabilities by model name
        model_lower = (self.model or "").lower()
        is_new_gen_model = any(
            [
                "gpt-4.1" in model_lower,
                "gpt-4.5" in model_lower,
                "gpt-5" in model_lower,
                "o1" in model_lower,
                "o3" in model_lower,
                model_lower.startswith("chatgpt-"),
            ]
        )

        # Temperature: newer models often only support default (1.0)
        if "temperature" in gen_kwargs and not is_new_gen_model:
            body["temperature"] = gen_kwargs["temperature"]

        # Forward response_format when caller enforces JSON mode
        resp_fmt = gen_kwargs.get("response_format")
        if resp_fmt:
            body["response_format"] = resp_fmt

        # Do NOT send any token limits - let model defaults handle it
        # OpenAI API rejects max_tokens/max_completion_tokens for some models

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        # ‚úÖ FIX TIMEOUT HIERARCHY: Timeout per-request din√¢mico (sobrescreve cliente)
        # RAZ√ÉO: Synthesis precisa de 600s+, mas cliente tem BASE de 180s
        # HTTPX permite override per-request que TEM PRIORIDADE sobre cliente
        default_read = (
            getattr(self.valves, "HTTPX_READ_TIMEOUT", 180)
            if hasattr(self, "valves")
            else 180
        )
        request_timeout = float(gen_kwargs.get("request_timeout", default_read))

        # ‚úÖ CR√çTICO: Usar MAX entre request_timeout e default (sempre respeitar expl√≠cito)
        # Se synthesis pede 600s, usar 600s (n√£o cap em 180s!)
        effective_read_timeout = max(request_timeout, 60)  # M√≠nimo 60s

        # ‚úÖ Criar timeout per-request (sobrescreve timeout do cliente)
        per_request_timeout = httpx.Timeout(
            240.0, connect=10.0, read=effective_read_timeout
        )

        if effective_read_timeout > 300:
            logger.info(
                f"[API] Long operation timeout: {effective_read_timeout}s (synthesis/large prompt)"
            )

        try:
            # ‚úÖ Async HTTP POST com timeout PER-REQUEST expl√≠cito
            resp = await client.post(
                url, json=body, headers=headers, timeout=per_request_timeout
            )
            resp.raise_for_status()
            j = resp.json()
            text_parts = []
            for ch in j.get("choices", []):
                if isinstance(ch.get("message"), dict):
                    text_parts.append(ch["message"].get("content") or "")
                else:
                    text_parts.append(ch.get("text") or "")
            return "".join(text_parts).strip()
        except httpx.TimeoutException as e:
            logger.error(f"[API] HTTP timeout after {effective_read_timeout}s: {e}")
            raise TimeoutError(
                f"HTTP request timeout after {effective_read_timeout}s"
            ) from e
        except httpx.HTTPStatusError as e:
            error_detail = ""
            try:
                error_detail = f" - {e.response.text}"
            except:
                pass
            logger.error("HTTP Error %s: %s%s", e.response.status_code, e, error_detail)
            logger.debug("URL: %s", url)
            logger.debug("Body: %s", json.dumps(body, indent=2))
            raise RuntimeError(f"HTTP {e.response.status_code}: {e}") from e
        except Exception as e:
            logger.error("HTTP Error: %s", e)
            raise

    async def run(self, prompt: str, generation_kwargs: Optional[dict] = None) -> dict:
        result = await self._call_api(prompt, generation_kwargs)
        return {"replies": [result]}


# ===== Logging =====
import logging
DEBUG_LOGGING = os.getenv("PIPE_DEBUG", "0") == "1"
logging.basicConfig(
    level=logging.DEBUG if DEBUG_LOGGING else logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
logger = logging.getLogger("pipe")

# ===== LLM Cache =====
_LLM_CACHE: Dict[str, Optional[AsyncOpenAIClient]] = {}
_LLM_CACHE_LOCK: Lock = Lock()


def _get_llm(
    valves, generation_kwargs: Optional[dict] = None, model_name: Optional[str] = None
) -> Optional[AsyncOpenAIClient]:
    model = model_name or getattr(valves, "LLM_MODEL", "") or ""
    base = getattr(valves, "OPENAI_BASE_URL", "") or ""
    key = f"{model}::{base}"
    # Fast path (read): if present and not None, return; else build under lock
    cached = _LLM_CACHE.get(key)
    if cached is not None:
        return cached

    with _LLM_CACHE_LOCK:
        # Double-check inside lock
        cached = _LLM_CACHE.get(key)
        if cached is not None:
            return cached

        api_key = (
            getattr(valves, "OPENAI_API_KEY", "") or os.getenv("OPENAI_API_KEY") or ""
        )

        # Debug info
        logger.debug("Model: %s", model)
        logger.debug("Base URL: %s", base)
        logger.debug("API Key: %s", "SET" if api_key else "NOT SET")

        if not all([base, api_key, model]):
            logger.error(
                "Missing configuration: base=%s, api_key=%s, model=%s",
                bool(base),
                bool(api_key),
                bool(model),
            )
            raise LLMConfigurationError(
                "LLM configuration missing: set OPENAI_BASE_URL, OPENAI_API_KEY and LLM_MODEL or corresponding valves"
            )

        llm = AsyncOpenAIClient(base, api_key, model, valves)
        _LLM_CACHE[key] = llm
        return llm


async def _safe_llm_run_with_retry(
    llm_obj,
    prompt_text: str,
    generation_kwargs: Optional[dict] = None,
    timeout: int = 60,
    max_retries: int = 3,
) -> Optional[dict]:
    """LLM call with exponential backoff retry

    Args:
        llm_obj: LLM client object
        prompt_text: Prompt to send
        generation_kwargs: Generation parameters
        timeout: Base timeout in seconds (default: 60)
        max_retries: Maximum number of retry attempts (default: 3)

    Returns:
        LLM response dict or None on recoverable errors

    Raises:
        PipeExecutionError: On timeout or unrecoverable errors
        ToolExecutionError: On connection errors
    """
    if not llm_obj:
        logger.warning("LLM object is None, skipping call")
        return None

    base_timeout = timeout

    for attempt in range(max_retries):
        # Aumentar timeout a cada tentativa: 60s, 120s, 240s
        current_timeout = base_timeout * (2**attempt)

        try:
            # ‚úÖ FIX: Usar timeout EXPL√çCITO sem cap quando dispon√≠vel
            # RAZ√ÉO: S√≠ntese final precisa de 600s+ (prompt gigante)
            # Per-request timeout SOBRESCREVE timeout do cliente httpx
            eff_kwargs = dict(generation_kwargs or {})

            # ‚úÖ SEMPRE usar current_timeout - 30s (margem para conex√£o + parsing + cleanup)
            # N√ÉO aplicar cap de HTTPX_READ_TIMEOUT (per-request override tem prioridade)
            # üîß FIX: Aumentar margem de 10s ‚Üí 30s para evitar timeout durante parsing de respostas grandes
            effective_http_timeout = max(60, int(current_timeout - 30))

            if current_timeout > 300:
                logger.info(
                    f"[TIMEOUT] Long operation: {current_timeout}s (synthesis/large prompt)"
                )

            eff_kwargs["request_timeout"] = effective_http_timeout

            # üîß LOG: Diagn√≥stico de timeout antes da chamada
            logger.info(
                f"[LLM_CALL] Attempt {attempt+1}/{max_retries}: timeout={current_timeout}s, http_timeout={effective_http_timeout}s"
            )

            # Direct async call (no asyncio.to_thread needed with AsyncOpenAIClient)
            result = await asyncio.wait_for(
                llm_obj.run(prompt=prompt_text, generation_kwargs=eff_kwargs),
                timeout=current_timeout,
            )

            # üîß LOG: Sucesso!
            response_size = len(str(result)) if result else 0
            logger.info(f"[LLM_CALL] ‚úÖ Response received ({response_size:,} chars)")

            return result

        except asyncio.TimeoutError:
            if attempt < max_retries - 1:
                wait_time = 2**attempt  # 1s, 2s, 4s
                logger.warning(
                    f"Timeout attempt {attempt+1}/{max_retries}, retrying in {wait_time}s with timeout={current_timeout}s"
                )
                await asyncio.sleep(wait_time)
            else:
                logger.error(
                    f"LLM call timeout after {max_retries} attempts (final timeout: {current_timeout}s)"
                )
                raise PipeExecutionError(
                    f"LLM call exceeded timeout after {max_retries} retries"
                )

        except (ConnectionError, TimeoutError) as e:
            # Retry apenas em erros recuper√°veis
            if "rate limit" in str(e).lower() or "overloaded" in str(e).lower():
                if attempt < max_retries - 1:
                    wait_time = 2 ** (attempt + 2)  # 4s, 8s, 16s para rate limit
                    logger.warning(f"Rate limit/overload, retrying in {wait_time}s")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(
                        f"LLM Connection Error after {max_retries} retries: {e}"
                    )
                    raise ToolExecutionError(
                        f"Failed to connect to LLM after {max_retries} retries: {e}"
                    ) from e
            else:
                # Erro n√£o-recuper√°vel de conex√£o
                logger.error(f"LLM Connection Error: {e}")
                raise ToolExecutionError(f"Failed to connect to LLM: {e}") from e

        except (KeyError, ValueError, json.JSONDecodeError) as e:
            # Parse errors can be transient (truncation, markdown wrappers). Retry with re-ask.
            logger.warning(f"LLM Response Parse Error: {e}")
            if attempt < max_retries - 1:
                wait_time = 2**attempt
                logger.warning(
                    f"Parse error attempt {attempt+1}/{max_retries}, retrying in {wait_time}s"
                )
                await asyncio.sleep(wait_time)
                # Append a strict JSON-only instruction for the next attempt
                prompt_suffix = "\n\nIMPORTANT: Return ONLY valid JSON (object or array). Do NOT include any markdown or explanatory text. Use double quotes for keys and strings."
                # If prompt_text already contains the suffix, don't duplicate
                if not prompt_text.strip().endswith(prompt_suffix.strip()):
                    prompt_text = prompt_text + prompt_suffix
                continue
            else:
                logger.error(
                    f"LLM Response Parse Error after {max_retries} attempts: {e}"
                )
                raise PipeExecutionError(
                    f"Invalid LLM response format after {max_retries} retries: {e}"
                ) from e

        except Exception as e:
            # Retry apenas em erros recuper√°veis
            if "rate limit" in str(e).lower() or "overloaded" in str(e).lower():
                if attempt < max_retries - 1:
                    wait_time = 2 ** (attempt + 2)  # 4s, 8s, 16s para rate limit
                    logger.warning(f"Rate limit/overload, retrying in {wait_time}s")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(
                        f"LLM Unexpected Error after {max_retries} retries: {e}"
                    )
                    raise PipeExecutionError(
                        f"LLM call failed after {max_retries} retries: {e}"
                    ) from e
            else:
                # Erro n√£o-recuper√°vel
                logger.error(f"LLM Unexpected Error: {e}")
                raise PipeExecutionError(f"LLM call failed: {e}") from e


# REMOVED (v4.3.1): _safe_llm_run() - wrapper desnecess√°rio
# Use diretamente _safe_llm_run_with_retry(max_retries=1) para single attempt


# ===== Utilities =====
def normalize_base_url(base_url: str) -> str:
    """Normaliza base_url para diferentes variantes de API"""
    base_url = base_url.strip().rstrip("/")
    # Normalizar variantes /api, /v1beta, etc.
    if base_url.endswith(("/v1", "/v1beta", "/api")):
        return base_url
    return base_url + "/v1"


def build_chat_endpoint(base_url: str) -> str:
    """Constr√≥i endpoint de chat completions de forma robusta"""
    from urllib.parse import urljoin

    norm = normalize_base_url(base_url)
    return urljoin(norm + "/", "chat/completions")


def _hash_contract(contract: Dict[str, Any]) -> str:
    s = json.dumps(contract, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(s.encode("utf-8")).hexdigest()


# ==================== UNIFIED JSON PARSING (v4.3.1 - P1A Consolidation) ====================


def parse_json_resilient(
    text: str, mode: str = "balanced", allow_arrays: bool = True
) -> Optional[dict]:
    """CONSOLIDADO (v4.3.1): √önica fun√ß√£o de parsing JSON com 3 modos

    Substitui 3 fun√ß√µes antigas:
    - _extract_json_from_text() ‚Üí mode='balanced', allow_arrays=True
    - parse_llm_json_strict() ‚Üí mode='strict', allow_arrays=False
    - _soft_json_cleanup() ‚Üí usado internamente em mode='soft'

    Args:
        text: Texto contendo JSON (possivelmente com ru√≠do)
        mode: 'strict' (apenas objetos, raise em erro) |
              'soft' (cleanup trailing commas) |
              'balanced' (markdown + cleanup + balanceamento) [DEFAULT]
        allow_arrays: Se True, aceita arrays na raiz; se False, apenas objetos

    Returns:
        Dict/List parseado ou None (mode='balanced') / raises (mode='strict')

    Raises:
        ContractValidationError: Se mode='strict' e JSON inv√°lido
    """
    if not text or not isinstance(text, str):
        if mode == "strict":
            raise ContractValidationError("Empty or invalid LLM response")
        return None

    s = text.strip()

    # STEP 1: Remove markdown fences (todos os modos)
    s = re.sub(r"^```(?:json)?\s*", "", s, flags=re.MULTILINE)
    s = re.sub(r"\s*```\s*$", "", s, flags=re.MULTILINE)
    s = s.strip()

    # MODE: STRICT (contracts - apenas objetos)
    if mode == "strict":
        m_open = s.find("{")
        m_close = s.rfind("}")
        if m_open == -1 or m_close == -1 or m_close <= m_open:
            raise ContractValidationError(
                f"JSON object not found in LLM response (len={len(s)})"
            )

        raw = s[m_open : m_close + 1]

        # Tentativa 1: parse direto
        try:
            return json.loads(raw)
        except json.JSONDecodeError:
            pass

        # Tentativa 2: limpar bytes de controle
        cleaned = re.sub(r"[\x00-\x1f\x7f]", "", raw)
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass

        # Tentativa 3: trailing commas
        cleaned2 = re.sub(r",\s*}", "}", cleaned)
        cleaned2 = re.sub(r",\s*\]", "]", cleaned2)
        try:
            return json.loads(cleaned2)
        except json.JSONDecodeError as e:
            preview = cleaned2[:200] + "..." if len(cleaned2) > 200 else cleaned2
            raise ContractValidationError(
                f"Invalid JSON from LLM (after cleaning): {e}\nPreview: {preview}"
            )

    # MODE: SOFT (apenas trailing commas cleanup)
    if mode == "soft":
        s2 = re.sub(r",\s*}\s*", r"}", s)
        s2 = re.sub(r",\s*\]\s*", r"]", s2)
        try:
            return json.loads(s2)
        except json.JSONDecodeError:
            return None

    # MODE: BALANCED (default - m√°ximo esfor√ßo)
    # Tentativa 1: parse direto
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        pass

    # Tentativa 2: encontrar JSON (objeto ou array se permitido)
    if allow_arrays:
        json_pattern = re.compile(r"(\{[\s\S]*\}|\[[\s\S]*\])")
    else:
        json_pattern = re.compile(r"(\{[\s\S]*\})")

    m = json_pattern.search(s)
    if not m:
        logger.warning("No JSON pattern found in text")
        return None

    snippet = m.group(1).strip()

    # ‚úÖ AGGRESSIVE CLEANUP (added for Analyst robustness)
    # Remove inline comments (// and /* */)
    snippet = re.sub(r'//.*?$', '', snippet, flags=re.MULTILINE)  # Single-line comments
    snippet = re.sub(r'/\*.*?\*/', '', snippet, flags=re.DOTALL)  # Multi-line comments
    
    # Remove trailing commas at ANY nesting level
    snippet = re.sub(r',\s*([}\]])', r'\1', snippet)  # , before } or ]
    
    # Normalize whitespace
    snippet = re.sub(r'\s+', ' ', snippet)
    
    # Tentativa 3: parse cleaned snippet
    try:
        return json.loads(snippet)
    except json.JSONDecodeError as e:
        # Enhanced error logging
        logger.error(f"[JSON_PARSE] Failed after aggressive cleanup: {e}")
        logger.error(f"[JSON_PARSE] Error position: char {e.pos}")
        ctx_start = max(0, e.pos - 50)
        ctx_end = min(len(snippet), e.pos + 50)
        logger.error(f"[JSON_PARSE] Context: ...{snippet[ctx_start:ctx_end]}...")

    # Tentativa 4: balanceamento de chaves/colchetes
    if snippet.startswith("{"):
        start = snippet.find("{")
        depth = 0
        for i in range(start, len(snippet)):
            ch = snippet[i]
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    try:
                        return json.loads(snippet[start : i + 1])
                    except Exception:
                        break
    elif snippet.startswith("[") and allow_arrays:
        start = snippet.find("[")
        depth = 0
        for i in range(start, len(snippet)):
            ch = snippet[i]
            if ch == "[":
                depth += 1
            elif ch == "]":
                depth -= 1
                if depth == 0:
                    try:
                        return json.loads(snippet[start : i + 1])
                    except Exception:
                        break

    return None


# ==================== LEGACY JSON PARSERS (mantidos para compatibilidade, delegam para parse_json_resilient) ====================


def _extract_json_from_text(text: str) -> Optional[dict]:
    """LEGACY WRAPPER: Delega para parse_json_resilient(mode='balanced')"""
    return parse_json_resilient(text, mode="balanced", allow_arrays=True)


def _soft_json_cleanup(text: str) -> str:
    """LEGACY WRAPPER: Delega para parse_json_resilient(mode='soft')

    Returns cleaned text (not parsed dict) for backward compatibility.
    """
    if not isinstance(text, str):
        return text
    # Usar mode='soft' e depois retornar o texto limpo (n√£o parseado)
    s = text
    s = re.sub(r",\s*}\s*", r"}", s)
    s = re.sub(r",\s*\]\s*", r"]", s)
    return s


# ==================== LLM PARAMETER HELPERS ====================


def get_safe_llm_params(model_name: str, base_params: dict = None) -> dict:
    """Retorna par√¢metros seguros para o modelo, removendo incompat√≠veis

    GPT-5/GPT-4.5/O1/O3: N√ÉO suportam temperature, max_tokens
    GPT-4/GPT-3.5: Suportam todos os par√¢metros

    Args:
        model_name: Nome do modelo (ex: "gpt-5-mini")
        base_params: Par√¢metros desejados (podem ser filtrados)

    Returns:
        Dict com par√¢metros seguros para o modelo
    """
    if not base_params:
        base_params = {}

    model_lower = (model_name or "").lower()
    is_new_gen = any(
        [
            "gpt-4.1" in model_lower,
            "gpt-4.5" in model_lower,
            "gpt-5" in model_lower,
            "o1" in model_lower,
            "o3" in model_lower,
            model_lower.startswith("chatgpt-"),
        ]
    )

    safe_params = {}

    # response_format: suportado por todos
    if "response_format" in base_params:
        safe_params["response_format"] = base_params["response_format"]

    # temperature: N√ÉO suportado por modelos novos
    if "temperature" in base_params and not is_new_gen:
        safe_params["temperature"] = base_params["temperature"]

    # request_timeout: sempre seguro (n√£o vai no body da API)
    if "request_timeout" in base_params:
        safe_params["request_timeout"] = base_params["request_timeout"]

    # max_tokens/max_completion_tokens: N√ÉO enviar (deixar model defaults)
    # OpenAI rejeita para alguns modelos

    return safe_params


# ==================== CONTRACT PARSING & BUILDING (Inline) ====================


def extract_json_object_strict(text: str) -> str:
    """LEGACY HELPER: Isola o primeiro {...} v√°lido

    Mantido para compatibilidade, mas parse_json_resilient(mode='strict') √© prefer√≠vel.
    """
    if not text or not isinstance(text, str):
        raise ContractValidationError("Empty or invalid LLM response")

    m_open = text.find("{")
    m_close = text.rfind("}")
    if m_open == -1 or m_close == -1 or m_close <= m_open:
        raise ContractValidationError(
            f"JSON object not found in LLM response (len={len(text)})"
        )

    return text[m_open : m_close + 1]


def parse_llm_json_strict(text: str) -> dict:
    """LEGACY WRAPPER: Delega para parse_json_resilient(mode='strict')"""
    return parse_json_resilient(text, mode="strict", allow_arrays=False)


def _first_content_token(text: str) -> str:
    """Extrai primeiro token significativo de um texto (>4 chars, n√£o stopword)

    Args:
        text: Texto para extrair token

    Returns:
        str: Primeiro token significativo ou ""
    """
    stopwords = {
        "sobre",
        "para",
        "como",
        "quais",
        "quem",
        "qual",
        "quando",
        "onde",
        "estudo",
        "an√°lise",
        "volume",
        "mercado",
    }
    for w in text.lower().split():
        if len(w) > 4 and w not in stopwords:
            return w
    return ""


def _patch_seed_if_needed(
    phase: dict, strict_mode: bool, metrics: dict, logger
) -> None:
    """Patch seed_query se estiver muito magra (modo relax apenas)

    Adiciona 1 token do objetivo se seed_query n√£o cont√©m nenhum token significativo do objetivo.

    Args:
        phase: Dict da fase (ser√° modificado se necess√°rio)
        strict_mode: Se True, n√£o faz patch (apenas valida)
        metrics: Dict de m√©tricas (incrementa seed_patched_count)
        logger: Logger para info
    """
    if strict_mode:
        return  # Modo strict: n√£o patch

    obj = phase.get("objective") or phase.get("objetivo") or ""
    sq = phase.get("seed_query", "")

    if not obj or not sq:
        return

    # Verifica se seed_query cont√©m algum token significativo do objetivo
    obj_tokens = [t for t in obj.lower().split() if len(t) > 4]
    sq_lower = sq.lower()

    has_obj_token = any(t in sq_lower for t in obj_tokens)

    if not has_obj_token:
        # Seed n√£o tem nenhum token do objetivo - patch
        k = _first_content_token(obj)
        if k and k not in sq_lower:
            phase["seed_query"] = f"{sq} {k}".strip()
            if metrics is not None:
                metrics["seed_patched_count"] = metrics.get("seed_patched_count", 0) + 1
            logger.info(f"[SEED] Patched seed_query '{sq}' ‚Üí '{phase['seed_query']}'")


# ==================== FASE 2 HELPERS ====================


def _check_mece_basic(fases: List[dict], key_questions: List[str]) -> List[str]:
    """Verifica MECE b√°sico: key_questions √≥rf√£s (sem cobertura)

    Args:
        fases: Lista de fases do contract
        key_questions: Lista de key_questions do contexto

    Returns:
        Lista de key_questions n√£o cobertas por nenhuma fase
    """
    if not key_questions:
        return []

    uncovered = []
    for kq in key_questions:
        tokens = [t for t in kq.lower().split() if len(t) > 4]
        covered = False
        for f in fases:
            obj = (f.get("objetivo") or f.get("objective") or "").lower()
            if any(t in obj for t in tokens):
                covered = True
                break
        if not covered:
            uncovered.append(kq)

    return uncovered


def _append_phase(contract: dict, candidate: dict) -> None:
    """Adiciona fase candidata ao contract (incremental, sem replanejar)

    Args:
        contract: Contract dict (ser√° modificado)
        candidate: Fase candidata completa
    """
    # Normalizar chaves (name/nome, objective/objetivo)
    if "nome" in candidate and "name" not in candidate:
        candidate["name"] = candidate.pop("nome")
    if "objective" not in candidate and "objetivo" in candidate:
        candidate["objective"] = candidate.pop("objetivo")

    # Sanity checks b√°sicos
    seed_query = candidate.get("seed_query", "")
    if not (3 <= len(seed_query.split()) <= 8):
        logger.warning(f"[APPEND] seed_query inv√°lida: {seed_query}")
        return

    seed_core = candidate.get("seed_core", "")
    if seed_core and seed_core == seed_query:
        logger.warning(f"[APPEND] seed_core igual a seed_query: {seed_core}")
        return

    # Adicionar ao contract
    contract["fases"].append(candidate)
    logger.info(f"[APPEND] Fase adicionada: {candidate.get('name', 'N/A')}")


# ==================== ENTITY COVERAGE HELPERS (FASE 1) ====================


def _calc_entity_coverage(fases: List[dict], entities: List[str]) -> float:
    """Calcula a % de fases que cont√™m pelo menos uma entidade em must_terms

    Args:
        fases: Lista de fases do contract (dicts com must_terms)
        entities: Lista de entidades can√¥nicas

    Returns:
        float entre 0.0 e 1.0 representando a cobertura
    """
    if not entities or not fases:
        return 1.0

    covered = 0
    for f in fases:
        must_terms = f.get("must_terms", [])
        mt_str = " ".join(must_terms).lower()
        if any(e.lower() in mt_str for e in entities):
            covered += 1

    return covered / max(1, len(fases))


def _list_missing_entity_phases(fases: List[dict], entities: List[str]) -> List[str]:
    """Lista as fases que N√ÉO cont√™m nenhuma entidade em must_terms

    Args:
        fases: Lista de fases do contract
        entities: Lista de entidades can√¥nicas

    Returns:
        Lista de nomes das fases sem entidades
    """
    if not entities:
        return []

    missing = []
    for f in fases:
        must_terms = f.get("must_terms", [])
        mt_str = " ".join(must_terms).lower()
        if not any(e.lower() in mt_str for e in entities):
            phase_name = (
                f.get("name") or f.get("nome") or f.get("phase_type") or "sem-nome"
            )
            missing.append(phase_name)

    return missing


def _check_entity_coverage_soft(
    contract: dict, entities: List[str], min_coverage: float, logger
) -> None:
    """Valida entity coverage em modo SOFT (warning em vez de exception)

    Args:
        contract: Contract dict (ser√° modificado com _entity_coverage_warning se necess√°rio)
        entities: Lista de entidades can√¥nicas
        min_coverage: Threshold m√≠nimo (ex: 0.70 = 70%)
        logger: Logger para warnings
    """
    fases = contract.get("fases") or contract.get("phases", [])
    coverage = _calc_entity_coverage(fases, entities)

    if entities and coverage < min_coverage:
        contract["_entity_coverage_warning"] = {
            "coverage": coverage,
            "min": min_coverage,
            "missing_phases": _list_missing_entity_phases(fases, entities),
        }
        logger.warning(
            f"Entity coverage {coverage:.0%} < {min_coverage:.0%} (modo soft). "
            f"Fases sem entidades: {contract['_entity_coverage_warning']['missing_phases']}"
        )


# ==================== PHASE POLICY ENFORCEMENT ====================


def _build_synthesis_sections(
    key_questions: List[str],
    research_objectives: List[str],
    contract_entities: List[str],
    phase_objectives: List[str],
) -> dict:
    """CONSOLIDADO (v4.3.1 - P1D): Constr√≥i se√ß√µes do prompt de s√≠ntese

    Args:
        key_questions: Lista de perguntas decis√≥rias
        research_objectives: Lista de objetivos de pesquisa
        contract_entities: Lista de entidades do contract
        phase_objectives: Lista de objetivos das fases executadas

    Returns:
        Dict com: key_questions_section, research_objectives_section,
                 entities_section, phase_objectives_section
    """
    sections = {}

    # Key Questions Section
    if key_questions:
        kq_display = "\n".join(f"{i}. {q}" for i, q in enumerate(key_questions[:8], 1))
        sections[
            "key_questions"
        ] = f"""
üéØ **KEY QUESTIONS (O RELAT√ìRIO DEVE RESPONDER):**
{kq_display}
"""
    else:
        sections["key_questions"] = ""

    # Research Objectives Section
    if research_objectives:
        obj_display = "\n".join(f"‚Ä¢ {obj}" for obj in research_objectives[:5])
        sections[
            "research_objectives"
        ] = f"""
üìã **RESEARCH OBJECTIVES (OBJETIVOS FINAIS):**
{obj_display}
"""
    else:
        sections["research_objectives"] = ""

    # Entities Section
    if contract_entities:
        entities_display = ", ".join(contract_entities[:15])
        if len(contract_entities) > 15:
            entities_display += f" (e mais {len(contract_entities) - 15})"
        sections[
            "entities"
        ] = f"""
üè¢ **ENTIDADES ESPEC√çFICAS (devem ser cobertas no relat√≥rio):**
{entities_display}
"""
    else:
        sections["entities"] = ""

    # Phase Objectives Section
    if phase_objectives:
        sections[
            "phase_objectives"
        ] = f"""
üìä **OBJETIVOS DAS FASES EXECUTADAS:**
{chr(10).join(phase_objectives)}
"""
    else:
        sections["phase_objectives"] = ""

    return sections


def _extract_quality_metrics(facts_list: List[dict]) -> dict:
    """CONSOLIDADO (v4.3.1 - P1C): Extrai m√©tricas de qualidade de lista de fatos

    Usado por:
    - JudgeLLM._validate_quality_rails()
    - Orchestrator._calculate_evidence_metrics_new()

    Returns:
        Dict com: domains, facts_with_evidence, facts_with_multiple_sources,
                 high_confidence_facts, contradictions, total_evidence
    """
    if not facts_list or not isinstance(facts_list, list):
        return {
            "domains": set(),
            "facts_with_evidence": 0,
            "facts_with_multiple_sources": 0,
            "high_confidence_facts": 0,
            "contradictions": 0,
            "total_evidence": 0,
        }

    domains = set()
    facts_with_evidence = 0
    facts_with_multiple_sources = 0
    high_confidence_facts = 0
    contradictions = 0
    total_evidence = 0

    for fact in facts_list:
        if not isinstance(fact, dict):
            continue

        evidencias = fact.get("evidencias", [])
        if evidencias and len(evidencias) > 0:
            facts_with_evidence += 1
            total_evidence += len(evidencias)

            # Extrair dom√≠nios
            fact_domains = set()
            for ev in evidencias:
                if not isinstance(ev, dict):
                    continue
                try:
                    url = ev.get("url", "")
                    if url:
                        domain = url.split("/")[2]
                        domains.add(domain)
                        fact_domains.add(domain)
                except:
                    pass

            # Contar m√∫ltiplas fontes
            if len(fact_domains) >= 2:
                facts_with_multiple_sources += 1

        # Contar alta confian√ßa
        if fact.get("confian√ßa") == "alta":
            high_confidence_facts += 1

        # Contar contradi√ß√µes
        if fact.get("contradicao", False):
            contradictions += 1

    return {
        "domains": domains,
        "facts_with_evidence": facts_with_evidence,
        "facts_with_multiple_sources": facts_with_multiple_sources,
        "high_confidence_facts": high_confidence_facts,
        "contradictions": contradictions,
        "total_evidence": total_evidence,
    }


def _extract_phase_count(prompt: str) -> Optional[int]:
    if not prompt:
        return None
    patterns = [
        r"(?:com|use|em|fazer|faz)\s+(\d+)\s*(?:fases?|etapas?|passos?)",
        r"(\d+)\s*(?:fases?|etapas?|passos?)",
        r"(?:dividir|separar|organizar)\s+em\s+(\d+)",
        r"(?:primeiro|segundo|terceiro|quarto|quinto)",
    ]
    for pattern in patterns:
        match = re.search(pattern, prompt.lower())
        if match:
            try:
                if pattern == r"(?:primeiro|segundo|terceiro|quarto|quinto)":
                    # Count ordinal numbers
                    ordinals = ["primeiro", "segundo", "terceiro", "quarto", "quinto"]
                    count = 0
                    for ordinal in ordinals:
                        if ordinal in prompt.lower():
                            count += 1
                    if count >= 2:
                        return count
                else:
                    num = int(match.group(1))
                    if 2 <= num <= 10:
                        return num
            except:
                continue
    return None


def _render_contract(contract: Dict[str, Any]) -> str:
    fases = contract.get("fases", [])
    num_fases = len(fases)
    lines = [f"## üìã Plano ‚Äì {num_fases} Fases\n"]

    intent = contract.get("intent", "")
    if intent:
        lines.append(f"**üéØ Objetivo:** {intent}\n")

    # Mostrar entidades
    entities = contract.get("entities", {})
    if entities.get("canonical"):
        lines.append(f"**üè∑Ô∏è Entidades:** {', '.join(entities['canonical'])}")
        if entities.get("aliases"):
            lines.append(f"**üîó Aliases:** {', '.join(entities['aliases'])}")
        lines.append("")

    lines.append(f"**üìç Fases:**\n")
    for i, fase in enumerate(fases, 1):
        lines.append(f"### Fase {i}/{num_fases} ‚Äì {fase.get('name', 'N/A')}")
        lines.append(f"**Objetivo:** {fase.get('objetivo', 'N/A')}")
        # Exibir seed_core (query rica para Discovery) em vez de seed_query
        seed_core = fase.get("seed_core", "N/A")
        lines.append(f"**Seed Query:** `{seed_core}`")

        # Mostrar must/avoid terms
        must_terms = fase.get("must_terms", [])
        avoid_terms = fase.get("avoid_terms", [])
        if must_terms:
            lines.append(f"**‚úÖ Must:** {', '.join(must_terms)}")
        if avoid_terms:
            lines.append(f"**‚ùå Avoid:** {', '.join(avoid_terms)}")

        # Mostrar time hint e source bias
        time_hint = fase.get("time_hint", {})
        source_bias = fase.get("source_bias", [])
        if time_hint:
            lines.append(f"**‚è∞ Tempo:** {time_hint.get('recency', 'N/A')}")
        if source_bias:
            lines.append(f"**üìä Fontes:** {' > '.join(source_bias)}")

        lines.append("")

    # Mostrar quality rails
    quality_rails = contract.get("quality_rails", {})
    if quality_rails:
        lines.append("**üõ°Ô∏è Quality Rails:**")
        lines.append(
            f"- M√≠nimo {quality_rails.get('min_unique_domains', 'N/A')} dom√≠nios √∫nicos"
        )
        if quality_rails.get("need_official_or_two_independent"):
            lines.append("- Fonte oficial OU ‚â•2 dom√≠nios independentes por fase")
        lines.append("")

    lines.append("---")
    lines.append(f"**üí° Responda:** **siga** | **continue**")
    return "\n".join(lines)


# ===== LLM Components (from PipeHay3) =====
class AnalystLLM:
    """Analyst que processa contexto acumulado completo"""

    def __init__(self, valves):
        self.valves = valves
        # Usar modelo espec√≠fico se configurado, sen√£o usa modelo padr√£o
        model = valves.LLM_MODEL_ANALYST or valves.LLM_MODEL
        self.model_name = model
        self.llm = _get_llm(valves, model_name=model)
        # Base kwargs: ser√£o filtrados por get_safe_llm_params (GPT-5 n√£o aceita temperature)
        self.generation_kwargs = {"temperature": valves.LLM_TEMPERATURE}

    async def run(
        self, query: str, accumulated_context: str, phase_context: Dict = None
    ) -> Dict[str, Any]:
        """Analisa contexto acumulado COMPLETO (todas as fases at√© agora)"""

        # üî¥ DEFESA P0: Validar inputs e estado do LLM
        if not self.llm:
            logger.error("[ANALYST] LLM n√£o configurado")
            return {"summary": "", "facts": [], "lacunas": ["LLM n√£o configurado"]}

        if not accumulated_context or len(accumulated_context.strip()) == 0:
            logger.warning("[ANALYST] Contexto vazio - sem dados para analisar")
            return {
                "summary": "Sem contexto para analisar",
                "facts": [],
                "lacunas": ["Contexto vazio"],
            }

        try:
            # Extrair informa√ß√µes da fase atual
            phase_info = ""
            if phase_context:
                phase_name = phase_context.get("name", "Fase atual")
                # Contract usa "objetivo" (PT), n√£o "objective" (EN)
                phase_objective = phase_context.get("objetivo") or phase_context.get(
                    "objective", ""
                )
                phase_info = f"\n**FASE ATUAL:** {phase_name}\n**Objetivo da Fase:** {phase_objective}"

            sys_prompt = _build_analyst_prompt(query, phase_context)

            user_prompt = f"""**Objetivo da Fase:** {query}{phase_info}

**Contexto Acumulado (todas as fases at√© agora):**
{accumulated_context}"""

            timeout_analyst = min(self.valves.LLM_TIMEOUT_ANALYST, 120)  # Cap at 120s to prevent truncation
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[DEBUG][ANALYST] Using timeout: {timeout_analyst}s (context: {len(accumulated_context):,} chars)"
                )
            # Use retry function if enabled, otherwise single attempt
            # Filtrar par√¢metros incompat√≠veis com GPT-5/O1
            # ‚úÖ FORCE JSON MODE for Analyst robustness
            base_params = {
                "temperature": self.generation_kwargs.get("temperature", 0.2),
                "response_format": {"type": "json_object"}  # FORCE JSON MODE
            }
            safe_params = get_safe_llm_params(self.model_name, base_params)

            if getattr(self.valves, "ENABLE_LLM_RETRY", True):
                max_retries = int(getattr(self.valves, "LLM_MAX_RETRIES", 3) or 3)
                out = await _safe_llm_run_with_retry(
                    self.llm,
                    f"{sys_prompt}\n\n{user_prompt}",
                    safe_params,
                    timeout=timeout_analyst,
                    max_retries=max_retries,
                )
            else:
                out = await _safe_llm_run_with_retry(
                    self.llm,
                    f"{sys_prompt}\n\n{user_prompt}",
                    safe_params,
                    timeout=timeout_analyst,
                    max_retries=1,
                )

            if not out:
                return {"summary": "", "facts": [], "lacunas": []}

            raw_reply = out.get("replies", [""])[0] if out else ""
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[DEBUG][ANALYST] Analyst raw reply length: {len(raw_reply)} chars"
                )
                print(
                    f"[DEBUG][ANALYST] Analyst raw reply preview: {raw_reply[:200]}..."
                )

            # üîß FIX v2: Strip agressivo para remover \n " no in√≠cio (erro comum do LLM)
            cleaned_reply = raw_reply.strip()

            # Remover newlines e whitespace no in√≠cio recursivamente
            while cleaned_reply and cleaned_reply[0] in "\n\r\t ":
                cleaned_reply = cleaned_reply[1:]

            # Se come√ßa com " mas n√£o √© JSON v√°lido, remover aspas soltas
            if cleaned_reply.startswith('"') and not cleaned_reply.startswith('{"'):
                # Remover todas as aspas duplas consecutivas no in√≠cio
                cleaned_reply = cleaned_reply.lstrip('"').lstrip()

            # Se ainda n√£o come√ßa com { ou [, tentar envolver em objeto
            if (
                cleaned_reply
                and not cleaned_reply.startswith("{")
                and not cleaned_reply.startswith("[")
            ):
                # Caso especial: LLM retornou apenas os campos sem o envelope {}
                # Tentar envolver em chaves
                if '"summary"' in cleaned_reply or '"facts"' in cleaned_reply:
                    cleaned_reply = "{" + cleaned_reply + "}"
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            "[DEBUG][ANALYST] Wrapped response in {} (LLM forgot envelope)"
                        )

            # v4.4: Usar parse_json_resilient direto (modo balanced - m√°ximo esfor√ßo)
            parsed = parse_json_resilient(
                cleaned_reply, mode="balanced", allow_arrays=False
            )

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[DEBUG] Analyst parsed: {parsed is not None}")
                if parsed:
                    print(f"[DEBUG] Analyst parsed keys: {list(parsed.keys())}")
                    print(
                        f"[DEBUG] Analyst facts count before validation: {len(parsed.get('facts', []))}"
                    )
                else:
                    # Log o motivo da falha
                    print(
                        f"[DEBUG] Analyst parsing FAILED. Raw reply length: {len(raw_reply)}"
                    )
                    print(f"[DEBUG] First 500 chars: {raw_reply[:500]}")
                    print(f"[DEBUG] Last 500 chars: {raw_reply[-500:]}")

            # Se falhou, tentar com mode='soft' (apenas cleanup)
            if not parsed and raw_reply:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print("[DEBUG] Trying mode='soft' (cleanup only)...")
                parsed = parse_json_resilient(
                    raw_reply, mode="soft", allow_arrays=False
                )
                if parsed:
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print("[DEBUG] Analyst reparsed successfully with mode='soft'")

            # Re-ask √∫nico e curto exigindo JSON v√°lido
            try_reask = not parsed
            if try_reask:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        "[DEBUG] Analyst initial parse failed, re-asking with stricter JSON-only instructions..."
                    )

                reask_instr = (
                    "RETORNE APENAS JSON PURO (sem markdown, sem explica√ß√£o, sem texto extra).\n\n"
                    "SCHEMA OBRIGAT√ìRIO:\n"
                    "{\n"
                    '  "summary": "string resumo",\n'
                    '  "facts": [{ "texto": "fato X", "confian√ßa": "alta|m√©dia|baixa", "evidencias": [{"url":"...","trecho":"..."}] }],\n'
                    '  "lacunas": ["lacuna 1", "lacuna 2"],\n'
                    '  "self_assessment": { "coverage_score": 0.7, "confidence": "m√©dia", "gaps_critical": true, "suggest_refine": false, "suggest_pivot": true, "reasoning": "brevemente por qu√™" }\n'
                    "}\n\n"
                    "‚ö†Ô∏è IMPORTANTE:\n"
                    "- coverage_score: 0.0-1.0 (quanto % do objetivo foi coberto)\n"
                    "- gaps_critical: True se lacunas impedem resposta ao objetivo\n"
                    "- suggest_pivot: True se lacuna precisa de √¢ngulo/temporal diferente\n\n"
                    "N√ÉO adicione coment√°rios, N√ÉO use ```json, N√ÉO explique nada fora do JSON."
                )
                limited_context = accumulated_context[:20000]
                reask_prompt = f"{_build_analyst_prompt(query, phase_context)}\n\n{reask_instr}\n\n**Objetivo da Fase:** {query}{phase_info}\n\n**Contexto Acumulado:**\n{limited_context}"

                # For√ßar JSON response_format quando suportado (evitar para modelos que n√£o aceitam)
                base_reask = {"temperature": 0.1}
                if not any(x in self.model_name.lower() for x in ["o1", "o3", "gpt-5"]):
                    base_reask["response_format"] = {"type": "json_object"}
                safe_reask = get_safe_llm_params(self.model_name, base_reask)

                reask_out = await _safe_llm_run_with_retry(
                    self.llm,
                    reask_prompt,
                    safe_reask,
                    timeout=timeout_analyst,
                    max_retries=1,
                )
                re_raw = reask_out.get("replies", [""])[0] if reask_out else ""

                # Parse estrito primeiro; se falhar, tentar balanced
                reparsed = parse_json_resilient(
                    re_raw, mode="strict", allow_arrays=False
                )
                if not reparsed and re_raw:
                    reparsed = parse_json_resilient(
                        re_raw, mode="balanced", allow_arrays=False
                    )
                if reparsed:
                    parsed = reparsed
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print("[DEBUG] Analyst parsed successfully on re-ask")

            # Valida√ß√£o de evid√™ncia rica (P0.4) - TEMPORARIAMENTE RELAXADA PARA DEBUG
            if parsed:
                facts_before_validation = parsed.get("facts", [])
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG] Facts before validation: {len(facts_before_validation)}"
                    )

                # Log detalhado de cada fato antes da valida√ß√£o
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    for i, fact in enumerate(facts_before_validation[:3]):
                        print(f"[DEBUG] Fact {i}: {fact}")

                validated = self._validate_analyst_output(parsed)
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEBUG] Analyst validation result: {validated}")

                if not validated["valid"]:
                    # v4.6: Valida√ß√£o RE-HABILITADA (era temporariamente relaxada para debug)
                    logger.warning(f"[ANALYST] Output inv√°lido: {validated['reason']}")
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[WARNING] Analyst output invalid: {validated['reason']}"
                        )
                    # Retornar output vazio com lacuna explicativa
                    return {
                        "summary": "",
                        "facts": [],
                        "lacunas": [validated["reason"]],
                    }

        except Exception as e:
            logger.error(f"[ANALYST] Exce√ß√£o n√£o tratada: {e}")
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                import traceback

                traceback.print_exc()
            return {
                "summary": "",
                "facts": [],
                "lacunas": [f"Erro interno: {str(e)[:100]}"],
            }

        return parsed or {"summary": "", "facts": [], "lacunas": []}

    def _validate_analyst_output(self, parsed):
        """Valida sa√≠da do Analyst - VERS√ÉO COMPLETA RE-HABILITADA (v4.6)

        Valida√ß√µes:
        1. Facts s√£o dicts com campos obrigat√≥rios
        2. Evid√™ncias t√™m URL v√°lida
        3. Self-assessment presente e bem-formado
        """
        facts = parsed.get("facts", [])

        # Sem fatos √© v√°lido (vai para lacunas)
        if not facts:
            return {"valid": True}

        # Valida√ß√£o de estrutura dos fatos
        for i, fact in enumerate(facts):
            if not isinstance(fact, dict):
                return {"valid": False, "reason": f"Fato {i} n√£o √© dict"}

            # Campos obrigat√≥rios
            if "texto" not in fact:
                return {"valid": False, "reason": f"Fato {i} sem campo 'texto'"}

            if not fact.get("texto") or not fact["texto"].strip():
                return {"valid": False, "reason": f"Fato {i} com texto vazio"}

            # Confian√ßa obrigat√≥ria
            if "confian√ßa" not in fact:
                return {"valid": False, "reason": f"Fato {i} sem campo 'confian√ßa'"}

            if fact["confian√ßa"] not in ["alta", "m√©dia", "baixa"]:
                return {
                    "valid": False,
                    "reason": f"Fato {i} com confian√ßa inv√°lida: {fact['confian√ßa']}",
                }

            # Evid√™ncias (opcional mas recomendado)
            evidencias = fact.get("evidencias", [])
            if evidencias:
                for j, ev in enumerate(evidencias):
                    if not isinstance(ev, dict):
                        return {
                            "valid": False,
                            "reason": f"Fato {i}, evid√™ncia {j} n√£o √© dict",
                        }

                    if "url" not in ev:
                        return {
                            "valid": False,
                            "reason": f"Fato {i}, evid√™ncia {j} sem URL",
                        }

        # Valida√ß√£o de self_assessment (obrigat√≥rio)
        sa = parsed.get("self_assessment", {})
        if not sa:
            return {"valid": False, "reason": "self_assessment ausente"}

        # Campos obrigat√≥rios de self_assessment
        required_sa_fields = ["coverage_score", "confidence", "gaps_critical"]
        for field in required_sa_fields:
            if field not in sa:
                return {
                    "valid": False,
                    "reason": f"self_assessment sem campo '{field}'",
                }

        # Validar coverage_score range
        coverage = sa.get("coverage_score")
        if not isinstance(coverage, (int, float)) or not (0.0 <= coverage <= 1.0):
            return {
                "valid": False,
                "reason": f"coverage_score inv√°lido: {coverage} (deve ser 0.0-1.0)",
            }

        # Validar confidence
        if sa.get("confidence") not in ["alta", "m√©dia", "baixa"]:
            return {
                "valid": False,
                "reason": f"confidence inv√°lida: {sa.get('confidence')}",
            }

        # Validar gaps_critical
        if not isinstance(sa.get("gaps_critical"), bool):
            return {
                "valid": False,
                "reason": f"gaps_critical deve ser bool, got {type(sa.get('gaps_critical'))}",
            }

        return {"valid": True}


class JudgeLLM:
    def __init__(self, valves):
        self.valves = valves
        # Usar modelo espec√≠fico se configurado, sen√£o usa modelo padr√£o
        model = valves.LLM_MODEL_JUDGE or valves.LLM_MODEL
        self.model_name = model
        self.llm = _get_llm(valves, model_name=model)
        # Base kwargs: ser√£o filtrados por get_safe_llm_params (GPT-5 n√£o aceita temperature)
        self.generation_kwargs = {"temperature": 0.3}

    def _calculate_phase_score(self, metrics: Dict[str, float]) -> float:
        """Calcula phase_score audit√°vel usando pesos configur√°veis (v4.7)

        F√≥rmula:
        phase_score = w_cov * coverage
                    + w_nf * novel_fact_ratio
                    + w_nd * novel_domain_ratio
                    + w_div * domain_diversity
                    - w_contra * contradiction_score

        Args:
            metrics: Dict com coverage, novel_fact_ratio, novel_domain_ratio,
                    domain_diversity, contradiction_score

        Returns:
            Score normalizado 0.0-1.0 (pode ser negativo se contradi√ß√µes altas)
        """
        weights = getattr(
            self.valves,
            "PHASE_SCORE_WEIGHTS",
            {
                "w_cov": 0.35,
                "w_nf": 0.25,
                "w_nd": 0.15,
                "w_div": 0.15,
                "w_contra": 0.40,
            },
        )

        coverage = metrics.get("coverage", 0.0)
        novel_fact_ratio = metrics.get("novel_fact_ratio", 0.0)
        novel_domain_ratio = metrics.get("novel_domain_ratio", 0.0)
        domain_diversity = metrics.get("domain_diversity", 0.0)
        contradiction_score = metrics.get("contradiction_score", 0.0)

        score = (
            weights["w_cov"] * coverage
            + weights["w_nf"] * novel_fact_ratio
            + weights["w_nd"] * novel_domain_ratio
            + weights["w_div"] * domain_diversity
            - weights["w_contra"] * contradiction_score
        )

        return round(score, 3)

    def _switch_seed_family(self, current_family: str) -> str:
        """Troca fam√≠lia de seed para explora√ß√£o sistem√°tica (v4.7)

        Ciclo: entity-centric ‚Üí problem-centric ‚Üí outcome-centric ‚Üí regulatory ‚Üí counterfactual ‚Üí entity-centric

        Args:
            current_family: Fam√≠lia atual

        Returns:
            Pr√≥xima fam√≠lia no ciclo
        """
        family_order = [
            "entity-centric",
            "problem-centric",
            "outcome-centric",
            "regulatory",
            "counterfactual",
        ]

        try:
            idx = family_order.index(current_family)
            next_idx = (idx + 1) % len(family_order)
            return family_order[next_idx]
        except ValueError:
            # Fam√≠lia desconhecida, retornar default
            return "problem-centric"  # Primeira alternativa ao entity-centric

    async def run(
        self,
        user_prompt: str,
        analysis: Dict[str, Any],
        phase_context: Dict[str, Any] = None,
        telemetry_loops: Optional[List[Dict[str, Any]]] = None,
        intent_profile: Optional[str] = None,
        full_contract: Optional[Dict] = None,
        valves=None,
        refine_queries: Optional[List[Dict]] = None,
        phase_candidates: Optional[List[Dict]] = None,
        previous_queries: Optional[List[str]] = None,  # ‚Üê NEW
        failed_queries: Optional[List[str]] = None,  # ‚Üê WIN #3: Failed queries context
    ) -> Dict[str, Any]:
        if not self.llm:
            raise ValueError("LLM n√£o configurado")

        phase_info = ""
        if phase_context:
            phase_info = f"\n**Crit√©rios:** {', '.join(phase_context.get('accept_if_any_of', []))}"

        prompt = _build_judge_prompt(
            user_prompt,
            analysis,
            phase_context,
            telemetry_loops,
            intent_profile,
            full_contract,
            refine_queries=refine_queries,
            phase_candidates=phase_candidates,
            previous_queries=previous_queries,
            failed_queries=failed_queries,  # ‚Üê WIN #3: Pass failed queries
        )

        # Filtrar par√¢metros incompat√≠veis com GPT-5/O1
        safe_params = get_safe_llm_params(self.model_name, self.generation_kwargs)

        # Use retry function if enabled, otherwise single attempt
        if getattr(self.valves, "ENABLE_LLM_RETRY", True):
            max_retries = int(getattr(self.valves, "LLM_MAX_RETRIES", 3) or 3)
            out = await _safe_llm_run_with_retry(
                self.llm,
                prompt,
                safe_params,
                timeout=self.valves.LLM_TIMEOUT_DEFAULT,
                max_retries=max_retries,
            )
        else:
            out = await _safe_llm_run_with_retry(
                self.llm,
                prompt,
                safe_params,
                timeout=self.valves.LLM_TIMEOUT_DEFAULT,
                max_retries=1,
            )
        if not out:
            raise RuntimeError("Judge failed")

        parsed = _extract_json_from_text(out.get("replies", [""])[0])
        if not parsed:
            raise ValueError("Judge output inv√°lido")

        # ===== JUDGE ENXUTO: 3 SINAIS AUTOM√ÅTICOS, 3 REGRAS MECE =====
        # Filosofia: Gen√©rico, sem thresholds manuais, sem whitelists

        # SINAL 1: Lacunas expl√≠citas (do Analyst)
        has_lacunas = bool(analysis.get("lacunas"))

        # SINAL 2: Tra√ß√£o (crescimento absoluto em dom√≠nios OU fatos)
        traction = True  # Default para primeiro loop
        if telemetry_loops and len(telemetry_loops) >= 2:
            last = telemetry_loops[-1]
            prev = telemetry_loops[-2]
            delta_domains = last.get("unique_domains", 0) - prev.get(
                "unique_domains", 0
            )
            
            # ‚úÖ WIN #2: Weight traction by fact confidence instead of simple count
            delta_facts = self._calculate_weighted_fact_delta(analysis)
            traction = (delta_domains > 0) or (delta_facts > 0)

        # SINAL 3: Dois loops flat consecutivos (histerese)
        two_flat_loops = False
        if telemetry_loops and len(telemetry_loops) >= 3:
            last = telemetry_loops[-1]
            prev = telemetry_loops[-2]
            prev_prev = telemetry_loops[-3]

            # √öltimo loop flat?
            delta_d_last = last.get("unique_domains", 0) - prev.get("unique_domains", 0)
            delta_f_last = last.get("n_facts", 0) - prev.get("n_facts", 0)
            last_flat = (delta_d_last == 0) and (delta_f_last == 0)

            # Pen√∫ltimo loop flat?
            delta_d_prev = prev.get("unique_domains", 0) - prev_prev.get(
                "unique_domains", 0
            )
            delta_f_prev = prev.get("n_facts", 0) - prev_prev.get("n_facts", 0)
            prev_flat = (delta_d_prev == 0) and (delta_f_prev == 0)

            two_flat_loops = last_flat and prev_flat

        # SINAL 4: Key Questions Status (do LLM Judge, n√£o heur√≠stica)
        # Judge LLM avalia: coverage, blind_spots, se descobertas invalidam hip√≥teses
        key_questions_coverage = 1.0  # Default: 100%
        blind_spots = []

        # Extrair key_questions_status do JSON do Judge (se dispon√≠vel)
        kq_status = parsed.get("key_questions_status", {})
        if kq_status:
            key_questions_coverage = float(kq_status.get("coverage", 1.0))
            blind_spots = kq_status.get("blind_spots", [])

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                answered = kq_status.get("answered", [])
                unanswered = kq_status.get("unanswered", [])
                print(
                    f"[DEBUG][JUDGE] Key Questions Coverage: {key_questions_coverage:.2f} ({len(answered)} answered, {len(unanswered)} unanswered)"
                )
                if blind_spots:
                    print(f"[DEBUG][JUDGE] Blind Spots detectados: {blind_spots[:3]}")

        # SINAL 5: Blind Spots Cr√≠ticos (descobertas que invalidam hip√≥teses)
        # SINAL 5: Blind Spots (telemetria, n√£o override)
        # Se Judge detectou blind_spots ‚Üí sinal de que hip√≥teses desviaram
        # O Judge LLM decide se s√£o cr√≠ticos ou apenas lacunas normais
        loops = len(telemetry_loops) if telemetry_loops else 0
        blind_spots_signal = bool(blind_spots) and (
            loops >= 1 or len(blind_spots) >= 3
        )

        # ===== v4.7: CALCULAR PHASE_SCORE AUDIT√ÅVEL =====
        # Coletar m√©tricas necess√°rias para o score
        facts = analysis.get("facts", [])
        lacunas = analysis.get("lacunas", [])

        # M√©tricas de telemetria (√∫ltima itera√ß√£o)
        last_loop = telemetry_loops[-1] if telemetry_loops else {}
        novel_fact_ratio = last_loop.get("new_facts_ratio", 0.0)
        novel_domain_ratio = last_loop.get("new_domains_ratio", 0.0)
        unique_domains = last_loop.get("unique_domains", 0)

        # Calcular domain_diversity (Herfindahl invertido ou simples ratio)
        # Simplifica√ß√£o: usar unique_domains / facts como proxy
        domain_diversity = (
            min(1.0, unique_domains / max(len(facts), 1)) if facts else 0.0
        )

        # Calcular contradiction_score (do Analyst ou telemetria)
        sa = analysis.get("self_assessment", {})
        contradiction_score = 0.0
        try:
            # Se Analyst reportou contradi√ß√µes, usar como score
            contradictions_count = last_loop.get("contradictions", 0)
            if contradictions_count > 0:
                contradiction_score = min(
                    1.0, contradictions_count / max(len(facts), 1)
                )
        except Exception:
            pass

        # Montar dict de m√©tricas para phase_score
        phase_metrics = {
            "coverage": key_questions_coverage,  # Do LLM Judge
            "novel_fact_ratio": novel_fact_ratio,
            "novel_domain_ratio": novel_domain_ratio,
            "domain_diversity": domain_diversity,
            "contradiction_score": contradiction_score,
            "loops_without_gain": 2 if two_flat_loops else (0 if traction else 1),
        }

        # Calcular phase_score
        phase_score = self._calculate_phase_score(phase_metrics)

        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[JUDGE][SCORE] phase_score={phase_score:.3f}")
            print(
                f"[JUDGE][SCORE] M√©tricas: coverage={key_questions_coverage:.2f}, novel_facts={novel_fact_ratio:.2f}, novel_domains={novel_domain_ratio:.2f}, diversity={domain_diversity:.2f}, contradictions={contradiction_score:.2f}"
            )

        # Obter gates do perfil/phase_type
        phase_type = (
            phase_context.get("phase_type", "industry") if phase_context else "industry"
        )
        gates = getattr(self.valves, "GATES_BY_PROFILE", {}).get(
            phase_type, {"threshold": 0.60, "two_flat_loops": 2}
        )
        threshold = gates.get("threshold", 0.60)
        required_flat_loops = gates.get("two_flat_loops", 2)

        # Calcular flat_streak (quantos loops consecutivos sem ganho)
        flat_streak = 0
        if telemetry_loops and len(telemetry_loops) >= 2:
            for i in range(len(telemetry_loops) - 1, 0, -1):
                curr = telemetry_loops[i]
                prev = telemetry_loops[i - 1]
                delta_d = curr.get("unique_domains", 0) - prev.get("unique_domains", 0)
                delta_f = curr.get("n_facts", 0) - prev.get("n_facts", 0)
                if delta_d == 0 and delta_f == 0:
                    flat_streak += 1
                else:
                    break

        # Calcular overlap_similarity (similaridade entre fatos desta fase vs anteriores)
        # Simplifica√ß√£o: usar novel_fact_ratio invertido como proxy
        overlap_similarity = 1.0 - novel_fact_ratio if novel_fact_ratio > 0 else 0.0

        # ===== DECIS√ÉO PROGRAM√ÅTICA BASEADA EM PHASE_SCORE (v4.7) =====
        programmatic_decision = {}
        seed_family_switch = None

        # ‚úÖ Reaproveitar new_phase do Judge LLM (se dispon√≠vel)
        judge_new_phase = parsed.get("new_phase", {})

        # ===== SAFETY RAILS (prioridade m√°xima, sobrescrevem score) =====

        # Rail 1: Contradi√ß√µes cr√≠ticas ‚Üí NEW_PHASE imediato com seed_family switch
        contradiction_hard_gate = getattr(self.valves, "CONTRADICTION_HARD_GATE", 0.75)
        if contradiction_score >= contradiction_hard_gate:
            current_family = (
                phase_context.get("seed_family_hint", "entity-centric")
                if phase_context
                else "entity-centric"
            )
            seed_family_switch = self._switch_seed_family(current_family)
            programmatic_decision = {
                "verdict": "new_phase",
                "reasoning": f"Contradi√ß√µes cr√≠ticas ({contradiction_score:.2f} ‚â• {contradiction_hard_gate}). Trocar √¢ngulo",
                "seed_family": seed_family_switch,
            }
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[JUDGE][RAIL] Contradi√ß√µes cr√≠ticas: {current_family} ‚Üí {seed_family_switch}"
                )

        # Rail 2: Duplica√ß√£o alta (overlap ‚â• 0.90) ‚Üí REFINE
        elif overlap_similarity >= 0.90:
            programmatic_decision = {
                "verdict": "refine",
                "reasoning": f"Overlap muito alto ({overlap_similarity:.2f}). Refinar busca",
            }

        # ===== REGRAS MECE BASEADAS EM PHASE_SCORE (v4.7) =====

        # Regra 1: Score BOM + coverage OK ‚Üí DONE
        elif (
            phase_score >= threshold
            and key_questions_coverage >= getattr(self.valves, "COVERAGE_TARGET", 0.70)
        ):
            programmatic_decision = {
                "verdict": "done",
                "reasoning": f"Phase score {phase_score:.2f} ‚â• {threshold:.2f}, coverage {key_questions_coverage*100:.0f}% OK",
            }

        # Regra 2: Score BAIXO + flat_streak atingido ‚Üí NEW_PHASE com seed_family switch
        elif phase_score < threshold and flat_streak >= required_flat_loops:
            current_family = (
                phase_context.get("seed_family_hint", "entity-centric")
                if phase_context
                else "entity-centric"
            )
            seed_family_switch = self._switch_seed_family(current_family)
            programmatic_decision = {
                "verdict": "new_phase",
                "reasoning": f"Phase score {phase_score:.2f} < {threshold:.2f} ap√≥s {flat_streak} loops flat. Trocar fam√≠lia de explora√ß√£o",
                "seed_family": seed_family_switch,
            }
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[JUDGE][SWITCH] Score baixo + flat: {current_family} ‚Üí {seed_family_switch}"
                )

        # Regra 3: Score BAIXO mas ainda h√° tra√ß√£o ‚Üí REFINE
        elif phase_score < threshold and traction:
            programmatic_decision = {
                "verdict": "refine",
                "reasoning": f"Phase score {phase_score:.2f} < {threshold:.2f} mas h√° tra√ß√£o. Refinar",
            }

        # Regra 4 (REMOVIDA): Blind spots agora s√£o soft signal para Judge LLM
        # O Judge j√° recebe blind_spots no prompt e decide se justificam NEW_PHASE
        # Manter apenas log de telemetria

        # Fallback: REFINE (caso n√£o se encaixe em nenhuma regra acima)
        else:
            programmatic_decision = {
                "verdict": "refine",
                "reasoning": f"Score {phase_score:.2f}, coverage {key_questions_coverage*100:.0f}%. Continuar refinando",
            }

        # ===== CRIAR NEW_PHASE OBJECT SE NECESS√ÅRIO (v4.7) =====
        # Se decis√£o for NEW_PHASE, garantir que temos um new_phase object
        if programmatic_decision.get("verdict") == "new_phase":
            # Priorizar new_phase do Judge LLM (mais sem√¢ntico)
            if not judge_new_phase or not judge_new_phase.get("objective"):
                # Fallback: gerar programaticamente baseado em lacunas/blind_spots
                lacunas_list = analysis.get("lacunas", [])

                if blind_spots_signal and blind_spots:
                    # Transform negative blind_spot into positive query
                    first_bs = blind_spots[0]
                    # Remove "Aus√™ncia de", "Falta", "N√£o encontrado" patterns
                    import re
                    positive_query = re.sub(
                        r'^(Aus√™ncia de|Falta|N√£o encontr(ou|ado|ada)|Sem)\s+', 
                        '', 
                        first_bs, 
                        flags=re.IGNORECASE
                    )
                    
                    judge_new_phase = {
                        "objective": f"Buscar informa√ß√µes sobre: {positive_query[:80]}",
                        "seed_query": " ".join(positive_query.split()[:6]),
                        "name": "Descobertas Inesperadas",
                        "por_que": f"Blind spots: {'; '.join(blind_spots[:2])}",
                    }
                elif lacunas_list:
                    # Baseado em lacunas
                    lacunas_sample = lacunas_list[:2]
                    # P0: lacunas_list pode ser lista de dicts ou strings
                    lacunas_text = []
                    for lac in lacunas_sample:
                        if isinstance(lac, dict):
                            lacunas_text.append(lac.get("descricao", str(lac)))
                        else:
                            lacunas_text.append(str(lac))
                    first_lacuna = lacunas_text[0] if lacunas_text else "busca dirigida"
                    judge_new_phase = {
                        "objective": f"Busca dirigida para lacunas: {'; '.join(lacunas_text)}",
                        "seed_query": " ".join(first_lacuna.split()[:6]),
                        "name": "Busca Dirigida - Lacunas Essenciais",
                        "por_que": f"Lacunas persistem ap√≥s {flat_streak} loops flat",
                    }
                else:
                    # Fallback gen√©rico
                    judge_new_phase = {
                        "objective": f"Explora√ß√£o alternativa: {user_prompt[:60]}",
                        "seed_query": " ".join(user_prompt.split()[:6]),
                        "name": "Explora√ß√£o Alternativa",
                        "por_que": f"Score {phase_score:.2f} < threshold ap√≥s {flat_streak} loops",
                    }

            # Adicionar seed_family ao new_phase se foi calculado
            if seed_family_switch:
                judge_new_phase["seed_family_hint"] = seed_family_switch
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[JUDGE] NEW_PHASE com fam√≠lia: {seed_family_switch}")

            # Atualizar programmatic_decision com new_phase completo
            programmatic_decision["new_phase"] = judge_new_phase

        # Aplicar rails de qualidade program√°ticos
        verdict = parsed.get("verdict", "done").strip()
        reasoning = parsed.get("reasoning", "").strip()
        next_query = parsed.get("next_query", "").strip()

        # Salvar decis√£o original do Judge para compara√ß√£o
        original_verdict = verdict
        original_reasoning = reasoning
        modifications = []

        # ‚úÖ P2: Detectar duplica√ß√£o de new_phase ANTES de aplicar override
        if programmatic_decision.get("verdict") == "new_phase":
            proposed_new_phase = programmatic_decision.get("new_phase", {})
            duplicate_detected = False

            if proposed_new_phase and full_contract and full_contract.get("fases"):
                # ‚úÖ CORE FIX: Multi-dimensional similarity comparison
                try:
                    from sklearn.feature_extraction.text import TfidfVectorizer
                    from sklearn.metrics.pairwise import cosine_similarity

                    new_obj = proposed_new_phase.get("objective", "")
                    new_seed = proposed_new_phase.get("seed_query", "")
                    new_type = proposed_new_phase.get("phase_type", "")
                    
                    existing_phases = full_contract.get("fases", [])
                    
                    if new_obj and existing_phases:
                        # Calculate multi-dimensional similarity
                        max_weighted_score, max_sim_idx = self._calculate_multi_dimensional_similarity(
                            new_obj, new_seed, new_type, existing_phases
                        )

                        if max_weighted_score > self.valves.DUPLICATE_DETECTION_THRESHOLD:
                            duplicate_phase = existing_phases[max_sim_idx]
                            duplicate_detected = True

                            # Converter NEW_PHASE ‚Üí REFINE (fase j√° existe)
                            logger.warning(
                                f"[JUDGE] Fase duplicada detectada (similaridade {max_weighted_score:.2f}): '{duplicate_phase.get('name', 'N/A')}'"
                            )
                            modifications.append(
                                f"Duplicate phase: new_phase ‚Üí refine (similaridade {max_weighted_score:.2f} com '{duplicate_phase.get('name', 'N/A')}')"
                            )

                            # Usar seed do new_phase proposto como next_query para refine
                            programmatic_decision = {
                                "verdict": "refine",
                                "reasoning": f"[AUTO-CORRE√á√ÉO] Fase proposta duplica '{duplicate_phase.get('name', 'fase existente')}'. Convertido para refine.",
                                "next_query": proposed_new_phase.get("seed_query", ""),
                            }

                            if getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(
                                    f"[JUDGE] NEW_PHASE bloqueado por duplica√ß√£o: '{new_obj[:60]}...'"
                                )
                                print(
                                    f"[JUDGE] Duplica fase existente: '{duplicate_phase.get('objetivo', 'N/A')[:60]}...'"
                                )
                                print(
                                    f"[JUDGE] Convertido para REFINE com seed: '{proposed_new_phase.get('seed_query', '')}'"
                                )

                except Exception as e:
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[JUDGE] Erro na detec√ß√£o de duplica√ß√£o (continuando sem check): {e}"
                        )

        # Se decis√£o program√°tica for diferente de "done", usar ela (tem prioridade)
        if (
            programmatic_decision.get("verdict")
            and programmatic_decision["verdict"] != "done"
        ):
            modifications.append(
                f"Programmatic override: {original_verdict} ‚Üí {programmatic_decision['verdict']}"
            )
            verdict = programmatic_decision["verdict"]
            reasoning = programmatic_decision["reasoning"]
            next_query = programmatic_decision.get("next_query", next_query)

        # üîí CONSISTENCY CHECK: Reasoning vs Verdict (3 camadas)

        # Camada 1: Lacunas expl√≠citas do Analyst
        if verdict == "done" and has_lacunas:
            logger.warning(
                f"[JUDGE] Inconsist√™ncia: verdict=done mas {len(analysis.get('lacunas', []))} lacunas no Analyst"
            )
            modifications.append(
                f"Consistency check: done ‚Üí refine ({len(analysis.get('lacunas', []))} lacunas encontradas)"
            )
            verdict = "refine"
            reasoning = f"[AUTO-CORRE√á√ÉO] Lacunas detectadas pelo Analyst. {reasoning}"
            # Query focada nas lacunas
            lacunas = analysis.get("lacunas", [])
            if lacunas and not next_query:
                # P0: lacunas pode ser lista de dicts ou strings
                first_lacuna = lacunas[0]
                if isinstance(first_lacuna, dict):
                    lacuna_text = first_lacuna.get("descricao", "")
                else:
                    lacuna_text = str(first_lacuna)
                lacuna_sample = " ".join(lacuna_text.split()[:8]) if lacuna_text else ""
                next_query = (
                    lacuna_sample
                    or f"dados verific√°veis {phase_context.get('objetivo', '')[:30]}"
                )

        # Camada 2: Key_questions coverage baixa (hip√≥teses n√£o respondidas)
        if verdict == "done" and key_questions_coverage < 0.70:
            logger.warning(
                f"[JUDGE] Inconsist√™ncia: verdict=done mas key_questions coverage={key_questions_coverage:.2f} < 0.70"
            )
            modifications.append(
                f"Consistency check: done ‚Üí refine (key_questions coverage {key_questions_coverage*100:.0f}% < 70%)"
            )
            verdict = "refine"
            reasoning = f"[AUTO-CORRE√á√ÉO] {key_questions_coverage*100:.0f}% das key_questions relevantes respondidas (< 70%). {reasoning}"

        # Camada 3: Blind Spots cr√≠ticos (descobertas que mudam contexto)
        # APENAS corrige DONE ‚Üí NEW_PHASE se Judge errou ao ignorar blind spots cr√≠ticos
        if verdict == "done" and blind_spots_signal:
            logger.warning(
                f"[JUDGE] Inconsist√™ncia: verdict=done mas {len(blind_spots)} blind_spots cr√≠ticos detectados"
            )
            modifications.append(
                f"Consistency check: done ‚Üí new_phase ({len(blind_spots)} blind_spots cr√≠ticos)"
            )
            verdict = "new_phase"
            reasoning = f"[AUTO-CORRE√á√ÉO] Blind spots cr√≠ticos invalidam hip√≥teses iniciais: {'; '.join(blind_spots[:2])}. {reasoning}"
            # Criar proposta de nova fase se n√£o existe
            if not parsed.get("new_phase"):
                parsed["new_phase"] = {
                    "objective": f"Explorar descobertas inesperadas: {blind_spots[0][:80]}",
                    "seed_query": " ".join(blind_spots[0].split()[:6]),
                    "name": "Descobertas Inesperadas",
                    "por_que": f"Blind spots cr√≠ticos detectados: {'; '.join(blind_spots[:2])}",
                }

        # Incluir nova fase se foi criada programaticamente
        new_phase = parsed.get("new_phase", {})
        if programmatic_decision.get("new_phase"):
            new_phase = programmatic_decision["new_phase"]
        
        # ===== NOVO: Rotacionar fam√≠lia de explora√ß√£o entre loops (P0 - Missing Feature) =====
        if verdict == "new_phase" and new_phase:
            # Contar loops para determinar se deve rotacionar fam√≠lia
            loop_number = len(telemetry_loops) if telemetry_loops else 0
            
            # Rotacionar fam√≠lia apenas a partir do loop 2 (terceira itera√ß√£o)
            if loop_number >= 2:
                current_family = phase_context.get("seed_family_hint", "entity-centric") if phase_context else "entity-centric"
                
                # Mapeamento de rota√ß√£o de fam√≠lias
                family_rotation = {
                    "entity-centric": "problem-centric",
                    "problem-centric": "outcome-centric", 
                    "outcome-centric": "regulatory",
                    "regulatory": "entity-centric"
                }
                
                new_family = family_rotation.get(current_family, "problem-centric")
                
                # Adicionar seed_family_hint ao new_phase
                if isinstance(new_phase, dict):
                    new_phase["seed_family_hint"] = new_family
                    
                    # Atualizar reasoning para incluir mudan√ßa de fam√≠lia
                    if "reasoning" in new_phase:
                        new_phase["reasoning"] += f" Mudan√ßa de fam√≠lia: {current_family} ‚Üí {new_family}"
                    else:
                        new_phase["reasoning"] = f"Mudan√ßa de fam√≠lia: {current_family} ‚Üí {new_family}"
                
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[JUDGE] Rota√ß√£o de fam√≠lia: {current_family} ‚Üí {new_family} (loop {loop_number})")

        # QUICK WIN #2 (v4.5.2): Validar similaridade de next_query (anti-duplica√ß√£o)
        if verdict == "refine" and next_query and telemetry_loops:
            # Extrair queries j√° usadas do telemetry
            used_queries = []
            for loop in telemetry_loops:
                q = loop.get("query", "").strip().lower()
                if q:
                    used_queries.append(q)

            # Verificar similaridade com queries anteriores
            from difflib import SequenceMatcher

            next_lower = next_query.strip().lower()

            for used in used_queries:
                similarity = SequenceMatcher(None, next_lower, used).ratio()
                if similarity > 0.7:
                    # Query muito similar ‚Üí problema
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[WARNING][JUDGE] next_query muito similar √† query anterior: {similarity:.2%} similaridade"
                        )
                        print(f"[WARNING][JUDGE] Anterior: '{used}'")
                        print(f"[WARNING][JUDGE] Nova: '{next_lower}'")

                    # For√ßar DONE ao inv√©s de REFINE com query duplicada
                    # Melhor parar do que repetir busca id√™ntica
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[JUDGE] Convertendo REFINE ‚Üí DONE (query duplicada n√£o agrega valor)"
                        )

                    verdict = "done"
                    reasoning = f"[AUTO-CORRE√á√ÉO] Query proposta muito similar √† anterior ({similarity:.0%}). Parando para evitar repeti√ß√£o in√∫til."
                    next_query = ""
                    break

        # üìä FASE 1: Log JSON do Judge (observabilidade/auditoria)
        decision = {
            "decision": verdict,
            "reason": reasoning,
            "coverage": phase_metrics.get("coverage", 0),
            "domains": len(phase_metrics.get("domains", set())),
            "evidence": phase_metrics.get("evidence_coverage", 0),
            "staleness_ok": True,  # TODO: implementar staleness check se necess√°rio
            "loops": f"{len(telemetry_loops) if telemetry_loops else 0}/{getattr(self.valves, 'MAX_AGENT_LOOPS', 2)}",
        }
        logger.info(f"[JUDGE]{json.dumps(decision, ensure_ascii=False)}")

        return {
            "reasoning": reasoning,
            "verdict": verdict,
            "next_query": next_query,
            "refine": parsed.get("refine", {}),
            "new_phase": new_phase,
            "unexpected_findings": parsed.get("unexpected_findings", []),
            "proposed_phase": new_phase,  # Para compatibilidade
            # ‚úÖ v4.7: M√©tricas audit√°veis
            "phase_score": phase_score,
            "phase_metrics": phase_metrics,
            "seed_family": seed_family_switch,  # Presente apenas se NEW_PHASE por explora√ß√£o
            "modifications": modifications,  # Lista de modifica√ß√µes aplicadas
        }

    def _validate_quality_rails(
        self, analysis, phase_context, intent_profile: Optional[str] = None
    ):
        """Gates M√çNIMOS - apenas safety net para casos extremos

        REBALANCED (v4.5.1): Reduzido de 6 gates r√≠gidos para 2 gates m√≠nimos
        Filosofia: Prompts guiam, gates alertam casos extremos
        """
        facts = analysis.get("facts", [])

        # Gate 1: ZERO fatos (caso extremo √≥bvio)
        if not facts:
            return {
                "passed": False,
                "reason": "Sem fatos encontrados - imposs√≠vel responder ao objetivo",
                "suggested_query": "buscar fontes espec√≠ficas e verific√°veis",
            }

        # Gate 2: Combina√ß√£o de problemas (evid√™ncia fraca + coverage baixo)
        # Apenas bloqueia quando AMBOS s√£o muito baixos
        metrics = _extract_quality_metrics(facts)
        evidence_coverage = metrics["facts_with_evidence"] / len(facts) if facts else 0
        coverage_score = analysis.get("self_assessment", {}).get("coverage_score", 0)

        # NOVO THRESHOLD: 50% evid√™ncia + 50% coverage (muito mais permissivo)
        if evidence_coverage < 0.5 and coverage_score < 0.5:
            return {
                "passed": False,
                "reason": f"Qualidade muito baixa: {evidence_coverage*100:.0f}% evid√™ncia + {coverage_score*100:.0f}% coverage (ambos <50%)",
                "suggested_query": "buscar fontes com dados espec√≠ficos e verific√°veis",
            }

        # REMOVIDO: Gate de 100% evid√™ncia obrigat√≥rio (muito r√≠gido)
        # REMOVIDO: Gate de "qualquer lacuna = falha" (pessimista demais)
        # REMOVIDO: Gate de diversidade m√≠nima de dom√≠nios (n√£o √© cr√≠tico)
        # REMOVIDO: Gate de oficial_or_two obrigat√≥rio (Judge decide melhor)
        # MANTIDO: Staleness check (apenas quando strict=True no perfil)

        # Verificar staleness apenas se perfil exigir (news, regulatory)
        staleness_check = self._check_evidence_staleness(
            facts, phase_context, intent_profile=intent_profile
        )
        if not staleness_check["passed"]:
            # Staleness √© informativo, n√£o bloqueante
            # Apenas loggar mas n√£o bloquear DONE
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[INFO][JUDGE] Staleness warning: {staleness_check['reason']}")
            # return {
            #     "passed": False,
            #     "reason": staleness_check["reason"],
            #     "suggested_query": staleness_check.get("suggested_query", "Buscar evid√™ncias mais recentes")
            # }

        return {"passed": True}

    def _check_evidence_staleness(
        self, facts, phase_context, intent_profile: Optional[str] = None
    ):
        """Verifica staleness (recency) das evid√™ncias (P1.2) com gates por perfil"""
        if not facts:
            return {"passed": True}

        # Extrair time_hint do phase_context
        time_hint = phase_context.get("time_hint", {}) if phase_context else {}
        recency = time_hint.get("recency", "1y")
        strict = time_hint.get("strict", False)
        # Aplicar gate por perfil (se perfil exigir strict, for√ßa strict)
        try:
            profile = (
                intent_profile
                or getattr(self.valves, "INTENT_PROFILE", None)
                or "company_profile"
            )
            gates = self.valves.GATES_BY_PROFILE.get(profile, {})
            if gates.get("staleness_strict"):
                strict = True
        except Exception:
            pass

        if not strict:
            return {"passed": True}  # Se n√£o √© strict, n√£o verifica staleness

        # Converter recency para dias
        recency_days = self._parse_recency_to_days(recency)
        if recency_days is None:
            return {"passed": True}  # Recency inv√°lido, n√£o verifica

        # Verificar idade das evid√™ncias
        from datetime import datetime, timedelta

        cutoff_date = datetime.now() - timedelta(days=recency_days)

        old_evidence_count = 0
        total_evidence_count = 0

        for fact in facts:
            evidencias = fact.get("evidencias", [])
            for ev in evidencias:
                total_evidence_count += 1
                ev_date_str = ev.get("data", "")

                if ev_date_str:
                    try:
                        # Tentar parsear data (YYYY-MM-DD)
                        ev_date = datetime.fromisoformat(ev_date_str)
                        if ev_date < cutoff_date:
                            old_evidence_count += 1
                    except:
                        # Se n√£o conseguir parsear, assumir que √© antiga
                        old_evidence_count += 1

        if total_evidence_count == 0:
            return {"passed": True}

        old_ratio = old_evidence_count / total_evidence_count

        # KPI: se >50% das evid√™ncias s√£o antigas, bloquear DONE
        if old_ratio > 0.5:
            return {
                "passed": False,
                "reason": f"{old_ratio*100:.0f}% evid√™ncias fora da janela de {recency} (strict=true)",
                "suggested_query": f"Buscar evid√™ncias mais recentes (√∫ltimos {recency})",
            }

        return {"passed": True}

    def _parse_recency_to_days(self, recency):
        """Converte recency string para dias"""
        if recency == "90d":
            return 90
        elif recency == "1y":
            return 365
        elif recency == "3y":
            return 1095
        else:
            return None

    def _decide_verdict_mece(self, analysis, phase_context, user_prompt):
        """Decis√£o MECE program√°tica para NEW_PHASE vs REFINE

        REFACTORED (v4.3.1 - P1C): Usa _extract_quality_metrics() para evitar duplica√ß√£o
        v4.4: Adiciona verifica√ß√£o de entidades alvo n√£o cobertas
        """
        facts = analysis.get("facts", [])
        lacunas = analysis.get("lacunas", [])

        if not facts:
            return {
                "verdict": "refine",
                "reasoning": "Sem fatos encontrados - precisa de refine",
                # v4.4: Sem fallback gen√©rico ‚Äì prompt do Judge deve gerar a pr√≥xima query espec√≠fica
                "next_query": "",
            }

        # 1.1 Lacuna estrutural (Coverage Gap) - Let Judge LLM handle this intelligently
        # Removed heuristic phase creation - Judge LLM will analyze lacunas and propose specific phases

        # 1.2 Contradi√ß√£o n√£o resolvida (Conflict Gap) - Let Judge LLM handle this intelligently
        # Removed heuristic phase creation - Judge LLM will analyze contradictions and propose specific phases

        # 1.3 Verificar diversidade e fontes oficiais
        quality_rails = phase_context.get("quality_rails", {}) if phase_context else {}
        min_unique_domains = quality_rails.get(
            "min_unique_domains", self.valves.MIN_UNIQUE_DOMAINS
        )

        # Usar fun√ß√£o consolidada para extrair m√©tricas
        metrics = _extract_quality_metrics(facts)
        domains = metrics["domains"]

        # 1.4 Diversity/Prim√°ria Gap
        if len(domains) < min_unique_domains:
            return {
                "verdict": "refine",
                "reasoning": f"Apenas {len(domains)} dom√≠nios √∫nicos, m√≠nimo {min_unique_domains}",
                "next_query": f"{' '.join(user_prompt.split()[:2])} fontes acad√™micas universidades",
            }

        # 1.5 Source-Type Gap - Let Judge LLM handle this intelligently
        # Removed heuristic phase creation - Judge LLM will analyze source gaps and propose specific phases

        # 1.6 Diminishing Returns (seria necess√°rio hist√≥rico de loops)
        # Por enquanto, assumir que se chegou aqui, est√° OK

        return {"verdict": "done"}

    # Removed _create_phase_template - Now using Judge LLM for intelligent phase creation


def _build_seed_query_rules() -> str:
    """Retorna regras compactas de seed_query (usar 1x no prompt)"""
    return """
**SEED_QUERY (3-8 palavras, SEM operadores):**
- Estrutura: TEMA_CENTRAL + ASPECTO + GEO
- Se 1-3 entidades: incluir TODOS os nomes na seed
- Se 4+ entidades: seed gen√©rica + TODOS em must_terms
- @noticias: adicionar 3-6 palavras espec√≠ficas (eventos, tipos, a√ß√µes)

Exemplos:
‚úÖ "RedeDr S√≥ Sa√∫de oncologia Brasil" (1-3 entidades)
‚úÖ "volume autos el√©tricos Brasil" (4+ entidades)
‚úÖ "@noticias recalls ve√≠culos el√©tricos Brasil" (breaking news)
‚ùå "volume fees Brasil" (falta tema!)
‚ùå "buscar dados verific√°veis" (gen√©rico demais)
"""


def _build_time_windows_table() -> str:
    """Tabela compacta de janelas temporais"""
    return """
**JANELAS TEMPORAIS:**

| Recency | Uso | Exemplo |
|---------|-----|---------|
| **90d** | Breaking news expl√≠cito | "√∫ltimos 90 dias", "breaking news" |
| **1y** | Tend√™ncias/estado atual (DEFAULT news) | "eventos recentes", "aquisi√ß√µes ano" |
| **3y** | Panorama/contexto hist√≥rico | "evolu√ß√£o setorial", "baseline" |

**Regra Pr√°tica:**
- News SEM prazo expl√≠cito ‚Üí 1y (captura 12 meses)
- News COM "90 dias" ‚Üí 90d (breaking only)
- Estudos de mercado ‚Üí 3y (contexto) + 1y (tend√™ncias) [OBRIGAT√ìRIO]
"""


def _build_entity_rules_compact() -> str:
    """Regras de entidades (v4.8 - Entity-Centric Policy)"""
    return """
**POL√çTICA ENTITY-CENTRIC (v4.8):**

| Quantidade | Mode | Seed_query | Must_terms (por fase) | Exemplo |
|------------|------|------------|----------------------|---------|
| 1-3 | üéØ FOCADO | Incluir TODOS | **TODAS as fases** devem ter | "RedeDr S√≥ Sa√∫de oncologia BR" |
| 4-6 | üìä DISTRIBU√çDO | Gen√©rica | industry:‚â§3, profiles/news:TODAS | seed:"sa√∫de digital BR", must:["RedeDr","DocTech","Hospital X"] |
| 7+ | üìä DISTRIBU√çDO | Gen√©rica | industry:‚â§3, profiles/news:TODAS | must:["Magalu","Via","Americanas",...] |

**Cobertura obrigat√≥ria (1-3 entidades): ‚â•70% das fases devem incluir as entidades em must_terms**
**Raz√£o:** Discovery Selector usa must_terms para prioriza√ß√£o + Analyst precisa de contexto focado
"""


def _build_planner_prompt(
    user_prompt: str,
    phases: int,
    current_date: Optional[str] = None,
    detected_context: Optional[dict] = None,
) -> str:
    """Build unified Planner prompt used by both Manual and SDK routes.

    Args:
        user_prompt: User's research objective
        phases: Number of phases to plan
        current_date: Current date for temporal context
        detected_context: Context detected by _detect_unified_context (perfil, setor, tipo)
    """
    if not current_date:
        from datetime import datetime

        current_date = datetime.now().strftime("%Y-%m-%d")

    date_context = f"DATA ATUAL: {current_date}\n(Use esta data ao planejar fases de not√≠cias/eventos recentes. N√£o sugira anos passados como '2024' se estamos em 2025.)\n\n"

    # Orienta√ß√£o espec√≠fica por perfil detectado (compacta)
    profile_guidance = ""
    if detected_context:
        perfil = detected_context.get("perfil", "")
        setor = detected_context.get("setor", "")
        # Blocos curtos por perfil (2‚Äì3 bullets). Se j√° houver key_questions/entities, manter guidance minimalista
        short_guidance = {
            "company_profile": (
                f"Perfil mercado ({setor}): use 3y para panorama, 1y para tend√™ncias, 90d s√≥ para eventos pontuais. Priorize fontes oficiais/prim√°rias."
            ),
            "technical_spec": (
                f"Perfil t√©cnico ({setor}): panorama 3y, docs atuais 1y, releases 90d. Priorize docs oficiais/RFCs/repos."
            ),
            "regulation_review": (
                f"Perfil regulat√≥rio ({setor}): marco vigente 3y, compliance 1y, mudan√ßas 90d. Priorize gov/oficial."
            ),
            "literature_review": (
                f"Perfil acad√™mico ({setor}): fundamentos 3y+, estado da arte 1‚Äì3y, papers 1y. Priorize scholar/peri√≥dicos."
            ),
            "history_review": (
                f"Perfil hist√≥rico ({setor}): contexto 3y+, evolu√ß√£o 3y, an√°lise atual 1y. Priorize arquivos/oficial/academia."
            ),
        }
        pg = short_guidance.get(perfil, "")
        if pg:
            profile_guidance = pg + "\n\n"

    # Usar key_questions e entities do detected_context (se dispon√≠veis) - vers√£o compacta
    cot_preamble = ""
    if detected_context:
        # Usar as informa√ß√µes do Context Detection (CoT j√° foi feito l√°)
        key_q = detected_context.get("key_questions", [])
        entities = detected_context.get("entities_mentioned", [])
        objectives = detected_context.get("research_objectives", [])

        if key_q or entities or objectives:
            # SEMPRE mostrar key_questions e entities explicitamente (n√£o depender de reasoning_summary)
            cot_preamble = f"""
üìã **CONTEXTO J√Å ANALISADO (CONTEXT-LOCK):**
‚úÖ {len(key_q)} key questions identificadas
‚úÖ {len(entities)} entidades espec√≠ficas detectadas  
‚úÖ {len(objectives)} objetivos de pesquisa definidos
‚úÖ Perfil: {detected_context.get('perfil', 'N/A')}

üîí **PAYLOAD DO ESTRATEGISTA (USE EXCLUSIVAMENTE, N√ÉO RE-INFIRA):**
KEY_QUESTIONS={json.dumps(key_q[:10], ensure_ascii=False)}
ENTITIES_CANONICAL={json.dumps(entities[:15], ensure_ascii=False)}
RESEARCH_OBJECTIVES={json.dumps(objectives[:10], ensure_ascii=False)}
LANG_BIAS={detected_context.get('language_bias', ['pt-BR', 'en'])}
GEO_BIAS={detected_context.get('geo_bias', ['BR', 'global'])}

‚ö†Ô∏è **INSTRU√á√ïES CR√çTICAS:**
1. Crie fases que RESPONDAM √†s KEY_QUESTIONS listadas acima
2. Inclua ENTITIES_CANONICAL nos must_terms das fases apropriadas
3. Alinhe os objectives das fases aos RESEARCH_OBJECTIVES do estrategista
4. N√ÉO introduza novas entidades n√£o listadas acima
5. N√ÉO altere ou re-interprete os objetivos
6. Use SOMENTE os dados do payload acima
"""

    # Chain of Thought: SEMPRE usar informa√ß√µes do Context Detection (n√£o extrair novamente)
    if detected_context and (
        detected_context.get("key_questions")
        or detected_context.get("entities_mentioned")
    ):
        # Context Detection j√° fez o CoT - N√ÉO pedir re-extra√ß√£o
        chain_of_thought = f"""
‚öôÔ∏è **PROCESSO DE PLANEJAMENTO:**
Pense passo a passo INTERNAMENTE, mas N√ÉO exponha o racioc√≠nio. Retorne APENAS JSON.

1. **MAPEAR** cada KEY_QUESTION do payload acima ‚Üí uma fase espec√≠fica
2. **DIVIDIR** em at√© {phases} fases MECE (panorama ‚Üí detalhes ‚Üí atual/news)
3. **APLICAR** janelas temporais: 3y (panorama), 1y (tend√™ncias), 90d (not√≠cias)
4. **INCLUIR** ENTITIES_CANONICAL nos must_terms conforme phase_type

{cot_preamble}
"""
    else:
        # Fallback: se Context Detection falhou completamente
        chain_of_thought = f"""
‚ö†Ô∏è FALLBACK MODE (Context Detection falhou):
Extraia voc√™ mesmo as key questions e entidades da consulta abaixo e divida em fases.
{cot_preamble}
"""

    # Exemplo m√≠nimo (1 bloco) ‚Äî mant√©m orienta√ß√£o sem inflar prompt
    example_json = """    {
      "name": "Panorama geral",
      "objective": "Pergunta verific√°vel e espec√≠fica",
      "seed_query": "<3-6 palavras, sem operadores>",
      "seed_core": "<12-200 chars, 1 frase rica, sem operadores>",
      "must_terms": ["<todas as entidades mencionadas>"],
      "avoid_terms": ["<ru√≠do>"] ,
      "time_hint": {"recency": "1y", "strict": false},
      "source_bias": ["oficial", "primaria", "secundaria"],
      "evidence_goal": {"official_or_two_independent": true, "min_domains": 3},
      "lang_bias": ["pt-BR", "en"],
      "geo_bias": ["BR", "global"]
    }"""

    # P1: Exemplo ANTES/DEPOIS para seed_query (clareza de tema central)
    seed_before_after = """
‚ö†Ô∏è EXEMPLOS DE SEED QUERY - ANTES E DEPOIS:

‚ùå ERRADO (sem tema central):
- "volume fees Brasil" ‚Üí Falta contexto (fees de QU√ä?)
- "tend√™ncias servi√ßos Brasil" ‚Üí Gen√©rico (servi√ßos de QU√ä?)
- "reputa√ß√£o boutiques Brasil" ‚Üí Amb√≠guo (boutiques de QU√ä?)

‚úÖ CORRETO (tema presente):
- "volume fees executive search Brasil" ‚Üí Tema: executive search
- "tend√™ncias servi√ßos headhunting Brasil" ‚Üí Tema: headhunting
- "reputa√ß√£o boutiques executive search Brasil" ‚Üí Tema: executive search

REGRA: seed_query = TEMA_CENTRAL + ASPECTO + GEO
"""

    # P1: Instru√ß√µes para seed_core (OBRIGAT√ìRIO)
    seed_core_instructions = """
‚ö†Ô∏è **SEED_CORE (OBRIGAT√ìRIO para TODAS as fases):**
- Formato: 1 frase rica (12-200 chars), linguagem natural, SEM operadores
- Inclui: entidades + tema + aspecto + recorte geotemporal
- Contexto completo para Discovery Tool executar busca efetiva
- Rela√ß√£o com seed_query: seed_core √© expans√£o rica de seed_query

EXEMPLOS:
Fase "Volume setorial":
  seed_query: "volume executive search Brasil"
  seed_core: "volume anual mercado executive search Brasil √∫ltimos 3 anos fontes oficiais associa√ß√µes setor"

Fase "Tend√™ncias servi√ßos":
  seed_query: "tend√™ncias headhunting Brasil"
  seed_core: "tend√™ncias emergentes servi√ßos headhunting e recrutamento executivo Brasil √∫ltimos 12 meses inova√ß√µes tecnologia"

Fase "Perfis empresas":
  seed_query: "Korn Ferry portf√≥lio Brasil"
  seed_core: "Korn Ferry portf√≥lio servi√ßos posicionamento competitivo mercado brasileiro executive search √∫ltimos 2 anos"

‚ùå ERRADO (muito curta, sem contexto):
  seed_core: "Flow CNPJ Brasil"  // Apenas 3 palavras

‚úÖ CORRETO:
  seed_core: "Flow Executive Finders CNPJ registro Receita Federal Brasil raz√£o social data funda√ß√£o"
"""

    # Framework de auto-valida√ß√£o de realismo
    realism_framework = """
üîç AUTO-VALIDA√á√ÉO DE REALISMO (PENSE ANTES DE INCLUIR M√âTRICAS):

Para CADA m√©trica/dado que voc√™ incluir no objective, fa√ßa a pergunta:

'Empresas/organiza√ß√µes DESTE TIPO e PORTE divulgam isso publicamente?'

Use seu conhecimento sobre:
  ‚Ä¢ Pr√°ticas do setor (financeiro vs tech vs sa√∫de vs consultoria)
  ‚Ä¢ Tipo de empresa (listada vs privada vs startup vs p√∫blica)
  ‚Ä¢ Sensibilidade competitiva (pricing, margens, m√©tricas operacionais)
  ‚Ä¢ Obriga√ß√µes regulat√≥rias (empresas listadas divulgam mais)

HEUR√çSTICA SIMPLES:
  ‚úÖ Se encontraria em: site corporativo, press releases, relat√≥rios anuais
     ‚Üí INCLUIR no objective
  ‚ö†Ô∏è Se encontraria apenas em: relat√≥rios internos, pitches de vendas
     ‚Üí EVITAR ou marcar como 'se dispon√≠vel'
  ‚ùå Se √© vantagem competitiva: pricing real, custos, m√©tricas operacionais
     ‚Üí N√ÉO incluir, focar em proxies p√∫blicas

EXEMPLO DE RACIOC√çNIO:
Query: 'Boutique de executive search no Brasil'
M√©trica considerada: 'time-to-fill m√©dio, success rate %'

Pergunta: Consultoria de RH divulga m√©tricas operacionais?
Resposta: N√£o - s√£o vantagens competitivas confidenciais.
          Empresas listadas divulgam revenue agregado, privadas n√£o.

Objective ajustado: 'portf√≥lio de servi√ßos, setores atendidos,
                     ciclos/processos DECLARADOS (quando dispon√≠vel)'
                     [proxy p√∫blico para 'rapidez operacional']

‚ö†Ô∏è IMPORTANTE: Voc√™ conhece centenas de setores. Use esse conhecimento.
               N√£o force m√©tricas que voc√™ sabe serem privadas.
"""

    # Usar dicion√°rios globais de prompts
    system_prompt = PROMPTS["planner_system"].format(phases=phases)
    seed_rules = _build_seed_query_rules()
    time_windows = _build_time_windows_table()
    entity_rules = _build_entity_rules_compact()
    
    return (
        date_context
        + profile_guidance
        + cot_preamble
        + seed_before_after
        + seed_core_instructions
        + realism_framework
        + f"""

{system_prompt}

üéØ OBJETIVO DA PESQUISA:
{user_prompt}

{seed_rules}

{time_windows}

{entity_rules}

üéØ **ECONOMIA DE FASES (CRITICAL):**
AT√â """
        + str(phases)
        + """ fases permitidas. PREFIRA MENOS FASES BEM FOCADAS.

**QUANDO COMBINAR (1 fase):**
- Objetivo = comparar/rankear m√∫ltiplas entidades
- Overview geral ou an√°lise aggregada de mercado

**QUANDO ESPECIALIZAR (1 fase/entidade):**
- Usu√°rio pede "perfis detalhados" / "an√°lise profunda"
- Entidades muito distintas (B2B vs B2C, setores diferentes)
- Volume esperado >10 p√°ginas por entidade

**EXEMPLOS:**
- "Compare receita A, B, C" ‚Üí ‚úÖ 2 fases (receitas 3y + drivers 1y) | ‚ùå 6 fases (1/empresa + trends)
- "Perfis detalhados A, B, C" ‚Üí ‚úÖ 4 fases (3 perfis deep + comparativa) | Justificado: especializa√ß√£o necess√°ria

üìä **SCORING:** Precis√£o 40% + Economia 30% + MECE 30% ‚Üí Menos fases (mesma cobertura) = SUPERIOR

**CHECKLIST:** Antes de criar fase ‚Üí (1) Responde key_question √∫nica? (2) Aspecto/temporal diferente? (3) Combinar degrada qualidade? ‚Üí Se N√ÉO para qualquer ‚Üí N√ÉO CRIE

üî¥ **REGRA ESPECIAL - PEDIDOS EXPL√çCITOS DE NOT√çCIAS:**
Se o usu√°rio mencionar "not√≠cias", "noticias", "fase de not√≠cias", "eventos recentes":
‚Üí OBRIGAT√ìRIO criar fase type="news" com:
  - seed_query: "@noticias" + tema + entidades
  - time_hint: 1y (√∫ltimos 12 meses)
  - 90d SOMENTE se usu√°rio disser "breaking news", "√∫ltimos 90 dias" ou "muito recente"

‚öôÔ∏è **PROCESSO DE PLANEJAMENTO (Use o payload acima, N√ÉO re-extraia):**

Pense passo a passo INTERNAMENTE, mas N√ÉO exponha o racioc√≠nio. Retorne APENAS JSON.

**ETAPA 1 - MAPEAR (n√£o extrair):**
- Para cada KEY_QUESTION do payload ‚Üí crie 1 fase espec√≠fica
- Exemplo: KEY_QUESTION "Qual volume anual?" ‚Üí Fase "Volume setorial" (phase_type: industry)
- Exemplo: KEY_QUESTION "Qual reputa√ß√£o?" ‚Üí Fase "Perfis players" (phase_type: profiles)

**ETAPA 2 - DIVIDIR em fases MECE por phase_type:**

üéØ **ENTITY-CENTRIC MODE (1-3 entidades mencionadas):**
SE o payload tem 1-3 ENTITIES_CANONICAL ‚Üí MODO FOCADO:
  ‚úÖ **TODAS as fases** devem incluir essas entidades em must_terms
  ‚úÖ Seed_query de cada fase deve conter nomes das entidades
  ‚úÖ Objetivo: Manter foco laser nas entidades espec√≠ficas
  ‚ùå N√ÉO crie fases gen√©ricas sem as entidades
  
üìä **MULTI-ENTITY MODE (4+ entidades mencionadas):**
SE o payload tem 4+ ENTITIES_CANONICAL ‚Üí MODO DISTRIBU√çDO:
  - **industry**: pode ter subset (‚â§3 entidades representativas)
  - **profiles**: deve ter TODAS
  - **news**: deve ter TODAS

**Phase types (aplique a l√≥gica acima):**
- **industry**: panorama setorial (volume, tend√™ncias, players)
  - must_terms: [ENTITY-CENTRIC: todas entidades] [MULTI: subset ‚â§3] + termos setoriais + geo
  - time_hint: 1y ou 3y
- **profiles**: perfis detalhados de players
  - must_terms: **TODAS** as ENTITIES_CANONICAL do payload + geo
  - time_hint: 3y
- **news**: not√≠cias e eventos relevantes (√∫ltimos 12 meses)
  - must_terms: **TODAS** as ENTITIES_CANONICAL do payload + geo
  - seed_query: DEVE incluir "@noticias" + tema + entidades
  - time_hint: 1y (DEFAULT) | 90d SOMENTE para "breaking news" expl√≠cito

**ETAPA 3 - APLICAR janelas temporais corretas:
üîç **CONTEXTO IMPORTA:** A janela temporal depende do TIPO DE INFORMA√á√ÉO, n√£o apenas se √© "not√≠cia"!

"""
        + _build_time_windows_table()
        + """

‚ö†Ô∏è **CR√çTICO - ESTUDOS DE MERCADO (READ THIS!):**

üö® **SE** o objetivo geral cont√©m ["estudo", "an√°lise", "mercado", "setor", "panorama", "competitivo"]:

**ARQUITETURA OBRIGAT√ìRIA (N√ÉO NEGOCI√ÅVEL):**
1. ‚úÖ Fase "industry/profiles" com 3y (contexto/baseline)
2. ‚úÖ **Fase "not√≠cias/eventos" com 1y** (OBRIGAT√ìRIA se planejando 3+ fases)
   - seed_query DEVE ter "@noticias" + tema + entidades
   - Captura √∫ltimos 12 meses de eventos relevantes
   - 90d SOMENTE se usu√°rio pedir "breaking news" ou "√∫ltimos 90 dias" explicitamente
3. ‚úÖ Fase adicional de "perfis" ou "tend√™ncias" conforme necess√°rio

**‚ùå ERRO COMUM (N√ÉO FA√áA):**
- Criar apenas 1 fase "news" com 90d
- Esquecer de incluir "@noticias" na seed_query de fases de not√≠cias
- Criar fases gen√©ricas sem as entidades quando h√° 1-3 entidades (entity-centric)
- Resultado: perde tend√™ncias dos √∫ltimos 12 meses (70% das key questions n√£o respondidas) + falta foco nas entidades

**‚úÖ EXEMPLO CORRETO - Estudo entity-centric (3 entidades: Health+, Vida Melhor, OncoTech):**
```json
{
  "plan_intent": "Mapear oportunidades e riscos em sa√∫de digital com foco em 3 hospitais brasileiros",
  "phases": [
    {"name": "Panorama de mercado e players (3 anos)", "phase_type": "industry", 
    "seed_query": "RedeDr S√≥ Sa√∫de oncologia Brasil",  // ‚Üê ENTITY-CENTRIC: todas as 3 empresas
    "must_terms": ["RedeDr", "S√≥ Sa√∫de", "Onco Brasil", "sa√∫de digital", "Brasil"],  // ‚Üê TODAS
     "time_hint": {"recency": "3y"}},
    {"name": "Perfis, servi√ßos e reputa√ß√£o", "phase_type": "profiles", 
    "seed_query": "Health+ Vida Melhor OncoTech servi√ßos rankings reputa√ß√£o",  // ‚Üê ENTITY-CENTRIC: todas as 3
    "must_terms": ["Health+", "Vida Melhor", "OncoTech", "sa√∫de digital", "Brasil"],  // ‚Üê TODAS
     "time_hint": {"recency": "3y"}},
    {"name": "Not√≠cias e eventos (12 meses)", "phase_type": "news", 
    "seed_query": "@noticias Magalu Via Americanas varejo Brasil",  // ‚Üê ENTITY-CENTRIC + @noticias
    "must_terms": ["Magazine Luiza", "Via", "Americanas", "varejo", "Brasil"],  // ‚Üê TODAS
     "objective": "Aquisi√ß√µes, lan√ßamentos, mudan√ßas de mercado com foco nas 3 empresas-alvo (12 meses)",
     "time_hint": {"recency": "1y", "strict": false}}  // ‚Üê 1y (n√£o 90d!)
  ]
}
```

**‚ö†Ô∏è CONTRASTE - ERRADO (fases gen√©ricas, perdeu foco):**
```json
{
  "phases": [
    {"name": "Panorama geral", "seed_query": "mercado executive search Brasil",  // ‚ùå SEM entidades
     "must_terms": ["executive search", "Brasil"]},  // ‚ùå Faltam empresas
    {"name": "Tend√™ncias", "seed_query": "tend√™ncias servi√ßos headhunting Brasil",  // ‚ùå SEM entidades
     "must_terms": ["executive search", "assessment"]},  // ‚ùå Faltam empresas
    {"name": "Perfis", "seed_query": "Health+ Vida Melhor OncoTech",  // ‚úÖ Tem entidades MAS s√≥ em 1 fase
     "must_terms": ["Health+", "Vida Melhor", "OncoTech"]}  // ‚úÖ OK mas TARDE DEMAIS (70% das fases sem foco)
  ]
}
```
**Resultado errado: Judge detecta falta de foco nas empresas-alvo e cria novas fases redundantes (desperd√≠cio de budget)**

**üéØ VALIDA√á√ÉO OBRIGAT√ìRIA (checklist antes de retornar plano):**
- [ ] **Entity-centric?** Se 1-3 entidades: ‚â•70% das fases incluem essas entidades em must_terms?
- [ ] **Temporal coverage?** H√° fase com recency=1y para capturar tend√™ncias dos √∫ltimos 12 meses?
- [ ] **News phase?** Se pedido "not√≠cias" ou "estudo de mercado": fase news com "@noticias" e 1y?
- [ ] **Key questions cobertas?** Cada KEY_QUESTION do payload tem fase correspondente?
- [ ] **Seed_query v√°lido?** 3-8 palavras, sem operadores, cont√©m tema central + entidades?

üìê REGRAS OBRIGAT√ìRIAS:

‚úÖ CADA FASE TEM:
   - name: descritivo e √∫nico
   - objective: pergunta verific√°vel (n√£o gen√©rica!)
   - seed_query: 3-8 palavras, SEM operadores
   - seed_core: 12-200 chars, frase rica para discovery (OBRIGAT√ìRIO!)
     
     """
        + _build_seed_query_rules()
        + """
     
     """
        + _build_entity_rules_compact()
        + """
     
     **SLACK SEM√ÇNTICO PARA ASPECTOS/M√âTRICAS:**
     
     ‚ùå N√ÉO coloque m√©tricas/aspectos espec√≠ficos na seed:
     - "volume fees tempo-to-fill executive search Brasil" (6 palavras, MUITO espec√≠fica)
     
     ‚úÖ Seed gen√©rica + m√©tricas em must_terms:
     - seed: "mercado executive search Brasil" (4 palavras)
     - must_terms: ["volume", "fees", "tempo-to-fill", "coloca√ß√µes", "market size", ...]
     
   - must_terms: **CR√çTICO - TODOS OS NOMES V√ÉO AQUI (SEMPRE)**
     * Independente de quantos, TODOS os nomes v√£o em must_terms
     * Se usu√°rio mencionou 10 empresas, TODAS v√£o em must_terms
     * Se usu√°rio mencionou produtos/pessoas, TODOS v√£o em must_terms
     * Discovery vai usar must_terms para priorizar e expandir a busca
     * Seed_query + must_terms = m√°xima precis√£o
   - avoid_terms: ru√≠do a evitar
   - time_hint: {"recency": "90d|1y|3y", "strict": true/false}
   - source_bias: ["oficial", "primaria", "secundaria"]
   - evidence_goal: {"official_or_two_independent": true, "min_domains": 3}
   - lang_bias e geo_bias apropriados

üÜï **NOVO v4.7 - SEED_CORE E SEED_FAMILY_HINT:**

**seed_core** (OPCIONAL mas RECOMENDADO):
- Vers√£o RICA da seed_query (1 frase, ‚â§200 chars, sem operadores)
- Usado pelo Discovery para gerar 1-3 varia√ß√µes de busca
- Se ausente, Discovery usa seed_query (curta)

**EXEMPLOS:**
- seed_query: "aquisi√ß√µes headhunting Brasil" (curta, 3 palavras)
- seed_core: "aquisi√ß√µes e parcerias estrat√©gicas no mercado de headhunting no Brasil nos √∫ltimos 12 meses" (rica, contexto completo)

**seed_family_hint** (OPCIONAL, default: "entity-centric"):
- Orienta Discovery sobre TIPO de explora√ß√£o
- Valores: "entity-centric" | "problem-centric" | "outcome-centric" | "regulatory" | "counterfactual"

**TEMPLATES POR FAM√çLIA:**
- **entity-centric**: "<ENTIDADE/SETOR> <tema central> <recorte geotemporal>"
  - Ex: "Spencer Stuart executive search Brasil √∫ltimos 12 meses"
- **problem-centric**: "<problema/risco> <drivers/causas> <contexto/segmento>"
  - Ex: "escassez de talentos C-level causas mercado brasileiro"
- **outcome-centric**: "<efeito/resultado> <indicadores/impacto> <stakeholders>"
  - Ex: "impacto turnover executivo indicadores performance empresas"
- **regulatory**: "<norma/regulador> <exig√™ncias/procedimentos> <abrang√™ncia>"
  - Ex: "LGPD requisitos compliance headhunting Brasil"
- **counterfactual**: "<tese/controv√©rsia> <obje√ß√£o/ant√≠tese> <evid√™ncia-chave>"
  - Ex: "boutiques locais vs internacionais vantagens competitivas evid√™ncias"

**QUANDO USAR CADA FAM√çLIA:**
- **entity-centric** (default): Foco em empresas/produtos/pessoas espec√≠ficas
- **problem-centric**: Quando objetivo menciona "desafios", "riscos", "problemas"
- **outcome-centric**: Quando objetivo menciona "impacto", "resultados", "efeitos"
- **regulatory**: Quando objetivo menciona "compliance", "regula√ß√£o", "normas"
- **counterfactual**: Quando objetivo menciona "comparar", "contrastar", "alternativas"

‚ö†Ô∏è **IMPORTANTE:**
- Se Judge anterior sugeriu seed_family diferente (via NEW_PHASE), RESPEITE-A
- seed_core e seed_family_hint s√£o OPCIONAIS (backwards-compatible)
- Se ausentes, Discovery usa seed_query (comportamento atual)

‚ùå N√ÉO FA√áA:
   - Objetivos gen√©ricos ("explorar", "entender melhor")
   - Seed queries id√™nticas ou muito similares
   - Operadores em seed_query (apenas 3-6 palavras simples)
   - Esquecer @noticias para t√≥picos atuais
   - **IGNORAR ENTIDADES ESPEC√çFICAS** mencionadas no objetivo do usu√°rio
   - Ser gen√©rico quando o usu√°rio foi espec√≠fico (ex: usu√°rio menciona 10 empresas, voc√™ ignora)

üéØ SA√çDA OBRIGAT√ìRIA: APENAS JSON PURO (sem markdown, sem coment√°rios, sem texto extra)

SCHEMA JSON OBRIGAT√ìRIO (com phase_type + seed_core + seed_family_hint):
{{
  "plan_intent": "<objetivo do plano em 1 frase>",
  "total_phases_used": <int OPCIONAL: quantas fases criou, se omitir ser√° inferido>,
  "phases_justification": "<string OPCIONAL: por que esse n√∫mero de fases √© suficiente/econ√¥mico>",
  "assumptions_to_validate": ["<hip√≥tese1>", "<hip√≥tese2>"],
  "phases": [
    {{
      "name": "<nome descritivo da fase>",
      "phase_type": "industry|profiles|news|regulatory|financials|tech",
      "objective": "<pergunta verific√°vel e espec√≠fica>",
      "seed_query": "<3-6 palavras, SEM operadores (@, site:, OR, AND)>",
      "seed_core": "<OPCIONAL: 1 frase rica ‚â§200 chars, sem operadores>",
      "seed_family_hint": "<OPCIONAL: entity-centric|problem-centric|outcome-centric|regulatory|counterfactual>",
      "must_terms": ["<termo1>", "<termo2>"],
      "avoid_terms": ["<ru√≠do/SEO>"],
      "time_hint": {{"recency": "90d|1y|3y", "strict": false}},
      "source_bias": ["oficial","primaria","secundaria"],
      "evidence_goal": {{"official_or_two_independent": true, "min_domains": 3}},
      "lang_bias": ["pt-BR","en"],
      "geo_bias": ["BR","global"],
      "suggested_domains": ["<OPCIONAL: dom√≠nios priorit√°rios>"],
      "suggested_filetypes": ["<OPCIONAL: html, pdf, etc>"]
    }}
    // Repetir para 1 a """
        + str(phases)
        + """ fases (conforme necess√°rio, n√£o obrigat√≥rio usar todas)
  ],
  "quality_rails": {{
    "min_unique_domains": """
        + str(max(2, phases))
        + """,
    "need_official_or_two_independent": true
  }},
  "budget": {{"max_rounds": 2}}
}}

‚ö†Ô∏è IMPORTANTE: Voc√™ pode criar 1, 2, 3... at√© """
        + str(phases)
        + """ fases. Escolha o n√∫mero que FAZ SENTIDO para o objetivo!
- Objetivo simples/espec√≠fico? ‚Üí 2-3 fases podem bastar
- Objetivo complexo/amplo? ‚Üí Use mais fases (at√© o m√°ximo)

üí° EXEMPLO 1 - Gen√©rico (SEM empresas mencionadas):
"analisar ind√∫stria de executive search no Brasil":
- must_terms: ["executive search", "Brasil", "mercado"]  ‚Üê Gen√©rico OK

üí° EXEMPLO 2A - Poucas entidades (1-3):
"estudo sobre Health+, Vida Melhor e OncoTech no Brasil":
- seed_query: "Health+ Vida Melhor OncoTech sa√∫de digital Brasil"  ‚Üê 3 nomes na seed (OBRIGAT√ìRIO!)
- must_terms: ["Health+", "Vida Melhor", "OncoTech", "sa√∫de digital", "Brasil"]  ‚Üê TODOS aqui tamb√©m!

"estudo sobre Magalu e Via no Brasil":
- seed_query: "Magalu Via varejo digital Brasil"  ‚Üê 2 nomes na seed (OBRIGAT√ìRIO!)
- must_terms: ["Magalu", "Via", "varejo digital", "Brasil"]  ‚Üê TODOS aqui tamb√©m!

üí° EXEMPLO 2B - Muitas entidades (7+):
"estudo sobre Magalu, Via, Americanas, MercadoLivre, Shopee, Amazon, Submarino no Brasil":
- seed_query: "volume mercado varejo digital Brasil"  ‚Üê SEM nomes (tema + aspecto)
- must_terms: ["Magalu", "Via", "Americanas", "MercadoLivre", "Shopee", "Amazon", "Submarino"]  ‚Üê TODOS aqui!

üí° EXEMPLO CORRETO - Estudo de mercado varejo digital Brasil:
"mercado de varejo digital no Brasil (Magalu, Via, Americanas, MercadoLivre)":
```json
{
  "plan_intent": "Mapear mercado de varejo digital no Brasil com foco em players nacionais e internacionais",
  "assumptions_to_validate": ["Crescimento do e-commerce regional supera o global", "Players locais t√™m vantagens log√≠sticas"],
  "phases": [
    {"name": "Volume setorial", "phase_type": "industry", "objective": "Qual volume anual do varejo digital no Brasil?", "seed_query": "volume varejo digital Brasil", "seed_core": "volume anual vendas e-commerce Brasil", "must_terms": ["varejo digital", "e-commerce", "Brasil"], "avoid_terms": ["loja f√≠sica"], "time_hint": {"recency": "1y", "strict": false}, "source_bias": ["oficial", "primaria"], "evidence_goal": {"official_or_two_independent": true, "min_domains": 3}, "lang_bias": ["pt-BR"], "geo_bias": ["BR"]},
    {"name": "Tend√™ncias servi√ßos", "phase_type": "industry", "objective": "Quais tend√™ncias e servi√ßos adjacentes surgiram nos √∫ltimos 12 meses?", "seed_query": "tend√™ncias servi√ßos varejo digital Brasil", "seed_core": "tend√™ncias emergentes servi√ßos adjacentes varejo digital Brasil √∫ltimos 12 meses inova√ß√µes tecnologia", "must_terms": ["varejo digital", "omnicanal", "log√≠stica", "Brasil"], "avoid_terms": ["loja f√≠sica"], "time_hint": {"recency": "1y", "strict": false}, "source_bias": ["oficial", "primaria"], "evidence_goal": {"official_or_two_independent": true, "min_domains": 3}, "lang_bias": ["pt-BR"], "geo_bias": ["BR"]},
    {"name": "Perfis e reputa√ß√£o", "phase_type": "profiles", "objective": "Como se posicionam Magalu, Via, Americanas e MercadoLivre?", "seed_query": "reputa√ß√£o players varejo digital Brasil", "seed_core": "Magalu Via Americanas MercadoLivre posicionamento competitivo reputa√ß√£o mercado brasileiro varejo digital √∫ltimos 2 anos", "must_terms": ["Magalu", "Via", "Americanas", "MercadoLivre", "Brasil"], "avoid_terms": ["reclama√ß√µes"], "time_hint": {"recency": "3y", "strict": false}, "source_bias": ["oficial", "primaria"], "evidence_goal": {"official_or_two_independent": true, "min_domains": 3}, "lang_bias": ["pt-BR"], "geo_bias": ["BR"]},
    {"name": "Eventos recentes", "phase_type": "news", "objective": "Quais aquisi√ß√µes ou mudan√ßas ocorreram nos √∫ltimos 90 dias?", "seed_query": "@noticias aquisi√ß√µes varejo digital Brasil", "seed_core": "aquisi√ß√µes parcerias mudan√ßas estrat√©gicas Magalu Via Americanas MercadoLivre varejo digital Brasil √∫ltimos 90 dias", "must_terms": ["Magalu", "Via", "Americanas", "MercadoLivre", "Brasil"], "avoid_terms": ["promo√ß√µes"], "time_hint": {"recency": "90d", "strict": true}, "source_bias": ["oficial", "primaria"], "evidence_goal": {"official_or_two_independent": true, "min_domains": 2}, "lang_bias": ["pt-BR"], "geo_bias": ["BR"]}
  ],
  "quality_rails": {"min_unique_domains": 3, "need_official_or_two_independent": true},
  "budget": {"max_rounds": 2}
}
```

**OBSERVA√á√ÉO CR√çTICA sobre o exemplo acima:**
- ‚úÖ Fase 1 seed: "volume fees EXECUTIVE SEARCH Brasil" (tema presente!)
- ‚úÖ Fase 2 seed: "tend√™ncias servi√ßos HEADHUNTING Brasil" (tema presente!)
- ‚úÖ Fase 3 seed: "reputa√ß√£o players EXECUTIVE SEARCH Brasil" (tema presente!)
- ‚úÖ Fase 4 seed: "@noticias aquisi√ß√µes HEADHUNTING Brasil" (tema presente!)
- ‚ö†Ô∏è SEM tema: queries gen√©ricas que retornam noise (curr√≠culos, vagas, etc)

üéØ AGORA CRIE SEU PLANO:

‚ö†Ô∏è **CR√çTICO - POL√çTICAS DE phase_type:**
- **industry**: panorama setorial (volume, tend√™ncias). must_terms: termos setoriais + geo (‚â§5). time_hint: 1y ou 3y
- **profiles**: perfis espec√≠ficos de players. must_terms: **TODOS** os players + geo. time_hint: 3y
- **news**: eventos/not√≠cias do setor. must_terms: **TODOS** os players + geo. time_hint: 1y (padr√£o) OU 90d (apenas breaking news expl√≠cito)
  - ‚ö†Ô∏è NOVO (v4.4): News padr√£o = 1y (captura eventos relevantes 12 meses)
  - ‚ö†Ô∏è Exce√ß√£o: 90d apenas se objective menciona "√∫ltimos 90 dias" / "√∫ltimos 3 meses" / "breaking news"
- **regulatory**: marcos regulat√≥rios. must_terms: leis/normas + geo. time_hint: 1y ou 3y
- **financials**: m√©tricas financeiras. must_terms: players + m√©tricas. time_hint: 1y
- **tech**: especifica√ß√µes t√©cnicas. must_terms: tecnologias + componentes. time_hint: 1y

**INSTRU√á√ïES FINAIS:**

**üîí VALIDA√á√ÉO DE KEY_QUESTIONS COVERAGE (P0 - CR√çTICO):**
Antes de retornar o plano, verifique OBRIGATORIAMENTE:
1. **Para CADA key_question** listada no payload do Estrategista ‚Üí identifique qual fase a responde
2. **Se alguma key_question N√ÉO for coberta** ‚Üí crie fase adicional espec√≠fica
3. **Mapeamento mental obrigat√≥rio:**
   - Key_Q "Qual volume...?" ‚Üí Fase "Volume setorial" (industry, 1y ou 3y)
   - Key_Q "Quais tend√™ncias...?" ‚Üí Fase "Tend√™ncias/evolu√ß√£o" (industry, 1y) ‚Üê CR√çTICO!
   - Key_Q "Qual reputa√ß√£o...?" ‚Üí Fase "Perfis players" (profiles, 3y)
   - Key_Q "Quais eventos/not√≠cias...?" ‚Üí Fase "Eventos mercado" (news, 1y) ‚Üê v4.4: 1y padr√£o!
   - Key_Q "√öltimos dias/90d...?" ‚Üí Fase "Breaking news" (news, 90d) ‚Üê v4.4: apenas se expl√≠cito!
   - Key_Q "Quais riscos/oportunidades 3-5 anos?" ‚Üí Fase "Tend√™ncias/evolu√ß√£o" (industry, 1y)

**SE** alguma key_question n√£o tiver fase correspondente ‚Üí **ERRO CR√çTICO** ‚Üí crie fase adicional.

**EXEMPLO DE VALIDA√á√ÉO:**
```
10 key_questions fornecidas:
‚úì Q1-Q3 ‚Üí Fase 1 (industry 3y)
‚úì Q4-Q6 ‚Üí Fase 2 (profiles 3y) 
‚úì Q7-Q9 ‚Üí Fase 3 (tend√™ncias 1y)  ‚Üê Se esta fase n√£o existir, 30% das questions ficam sem resposta!
‚úì Q10 ‚Üí Fase 4 (news 90d)
```

**AP√ìS VALIDA√á√ÉO:**
1. Use as key_questions e entities j√° analisadas (acima) para criar as fases
2. Atribua phase_type correto para cada fase
3. Aplique as pol√≠ticas de must_terms por phase_type
4. Retorne APENAS JSON PURO (sem markdown, sem texto extra, sem racioc√≠nio)

üéØ **VALIDA√á√ÉO DE RESEARCH_OBJECTIVES COVERAGE (P0 - CR√çTICO):**

Antes de retornar o plano, verifique OBRIGATORIAMENTE:

1. **Para CADA research_objective** listado no payload ‚Üí identifique qual fase cobre
2. **Se algum objective N√ÉO for coberto** ‚Üí ajuste objectives de fase ou crie fase adicional

**EXEMPLO DE MAPEAMENTO:**
```
RESEARCH_OBJECTIVES do estrategista:
1. "Mapear principais players..." ‚Üí Fase "Perfis players" (phase_type: profiles)
2. "Comparar ofertas e pricing..." ‚Üí Fase "Modelos de pre√ßo" (phase_type: industry)
3. "Segmentar demanda por setor..." ‚Üí Fase "Panorama mercado" (phase_type: industry)
4. "Avaliar reputa√ß√£o e m√≠dia..." ‚Üí Fase "Perfis players" (phase_type: profiles)
5. "Identificar riscos regulat√≥rios..." ‚Üí Fase "Panorama mercado" (objective espec√≠fico)
6. "Recomendar estrat√©gias M&A..." ‚Üí Fase "Tend√™ncias e oportunidades" (phase_type: industry)
7. "Produzir matriz competitiva..." ‚Üí Fase "Perfis players" (phase_type: profiles)
```

**SE** algum research_objective n√£o tiver fase que o cubra ‚Üí ajuste fase existente ou crie nova.

**REGRA:** Objectives de fase devem ser MAIS ESPEC√çFICOS que research_objectives (subconjunto detalhado).
- ‚ùå ERRADO: Objective gen√©rico "Analisar mercado" (n√£o cobre research_objective espec√≠fico)
- ‚úÖ CERTO: Objective "Quantificar market share por tipo de player e identificar riscos regulat√≥rios" (cobre research_objectives 1, 3, 5)

**DICA:** Se um research_objective menciona "matriz competitiva", uma fase DEVE ter isso explicitamente no objective.
Se menciona "M&A/expans√£o", uma fase DEVE cobrir fus√µes/aquisi√ß√µes/parcerias.

---

üéØ **ACCEPTANCE CRITERIA (VALIDA√á√ÉO FINAL OBRIGAT√ìRIA):**

Antes de retornar o JSON, verifique:

‚úÖ **ESTRUTURA:**
- [ ] 1-3 fases criadas (pode ser menos que o m√°ximo se suficiente)
- [ ] Cada fase tem TODOS os campos obrigat√≥rios
- [ ] JSON v√°lido (sem markdown, sem coment√°rios, sem texto extra)

‚úÖ **SEED_QUERY (curta, para UI/telemetria):**
- [ ] 3-6 palavras (excluindo @noticias)
- [ ] SEM operadores (site:, filetype:, after:, before:, AND, OR, aspas)
- [ ] Cont√©m tema central + aspecto + geo
- [ ] Se 1-3 entidades: TODOS os nomes na seed_query

‚úÖ **SEED_CORE (rica, para Discovery):**
- [ ] 12-200 caracteres (1 frase completa)
- [ ] SEM operadores
- [ ] Inclui: entidades + tema + aspecto + recorte geotemporal
- [ ] N√ÉO repete seed_query sem adicionar pelo menos 1 aspecto + 1 entidade

‚úÖ **MUST_TERMS:**
- [ ] 2-8 termos (n√£o vazio, n√£o excessivo)
- [ ] TODAS as entidades can√¥nicas inclu√≠das (quando aplic√°vel)
- [ ] SEM overlap com avoid_terms

‚úÖ **OBJECTIVE:**
- [ ] Pergunta verific√°vel (verbo: mapear/identificar/comparar/quantificar)
- [ ] Condi√ß√£o de sucesso clara (ex: "Quantificar market share por player")
- [ ] N√ÉO gen√©rico (ex: "entender melhor", "explorar")

‚úÖ **MECE (N√ÉO OVERLAP COM DISCOVERY):**
- [ ] N√ÉO gerar varia√ß√µes da seed (Discovery far√° isso)
- [ ] N√ÉO criar m√∫ltiplas queries por fase (apenas 1 seed_query + 1 seed_core)

‚úÖ **NEWS PHASES:**
- [ ] time_hint.recency = "1y" (padr√£o) OU "90d" (apenas se expl√≠cito)
- [ ] time_hint.strict = true
- [ ] @noticias na seed_query

üîé **SELF-CHECK (execute ANTES de retornar JSON):**

Antes de retornar o plano, verifique OBRIGATORIAMENTE cada item abaixo:

1Ô∏è‚É£ **Todas as key_questions cobertas?**
   - Cada KEY_QUESTION do payload tem ‚â•1 fase correspondente?
   - Se alguma ficou √≥rf√£ ‚Üí crie fase adicional

2Ô∏è‚É£ **Not√≠cias (se pedidas)?**
   - Se usu√°rio mencionou "not√≠cias" OU √© "estudo de mercado" ‚Üí existe fase type="news"?
   - Fase news tem time_hint.recency="1y" (n√£o 90d) e strict=true?
   - Seed_query da fase news tem "@noticias" + tema + entidades?

3Ô∏è‚É£ **Seeds v√°lidas?**
   - Cada seed_query tem 3-8 palavras (excluindo @noticias)?
   - seed_query N√ÉO usa operadores (site:, filetype:, OR, AND, aspas)?
   - seed_core tem ‚â•12 caracteres e √© DIFERENTE de seed_query?
   - seed_core inclui pelo menos 1 entidade + 1 aspecto adicional?
   - seed_core √© 1 frase rica (n√£o apenas palavras soltas)?

4Ô∏è‚É£ **ENTIDADES (cobertura m√≠nima):**
   - Se ‚â§3 entidades ‚Üí elas aparecem em must_terms de pelo menos 70% das fases?
   - Seed_query das fases de profiles/news incluem TODAS as entidades?
   - Se >3 entidades ‚Üí pelo menos as 3 principais em must_terms de cada fase?

5Ô∏è‚É£ **MECE (sem overlap):**
   - Objectives das fases s√£o mutualmente exclusivos (n√£o overlap √≥bvio)?
   - Se detectou overlap ‚Üí reescreva objectives antes de retornar
   - Fases cobrem TODO o escopo (nenhuma key_question √≥rf√£)?

‚úÖ **SEED_CORE VALIDATION:**
- [ ] TODAS as fases t√™m seed_core (12-200 chars)
- [ ] seed_core ‚â† seed_query (seed_core √© EXPANS√ÉO)
- [ ] seed_core inclui: entidades + tema + aspecto + geo/temporal
- [ ] seed_core SEM operadores (@, site:, OR, AND)

‚úÖ **Se todos os checks passarem ‚Üí retorne JSON**
‚ùå **Se algum falhar ‚Üí corrija ANTES de retornar**

FORMATO DE SA√çDA:
[JSON do plano completo]"""
    )


def _build_analyst_prompt(query: str, phase_context: Dict = None) -> str:
    """Build unified Analyst prompt used by both Manual and SDK routes."""
    # Extrair informa√ß√µes da fase atual
    phase_info = ""
    if phase_context:
        phase_name = phase_context.get("name", "Fase atual")
        # Contract usa "objetivo" (PT), n√£o "objective" (EN)
        phase_objective = phase_context.get("objetivo") or phase_context.get(
            "objective", ""
        )

        # Adicionar must_terms e avoid_terms para guiar o Analyst
        must_terms = phase_context.get("must_terms", [])
        avoid_terms = phase_context.get("avoid_terms", [])

        phase_info = (
            f"\n**FASE ATUAL:** {phase_name}\n**Objetivo da Fase:** {phase_objective}"
        )

        if must_terms:
            # Mostrar at√© 8 termos priorit√°rios (evitar prompt muito longo)
            terms_display = ", ".join(must_terms[:8])
            if len(must_terms) > 8:
                terms_display += f" (e mais {len(must_terms) - 8})"
            phase_info += f"\n**Termos Priorit√°rios:** {terms_display}"

            # P0: Enfatizar obrigatoriedade dos must_terms
            phase_info += f"""

‚ö†Ô∏è **MUST_TERMS S√ÉO OBRIGAT√ìRIOS:**
- TODOS os fatos extra√≠dos DEVEM mencionar pelo menos 1 termo priorit√°rio
- Se contexto n√£o menciona must_terms, reportar em lacunas (ex: "Falta dados sobre [termo]")
- Coverage_score deve penalizar aus√™ncia de must_terms
- Exemplo: Query "market share Flow Executive Brasil" + must_terms ["Flow Executive", "market share", "Brasil"]
  ‚Üí ‚úÖ Fato CORRETO: "Flow Executive tem 15% de market share no Brasil" (3/3 must_terms)
  ‚Üí ‚ùå Fato INCORRETO: "Mercado de consultoria no Brasil cresceu 10%" (1/3 must_terms - gen√©rico demais)"""

        if avoid_terms:
            # Mostrar at√© 5 termos a evitar
            avoid_display = ", ".join(avoid_terms[:5])
            if len(avoid_terms) > 5:
                avoid_display += f" (e mais {len(avoid_terms) - 5})"
            phase_info += f"\n**Evitar:** {avoid_display}"

    # Extrair objetivo espec√≠fico para enfatizar
    objective_emphasis = ""
    if phase_context:
        # Contract usa "objetivo" (PT), n√£o "objective" (EN)
        obj = phase_context.get("objetivo") or phase_context.get("objective", "")
        if obj:
            objective_emphasis = f"\n\nüéØ **SUA MISS√ÉO ESPEC√çFICA NESTA FASE:**\n{obj}\n\n**FOQUE APENAS** em extrair fatos que RESPONDEM DIRETAMENTE esta pergunta/objetivo!"

    # Usar dicion√°rios globais de prompts
    system_prompt = PROMPTS["analyst_system"]
    calibration_rules = PROMPTS["analyst_calibration"]
    
    prompt_template = (
        system_prompt
        + "\n\nOBJETIVO: {query_text}{phase_block}{objective_block}\n\n"
        + calibration_rules
        + "\n\nJSON:\n"
        + "{\n"
        + '  "summary": "Resumo FOCADO NO OBJETIVO da fase (n√£o gen√©rico!)",\n'
        + '  "facts": [\n'
        + '    {\n'
        + '      "texto": "Fato que RESPONDE ao objetivo da fase",\n'
        + '      "confian√ßa": "alta|m√©dia|baixa", \n'
        + '      "evidencias": [{"url": "...", "trecho": "..."}]\n'
        + '    }\n'
        + '  ],\n'
        + '  "lacunas": ["O que AINDA FALTA para responder completamente o objetivo"],\n'
        + '  "self_assessment": {\n'
        + '    "coverage_score": 0.7,\n'
        + '    "confidence": "alta|m√©dia|baixa",\n'
        + '    "gaps_critical": true,\n'
        + '    "suggest_refine": false,\n'
        + '    "suggest_pivot": true,\n'
        + '    "reasoning": "Por que pivot: lacuna precisa de dados 90d (fase atual: 3y)"\n'
        + '  }\n'
        + '}\n\n'
        + "üéØ CALIBRA√á√ÉO DE coverage_score (NOVA - PRAGM√ÅTICA):\n\n"
        + "**PRINC√çPIO:** Foque em VALOR ENTREGUE, n√£o perfei√ß√£o.\n\n"
        + "**0.0-0.3 (BAIXO - RESPOSTA INADEQUADA):**\n"
        + 'Objetivo: "Qual volume anual de coloca√ß√µes executivas no Brasil?"\n'
        + 'Contexto: "Executive search √© importante para empresas. Headhunters buscam talentos."\n'
        + 'Fatos: ["Executive search existe no Brasil", "Headhunters fazem recrutamento"]\n\n'
        + "‚Üí coverage_score = 0.2\n"
        + "‚Üí Raz√£o: Objetivo pede VOLUME ANUAL (n√∫mero), fatos s√£o apenas conceituais\n"
        + "‚Üí gaps_critical = True (pergunta principal n√£o respondida)\n"
        + "‚Üí suggest_refine = True (mesmo √¢ngulo, buscar fontes com n√∫meros)\n\n"
        + "**0.4-0.6 (M√âDIO - RESPOSTA PARCIAL mas √öTIL):**\n"
        + 'Objetivo: "Qual volume anual de coloca√ß√µes executivas no Brasil?"\n'
        + 'Contexto: "Mercado movimentou R$500M em 2023. Spencer, Heidrick, Flow Executive s√£o top 3."\n'
        + 'Fatos: ["Volume estimado R$500M em 2023", "Spencer, Heidrick, Flow Executive lideram"]\n\n'
        + "‚Üí coverage_score = 0.6\n"
        + "‚Üí Raz√£o: ‚úÖ J√Å ENTREGA VALOR (n√∫mero principal + contexto existem)\n"
        + "‚Üí gaps_critical = False (lacunas n√£o impedem uso pr√°tico)\n"
        + "‚Üí suggest_refine = False (resposta utiliz√°vel)\n\n"
        + "**0.7-0.9 (ALTO - RESPOSTA S√ìLIDA):**\n"
        + 'Objetivo: "Qual volume anual de coloca√ß√µes executivas no Brasil?"\n'
        + 'Contexto: "Mercado R$500M (2023), +12% vs 2022. Spencer 25%, Heidrick 18%, Flow Executive 15%. Fonte: ABRH."\n'
        + 'Fatos: ["Volume R$500M 2023 (+12%)", "Spencer 25% share", "Heidrick 18%", "Flow Executive 15%", "Fonte: ABRH"]\n\n'
        + "‚Üí coverage_score = 0.8\n"
        + "‚Üí Raz√£o: Volume + breakdown + fontes + m√©tricas operacionais\n"
        + "‚Üí gaps_critical = False\n"
        + "‚Üí suggest_refine = False\n"
        + "‚Üí ‚úÖ RESPOSTA √öTIL E COMPLETA (lacunas s√£o \"nice-to-have\")\n\n"
        + "1.0 (PERFEITO): Resposta EXAUSTIVA com m√∫ltiplas perspectivas\n"
        + "  - RARO! S√≥ use se objetivo coberto 100% com evid√™ncias robustas de m√∫ltiplas fontes\n"
        + "  - Exemplo: Volume + breakdown detalhado + tend√™ncias + players + m√©tricas + contexto hist√≥rico\n\n"
        + "‚ö†Ô∏è IMPORTANTE - SEJA MENOS CRITICO:\n"
        + '- "Volume R$500M (Fonte: relat√≥rio X)" = coverage 0.6 (√∫til!) N√ÉO 0.3\n'
        + '- "3 players: A, B, C com market share" = coverage 0.6 (√∫til!) N√ÉO 0.4\n'
        + '- N√£o exija perfei√ß√£o para marcar 0.7+\n'
        + '- Lacunas "seria bom ter" n√£o reduzem score (s√≥ lacunas cr√≠ticas)\n\n'
        + "‚ö†Ô∏è AUTO-AVALIA√á√ÉO OBRIGAT√ìRIA:\n"
        + "- gaps_critical: True se lacunas impedem resposta ao objetivo\n"
        + "- suggest_refine: True se mais dados na MESMA dire√ß√£o ajudam\n"
        + "- suggest_pivot: True se lacuna precisa de √¢ngulo/temporal DIFERENTE\n"
        + "- reasoning: Explique brevemente por que refine OU pivot\n\n"
        + "---\n\n"
        + "üéØ **ACCEPTANCE CRITERIA (VALIDA√á√ÉO FINAL OBRIGAT√ìRIA):**\n\n"
        + "‚úÖ **ATOMICIDADE DE FATOS:**\n"
        + "- [ ] 1 fato = 1 proposi√ß√£o verific√°vel (Sujeito-Verbo-Objeto)\n"
        + "- [ ] SEM conjun√ß√µes (\"e\", \"mas\", \"por√©m\") - dividir em m√∫ltiplos fatos\n"
        + "- [ ] Incluir entidade can√¥nica quando aplic√°vel\n"
        + "- [ ] Incluir n√∫mero/m√©trica COM unidade (ex: \"R$500M\", \"25%\", \"12 meses\")\n"
        + "- [ ] Incluir data/per√≠odo quando dispon√≠vel (ex: \"em 2023\", \"√∫ltimos 12 meses\")\n\n"
        + "‚úÖ **EVID√äNCIAS:**\n"
        + "- [ ] 100% dos fatos com ‚â•1 evid√™ncia (URL + trecho)\n"
        + "- [ ] Quando poss√≠vel, ‚â•2 fontes para o mesmo fato (m√∫ltiplas perspectivas)\n"
        + "- [ ] Marcar fonte prim√°ria quando aplic√°vel (ex: site oficial da empresa)\n"
        + "- [ ] ‚â•80% dos fatos com data extra√≠da ou inferida\n\n"
        + "‚úÖ **COVERAGE MATRIX (impl√≠cita):**\n"
        + "- [ ] Para cada key_question relevante: identificar qual(is) fato(s) respondem\n"
        + "- [ ] Coverage_score = (key_questions respondidas) / (key_questions relevantes)\n"
        + "- [ ] Se key_question N√ÉO respondida ‚Üí incluir em lacunas\n\n"
        + "‚úÖ **SELF_ASSESSMENT:**\n"
        + "- [ ] coverage_score: 0.0-1.0 (calibrado conforme exemplos acima)\n"
        + "- [ ] confidence: \"alta|m√©dia|baixa\" (baseado em n¬∫ e qualidade de fontes)\n"
        + "- [ ] gaps_critical: True se lacunas impedem resposta ao objetivo principal\n"
        + "- [ ] suggest_refine vs suggest_pivot: escolha baseada em tipo de lacuna\n\n"
        + "‚úÖ **QUALIDADE:**\n"
        + "- [ ] 3-5 fatos (n√£o vazio, n√£o excessivo)\n"
        + "- [ ] Fatos espec√≠ficos (nomes, n√∫meros, datas) > fatos gen√©ricos\n"
        + "- [ ] Priorizar fatos sobre must_terms (termos priorit√°rios da fase)\n\n"
        + "üß† **CLASSIFICA√á√ÉO INTELIGENTE DE LACUNAS (FRAMEWORK DE RACIOC√çNIO):**\n\n"
        + "Para CADA informa√ß√£o faltante, RACIOCINE usando este framework:\n\n"
        + "A) √â ESPERADO que exista publicamente?\n"
        + "   - Considere: tipo de organiza√ß√£o, setor, obriga√ß√µes regulat√≥rias\n"
        + "   - Exemplos de 'sim': produtos de empresa tech, rankings p√∫blicos, portf√≥lio de servi√ßos\n"
        + "   - Exemplos de 'n√£o': pricing de consultoria, m√©tricas operacionais internas, margens\n\n"
        + "B) √â ESSENCIAL para o objective da fase?\n"
        + "   - Pergunte: 'Sem isso, posso responder a quest√£o principal?'\n"
        + "   - Exemplo: Se objective √© 'portf√≥lio', falta pricing n√£o √© blocker\n"
        + "   - Exemplo: Se objective √© 'market share', falta n√∫meros √â blocker\n\n"
        + "C) H√° PROXIES ou dados relacionados dispon√≠veis?\n"
        + "   - Exemplo: N√£o achei 'time-to-fill exato' mas achei 'processo de 3-4 meses'\n"
        + "   - Proxy √© √∫til? Se sim, mencione no summary como informa√ß√£o parcial\n\n"
        + "CLASSIFICA√á√ÉO RESULTANTE (adicione ao JSON):\n\n"
        + '"lacunas": [\n'
        + '  {\n'
        + '    "descricao": "...",\n'
        + '    "tipo": "cr√≠tica|secund√°ria|esperada",\n'
        + '    "raciocinio": "Por que classifiquei assim (1 frase)"\n'
        + '  }\n'
        + ']\n\n'
        + "üî¥ LACUNA CR√çTICA:\n"
        + "   Esperado p√∫blico + Essencial + Sem proxy dispon√≠vel\n"
        + "   ‚Üí Exemplo: 'Falta informa√ß√£o sobre setores atendidos pela empresa X'\n"
        + "   ‚Üí A√ß√£o: suggest_refine = true\n\n"
        + "üü° LACUNA SECUND√ÅRIA:\n"
        + "   (Esperado p√∫blico + N√£o essencial) OU (Essencial mas tem proxy)\n"
        + "   ‚Üí Exemplo: 'Falta data funda√ß√£o' ou 'Falta m√©trica exata mas h√° declara√ß√£o qualitativa'\n"
        + "   ‚Üí A√ß√£o: Mencionar mas n√£o bloquear\n\n"
        + "‚ö™ LACUNA ESPERADA:\n"
        + "   N√£o esperado p√∫blico (dado privado/competitivo para este setor)\n"
        + "   ‚Üí Exemplo: 'M√©tricas operacionais detalhadas n√£o divulgadas por boutiques de RH'\n"
        + "   ‚Üí A√ß√£o: Aceitar, N√ÉO penalizar coverage_score\n\n"
        + "EXEMPLO DE RACIOC√çNIO:\n\n"
        + 'Lacuna: "Success rate % das boutiques de executive search"\n'
        + "An√°lise:\n"
        + "  A) Esperado p√∫blico? N√ÉO - consultoria n√£o divulga m√©tricas operacionais (vantagem competitiva)\n"
        + "  B) Essencial? N√ÉO se objective √© 'portf√≥lio e posicionamento'\n"
        + "  C) Proxy? SIM - 'ciclo m√©dio 3-4 meses' indica efici√™ncia\n"
        + "Classifica√ß√£o: ‚ö™ ESPERADA\n"
        + "A√ß√£o: N√ÉO penalizar coverage, N√ÉO suggest_refine\n\n"
        + "‚ö†Ô∏è USE SEU CONHECIMENTO DE DOM√çNIO para classificar, n√£o regras fixas.\n"
        + "‚ö†Ô∏è N√ÉO force refinamento para achar dados que voc√™ SABE serem privados.\n\n"
        + "üîç **PROPOSTAS PARA O JUDGE (FASE 2):**\n\n"
        + "Com base nas lacunas encontradas e no objetivo da fase, sugira:\n"
        + "1. **at√© 3 refine_queries** (queries SEM operadores para pr√≥xima busca)\n"
        + "2. **at√© 2 phase_candidates** (novas fases completas para o contrato)\n\n"
        + "Para cada refine_query:\n"
        + "- Formato: 3-8 palavras, SEM operadores (site:, filetype:, OR, etc.)\n"
        + "- Foque no que AINDA falta para responder o objetivo\n"
        + "- Ex: se objetivo=\"volume mercado Brasil\" e contexto tem s√≥ dados de 2022 ‚Üí \"volume mercado Brasil 2023 2024\"\n\n"
        + "Para cada phase_candidate:\n"
        + "- Estrutura completa igual √†s fases do contrato (name, objective, seed_query, etc.)\n"
        + "- Foque em √¢ngulos COMPLETAMENTE diferentes das fases existentes\n"
        + "- Use phase_type apropriado (industry|profiles|news|regulatory|financials|tech)\n\n"
        + "SCHEMA ADICIONAL:\n"
        + "{\n"
        + '  "summary": "...",\n'
        + '  "facts": [...],\n'
        + '  "lacunas": [...],\n'
        + '  "self_assessment": {...},\n'
        + '  "refine_queries": [\n'
        + '    {"q": "<3-8 palavras>", "fills": "<o que espera descobrir>"}\n'
        + '  ],\n'
        + '  "phase_candidates": [\n'
        + '    {\n'
        + '      "name": "...",\n'
        + '      "phase_type": "profiles|news|...",\n'
        + '      "objective": "...",\n'
        + '      "seed_query": "<3-8 palavras>",\n'
        + '      "seed_core": "<frase rica>",\n'
        + '      "must_terms": ["..."],\n'
        + '      "time_hint": {"recency": "1y", "strict": true}\n'
        + '    }\n'
        + '  ]\n'
        + "}\n\n"
        + "Retorne APENAS JSON."
    )

    # üî¥ FIX P0: Usar str.replace em vez de .format para evitar KeyError com literais JSON no template
    # O template cont√©m exemplos JSON com {"summary": ...} que .format() interpreta como placeholder
    final_prompt = prompt_template.replace("{query_text}", query)
    final_prompt = final_prompt.replace("{phase_block}", phase_info)
    final_prompt = final_prompt.replace("{objective_block}", objective_emphasis)

    return final_prompt


def _build_judge_prompt(
    user_prompt: str,
    analysis: Dict[str, Any],
    phase_context: Dict[str, Any] = None,
    telemetry_loops: Optional[List[Dict[str, Any]]] = None,
    intent_profile: Optional[str] = None,
    full_contract: Optional[Dict] = None,
    refine_queries: Optional[List[Dict]] = None,
    phase_candidates: Optional[List[Dict]] = None,
    previous_queries: Optional[List[str]] = None,  # ‚Üê NEW
    failed_queries: Optional[List[str]] = None,  # ‚Üê WIN #3: Failed queries context
) -> str:
    """Build unified Judge prompt - VERS√ÉO OTIMIZADA v4.6

    Melhorias vs v4.5:
    - Compacta√ß√£o: se√ß√µes redundantes consolidadas
    - Decision tree visual para NEW_PHASE (mais claro)
    - Exemplo completo de avalia√ß√£o passo a passo
    - Autonomia preservada (Judge decide, programmatic apenas valida)
    """
    phase_objective = (phase_context or {}).get("objetivo", "") if phase_context else ""
    must_terms = (phase_context or {}).get("must_terms", []) if phase_context else []

    # Extract seed_query from phase_context to prevent duplication
    current_seed = phase_context.get("seed_query", "") if phase_context else ""

    # Extract used queries from telemetry to prevent repetition
    used_queries = []
    if telemetry_loops:
        for loop in telemetry_loops:
            q = loop.get("query", "").strip()
            if q and q not in used_queries:
                used_queries.append(q)

    # ===== CONTRACT AWARENESS (anti-duplica√ß√£o) =====
    contract_awareness = ""
    if full_contract and full_contract.get("fases"):
        current_phase_name = phase_context.get("name", "") if phase_context else ""
        fases_list = []

        for i, fase in enumerate(full_contract["fases"], 1):
            fase_name = fase.get("name", f"Fase {i}")
            fase_obj = fase.get("objetivo", "N/A")
            marker = " **‚Üê ATUAL**" if fase_name == current_phase_name else ""
            fases_list.append(f"{i}. {fase_name}: {fase_obj}{marker}")

        contract_awareness = f"""
üîí **FASES J√Å PLANEJADAS:**
{chr(10).join(fases_list)}

‚ö†Ô∏è **ANTI-DUPLICA√á√ÉO:** Antes de propor new_phase, verifique se j√° existe fase similar acima.
- Se overlap >50% com fase existente ‚Üí use REFINE (n√£o new_phase)
- Apenas use new_phase se for √¢ngulo/escopo COMPLETAMENTE diferente
"""

    # P0: Adicionar research_objectives do Context Detector (COMPACTO)
    research_objectives_section = ""
    if full_contract and full_contract.get("research_objectives"):
        objectives = full_contract["research_objectives"]
        obj_list = "\n".join([f"{i}. {obj}" for i, obj in enumerate(objectives[:5], 1)])
        # Concatena√ß√£o manual evita f-strings aninhadas em templates extensos
        research_objectives_section = """\nüìã **RESEARCH OBJECTIVES:** {list_section}\n‚ö†Ô∏è Se gap cr√≠tico ‚Üí considere NEW_PHASE.\n""".format(
            list_section=obj_list
        )

    # P0: Adicionar key_questions do Context Detector (ULTRA-COMPACTO v4.7)
    key_questions_section = ""
    mece_section = ""
    if full_contract and full_contract.get("key_questions") and phase_objective:
        questions = full_contract["key_questions"]
        q_lines = [
            "{}. {}".format(index, question)
            for index, question in enumerate(questions[:10], 1)
        ]
        q_list = "\n".join(q_lines)
        key_questions_section = (
            "\nüéØ **KEY QUESTIONS (H0):** {items}\n"
            "üìã **OBJETIVO FASE:** {objective}\n\n"
            '‚öôÔ∏è **JSON - key_questions_status:** {{relevant_to_phase: [√≠ndices], answered_in_phase: [√≠ndices], coverage: 0.0-1.0, blind_spots: ["descobertas INESPERADAS que INVALIDAM premissas"]}}\n'
            '\n'
            'üîç **BLIND SPOT = DESCOBERTA INESPERADA (n√£o "dado faltante"):**\n'
            '‚úÖ Blind spot CR√çTICO:\n'
            '   - Descobriu fus√£o/aquisi√ß√£o n√£o mencionada no objetivo (muda landscape competitivo)\n'
            '   - Descobriu esc√¢ndalo/processo regulat√≥rio (invalida premissa "reputa√ß√£o s√≥lida")\n'
            '   - Descobriu novo player dominante n√£o citado (premissas incompletas)\n'
            '‚úÖ Blind spot N√ÉO-CR√çTICO:\n'
            '   - Descobriu escrit√≥rio adicional n√£o esperado (detalhe operacional)\n'
            '   - Descobriu produto adicional no portf√≥lio (complementa mapeamento)\n'
            '\n'
            '‚ùå N√ÉO √© blind spot (s√£o "lacunas esperadas"):\n'
            '   - Falta TAM exato (dado tipicamente privado/estimado para mercados emergentes)\n'
            '   - Falta pricing exato (segredo comercial para empresas privadas)\n'
            '   - Falta receita/margens (boutiques privadas raramente divulgam)\n'
            '   - Falta success rate % (consultoria n√£o divulga vantagem competitiva)\n'
            '\n'
            '**REGRA:** Blind spot = unexpected finding. Lacuna = expected but missing data.\n'
        ).format(items=q_list, objective=phase_objective)
    if full_contract and full_contract.get("_mece_uncovered"):
        uncovered = full_contract["_mece_uncovered"] or []
        if uncovered:
            uncovered_lines = ["- {}".format(kq) for kq in uncovered[:5]]
            uncovered_block = "\n".join(uncovered_lines)
            mece_section = (
                "\n‚ö†Ô∏è **LACUNAS MECE DETECTADAS (Key Questions sem cobertura):**\n"
                "{lines}\n\n"
                "üí° **A√ß√£o sugerida:** Prefira REFINE para cobrir lacunas espec√≠ficas. Use NEW_PHASE somente se exigir √¢ngulo totalmente novo (temporal/fonte/escopo).\n"
            ).format(lines=uncovered_block)

    # Build anti-duplication context
    anti_dup_context = ""
    if current_seed or used_queries:
        anti_dup_sections: List[str] = ["\n**QUERIES J√Å USADAS (N√ÉO REPETIR):**\n"]
        if current_seed:
            anti_dup_sections.append(
                "- Seed original desta fase: '{}\n'".format(current_seed)
            )
        if used_queries:
            formatted_queries = ", ".join("`{}`".format(q) for q in used_queries)
            anti_dup_sections.append(
                "- Queries tentadas: {}\n".format(formatted_queries)
            )
        anti_dup_sections.append(
            "\n‚ö†Ô∏è **CR√çTICO:** Novas queries devem ser SUBSTANCIALMENTE DIFERENTES (novos termos, √¢ngulo, fonte).\n"
        )
        anti_dup_context = "".join(anti_dup_sections)

    # P1: Derivar entidades CAN√îNICAS (nomes pr√≥prios), n√£o termos gen√©ricos
    entities_block = ""
    try:
        # Prioridade 1: Usar entities.canonical do contrato (nomes reais)
        canonical_entities = []
        if full_contract and full_contract.get("entities"):
            canonical_entities = full_contract["entities"].get("canonical", [])

        # Fallback: Extrair entidades de must_terms (apenas nomes pr√≥prios - uppercase)
        if not canonical_entities:
            mt = (phase_context or {}).get("must_terms", [])
            canonical_entities = [
                t
                for t in mt
                if isinstance(t, str)
                and t.strip()
                and len(t.split()) <= 3
                and t[0].isupper()
            ]

        # Limitar e deduplicar
        seen = set()
        dedup = []
        for e in canonical_entities:
            if e.lower() not in seen:
                seen.add(e.lower())
                dedup.append(e)
        dedup = dedup[:12]

        if dedup:
            # Dividir constru√ß√£o em partes reduz a profundidade observada pelo parser do OpenWebUI
            entities_text = ", ".join(dedup)
            # üîß FIX: Usar concatena√ß√£o simples para evitar f-string nesting no OpenWebUI
            entities_block = (
                "\n‚ö†Ô∏è **ENTIDADES OBRIGAT√ìRIAS NA NEXT_QUERY:**\n" + entities_text + "\n"
                "\nüî¥ **REGRA CR√çTICA:** Se verdict=refine, next_query DEVE incluir ‚â•1 entidade acima.\n"
                "‚úÖ Exemplo v√°lido: \"Exec Vila Nova portf√≥lio servi√ßos Brasil\"\n"
                "‚ùå Exemplo inv√°lido: \"mercado executive search Brasil\" (sem entidades!)\n"
                "\n‚ö†Ô∏è Se lacuna = EMPRESAS ‚Üí use SOMENTE estas entidades | "
                "Se lacuna = MERCADO ‚Üí use termos setoriais (mercado, participa√ß√£o, volume)\n"
            )
    except Exception:
        pass

    # üìã FASE 2: Analyst Proposals (refine_queries e phase_candidates)
    analyst_proposals_block = ""
    if refine_queries or phase_candidates:
        analyst_proposals_block = "\n"

        if refine_queries:
            refine_list = []
            for i, rq in enumerate(refine_queries[:3]):  # Limitar a 3
                q = rq.get("q", "N/A")
                fills = rq.get("fills", "N/A")
                refine_list.append(f"{i}. **{q}**\n   Objetivo: {fills}")

            analyst_proposals_block += f"""
üìä **OP√á√ïES DE REFINE SUGERIDAS (do Analyst):**

{chr(10).join(refine_list)}

‚öôÔ∏è **SE verdict=refine:**
- Escolha a melhor op√ß√£o acima via `"selected_index": <int>`
- OU crie sua pr√≥pria query em `refine.next_query` (deixe `selected_index: null`)
- A op√ß√£o selecionada ser√° aplicada automaticamente pelo Orchestrator
"""

        if phase_candidates:
            candidate_list = []
            for i, pc in enumerate(phase_candidates[:2]):  # Limitar a 2
                name = pc.get("name", "N/A")
                obj = pc.get("objective", "N/A")[:80]
                candidate_list.append(f"{i}. **{name}**\n   Objetivo: {obj}")

            analyst_proposals_block += f"""
üìä **CANDIDATOS DE NOVA FASE SUGERIDOS (do Analyst):**

{chr(10).join(candidate_list)}

‚öôÔ∏è **SE verdict=new_phase:**
- Escolha o melhor candidato acima via `"selected_index": <int>`
- OU crie sua pr√≥pria fase em `new_phase` (deixe `selected_index: null`)
- O candidato selecionado ser√° integrado automaticamente ao contrato
- ‚ö†Ô∏è **CR√çTICO:** Valide anti-duplica√ß√£o antes de escolher (compare com fases j√° planejadas acima)
"""

    # ‚úÖ WIN #3: Failed queries context
    if failed_queries:
        failed_list = "\n".join([f"- {q}" for q in failed_queries[:5]])  # Limit to 5
        analyst_proposals_block += f"""
üîç **QUERIES QUE RETORNARAM 0 URLs (dead ends):**
{failed_list}

‚ö†Ô∏è **IMPORTANTE:** Evite propor NEW_PHASE que repitam estas buscas que falharam.
"""

    # Anti-duplication context
    anti_dup_section = ""
    if previous_queries and len(previous_queries) > 0:
        queries_list = "\n".join([f"  {i+1}. \"{q}\"" for i, q in enumerate(previous_queries)])
        anti_dup_section = f"""
‚ö†Ô∏è **QUERIES J√Å TESTADAS NESTA FASE (EVITE VARIA√á√ïES SEM√ÇNTICAS):**
{queries_list}

**REGRA CR√çTICA**: Se sua `next_query` for **semanticamente similar** √†s anteriores, ela vai gerar **0 URLs novas**.

**EXEMPLOS DE VARIA√á√ïES IN√öTEIS (N√ÉO FAZER):**
- "tamanho mercado Brasil" ‚Üí "valor mercado Brasil" (apenas sin√¥nimo)
- "executive search Brasil" ‚Üí "executive search Brasil 2023" (apenas ano)
- "market size Brazil" ‚Üí "tamanho mercado Brasil" (apenas tradu√ß√£o)

**SOLU√á√ïES QUE FUNCIONAM:**
- Mudar FONTE: "tamanho mercado" ‚Üí "ABRH relat√≥rio setor RH"
- Mudar √ÇNGULO: "volume total" ‚Üí "custo m√©dio contrata√ß√£o"
- Mudar ESCOPO: "mercado Brasil" ‚Üí "Spencer Stuart earnings Brazil"

"""

    # Usar dicion√°rios globais de prompts
    system_prompt = PROMPTS["judge_system"]
    philosophy = PROMPTS["judge_philosophy"]
    
    return f"""{system_prompt}

{philosophy}

{anti_dup_section}

‚ö†Ô∏è **PAPEL DO LLM (CR√çTICO - LEIA PRIMEIRO):**

ü§ñ **VOC√ä (LLM) PROP√ïE, C√ìDIGO DECIDE:**
- Voc√™ analisa m√©tricas e prop√µe verdict + reasoning
- O c√≥digo VALIDA sua proposta usando phase_score, duplica√ß√£o, loops
- A decis√£o FINAL √© program√°tica (audit√°vel, configur√°vel)
- Seu papel: EXPLICAR o racioc√≠nio de forma clara e consistente

üìä **M√âTRICAS QUE O C√ìDIGO USA (para sua informa√ß√£o):**
- phase_score = f(coverage, novel_facts, novel_domains, diversity, contradictions)
- flat_streak = loops consecutivos sem ganho
- overlap_similarity = fatos repetidos vs fases anteriores
- Gates por phase_type (threshold, two_flat_loops)

üí° **IMPLICA√á√ÉO:**
- Seja consistente: reasoning deve alinhar com verdict proposto
- Seja espec√≠fico: mencione m√©tricas concretas (coverage %, n¬∫ fatos, n¬∫ dom√≠nios)
- Seja honesto: se dados s√£o fracos, diga; se h√° contradi√ß√µes, mencione

{contract_awareness}{key_questions_section}{mece_section}

üéØ **FILOSOFIA DE DECIS√ÉO (LEIA COM ATEN√á√ÉO):**

**DONE ‚â† PERFEITO. DONE = SUFICIENTE.**
- Responde ao objetivo? ‚Üí Propor DONE
- Fatos t√™m subst√¢ncia (nomes/n√∫meros)? ‚Üí Propor DONE
- Lacunas s√£o secund√°rias? ‚Üí Propor DONE

**REFINE: s√≥ se NECESS√ÅRIO**
- Fatos gen√©ricos SEM dados/nomes
- Lacunas IMPEDEM resposta ao objetivo
- Evid√™ncias MUITO fracas

**NEW_PHASE: √¢ngulo COMPLETAMENTE diferente**
- Escopo/temporal/fonte totalmente diferente
- Verifique anti-duplica√ß√£o (n√£o repita fases existentes!)
- **OBRIGAT√ìRIO**: Propor seed_family diferente do atual (trocar explora√ß√£o)

üìä **CHECKLIST:** Coverage‚â•60% OU fatos de alta qualidade? | ‚â•50% must_terms/entidades cobertos? | Lacunas cr√≠ticas?
‚Üí Se ‚â•2 itens falharem ‚Üí REFINE ou NEW_PHASE

‚è±Ô∏è **CUSTO-BENEF√çCIO DE REFINE:**
- Cada loop adicional: 5-10 minutos de pesquisa (discovery + scraper + analyst)
- Coverage incremental t√≠pico: +10-15% por loop
- **REGRA DE DECIS√ÉO:**
  - Coverage atual ‚â•60% E lacunas s√£o dados privados ‚Üí DONE (economia 5-10 min)
  - Coverage atual <50% E lacunas s√£o dados p√∫blicos ‚Üí REFINE (investimento justificado)
  - Coverage 50-60% ‚Üí Avaliar qualidade dos fatos existentes (nomes/n√∫meros = DONE)

üî¥ **CR√çTICO - FRAMEWORK "N√ÉO EXISTE vs N√ÉO ACHEI" (LEIA ANTES DE DECIDIR):**

Antes de decidir REFINE, pergunte-se:

1Ô∏è‚É£ O que falta √© REALISTICAMENTE p√∫blico?
   ‚Ä¢ Use seu conhecimento: este tipo de org divulga isso?
   ‚Ä¢ Exemplos:
     ‚úÖ Portf√≥lio de produtos ‚Üí P√∫blico (em sites/press releases)
     ‚úÖ Rankings e pr√™mios ‚Üí P√∫blico (em press/LinkedIn)
     ‚ùå Margens operacionais empresa privada ‚Üí Privado
     ‚ùå Success rate consultoria ‚Üí Privado (vantagem competitiva)
     ‚ùå Pricing exato (negociado) ‚Üí Privado

2Ô∏è‚É£ Se √© privado, h√° PROXY p√∫blico suficiente?
   ‚Ä¢ Exemplo: n√£o h√° 'time-to-fill exato' mas h√° 'processo 3-4 meses'
   ‚Ä¢ Proxy responde suficientemente o objective? ‚Üí Sim? DONE

3Ô∏è‚É£ Se √© p√∫blico, realmente n√£o achei ou n√£o procurei bem?
   ‚Ä¢ Avaliar: dom√≠nios visitados s√£o autoritativos para esta info?
   ‚Ä¢ Exemplo: procurei setores da empresa mas s√≥ visitei agregadores
   ‚Ä¢ Se n√£o procurei bem ‚Üí REFINE com query focada

FRAMEWORK DE DECIS√ÉO:

‚îå‚îÄ Lacunas cr√≠ticas (esperadas p√∫blicas)?
‚îÇ  ‚îú‚îÄ SIM ‚Üí REFINE
‚îÇ  ‚îî‚îÄ N√ÉO ‚Üì
‚îÇ
‚îú‚îÄ Lacunas s√£o dados privados para este setor?
‚îÇ  ‚îú‚îÄ SIM ‚Üí H√° proxies √∫teis?
‚îÇ  ‚îÇ  ‚îú‚îÄ SIM ‚Üí Coverage efetivo +15% ‚Üí DONE
‚îÇ  ‚îÇ  ‚îî‚îÄ N√ÉO ‚Üí Coverage efetivo = raw ‚Üí Avaliar threshold
‚îÇ  ‚îî‚îÄ N√ÉO ‚Üì
‚îÇ
‚îî‚îÄ Objective principal foi respondido?
   ‚îú‚îÄ SIM (‚â•65% cobertura) ‚Üí DONE
   ‚îî‚îÄ N√ÉO ‚Üí REFINE

EXEMPLO DE RACIOC√çNIO:

Fase: 'M√©tricas operacionais de boutiques executive search'
Encontrado: Portf√≥lio servi√ßos, setores, ciclo declarado '3-4 meses'
Faltando: Success rate %, time-to-fill exato, reten√ß√£o cliente

Pergunta 1: Success rate √© p√∫blico?
‚Üí N√ÉO. Consultoria nunca divulga (vantagem competitiva).

Pergunta 2: H√° proxy?
‚Üí SIM. 'Ciclo 3-4 meses' √© proxy razo√°vel para efici√™ncia operacional.

Pergunta 3: Objective principal respondido?
‚Üí SIM. 'M√©tricas operacionais' = entender rapidez/qualidade.
   Proxy + portf√≥lio respondem suficientemente.

Decis√£o: DONE (coverage ajustado 0.50 ‚Üí 0.70)
Reasoning: 'M√©tricas exatas s√£o privadas para este setor.
            Proxies dispon√≠veis (ciclos declarados) s√£o suficientes.'

‚ö†Ô∏è N√ÉO force refinamento para achar dados que voc√™ SABE serem privados.

üí° **EXEMPLO 1 - DONE COM LACUNAS SECUND√ÅRIAS (boutiques privadas):**

Objetivo: "Mapear posicionamento de EXEC, Vila Nova Partners, Flow EF no Brasil"
Encontrado: 
- EXEC: 250+ placements/ano, fundada 2009, expans√£o 4 s√≥cios 2024, setores diversos
- Vila Nova: foco Energy/Industrial, parceiro 10 anos exp
- Flow EF: PE/VC focused, fundada 2011, unfunded

Faltando: TAM exato setor, pricing das boutiques, receita anual, margens

Pergunta 1: TAM/pricing/receita s√£o p√∫blicos para boutiques privadas?
‚Üí N√ÉO. Boutiques privadas raramente divulgam dados financeiros.

Pergunta 2: H√° proxies?
‚Üí SIM. Volume operacional (250+ placements), setores atendidos, funding status, expans√£o estrat√©gica.

Decis√£o: DONE (coverage 0.65 ‚Üí ajustado 0.75 com proxies)
Reasoning: "Posicionamento das tr√™s boutiques mapeado com evid√™ncias operacionais. Lacunas (TAM, pricing, receita) s√£o dados privados; proxies dispon√≠veis respondem ao objetivo de mapeamento competitivo."

üí° **EXEMPLO 2 - DONE COM DADOS QUALITATIVOS (estudo de setor):**

Objetivo: "Entender din√¢mica competitiva setor XYZ no Brasil"
Encontrado: 
- 5 players principais identificados com market share relativo (fontes: 3 reports setoriais)
- Tend√™ncias 2023-2024: consolida√ß√£o (2 fus√µes), entrada player internacional
- Drivers: regula√ß√£o X (2023), demanda segmento Y +30%

Faltando: Market share exato (%), receita por player, forecasts 2025-2027

Pergunta 1: Market share exato √© p√∫blico?
‚Üí PARCIAL. Reports setoriais d√£o ranking ordinal, n√£o percentuais exatos.

Pergunta 2: Ranking + tend√™ncias respondem ao objetivo?
‚Üí SIM. "Din√¢mica competitiva" = entender posi√ß√µes relativas e movimentos estrat√©gicos.

Decis√£o: DONE (coverage 0.70)
Reasoning: "Ranking ordinal, fus√µes/aquisi√ß√µes e drivers regulat√≥rios mapeiam adequadamente a din√¢mica competitiva. Percentuais exatos n√£o alteram compreens√£o estrat√©gica."

üí° **EXEMPLO 3 - REFINE JUSTIFICADO (lacunas cr√≠ticas p√∫blicas):**

Objetivo: "Avaliar conformidade empresa X com regula√ß√£o Y"
Encontrado: 
- Empresa X mencionada em 2 not√≠cias gen√©ricas sobre setor
- Regula√ß√£o Y descrita (oficial gov.br)

Faltando: Certifica√ß√µes empresa X, auditorias, processos regulat√≥rios, declara√ß√µes conformidade

Pergunta 1: Certifica√ß√µes/auditorias s√£o p√∫blicas?
‚Üí SIM. Empresas reguladas divulgam certifica√ß√µes ISO, auditorias anuais.

Pergunta 2: Procuramos bem?
‚Üí N√ÉO. Apenas agregadores visitados; falta site oficial empresa X, portal regulador.

Decis√£o: REFINE
Next_query: "Empresa X certifica√ß√µes ISO auditorias conformidade regula√ß√£o Y Brasil site oficial"
Reasoning: "Dados de conformidade s√£o p√∫blicos para empresas reguladas. Fontes visitadas foram insuficientes; necess√°rio buscar site oficial e portal regulador."

üìä **AJUSTE DE COVERAGE POR PROXIES (PRAGM√ÅTICO):**

Quando lacunas s√£o **dados privados para o setor** mas h√° **proxies √∫teis**, ajuste coverage mentalmente:

**Exemplo 1 - Boutiques Executive Search:**
- Raw coverage: 0.60 (60% perguntas com resposta direta)
- Lacunas: TAM exato, pricing, receita (PRIVADOS para boutiques)
- Proxies: Volume operacional (250+ placements), setores, expans√£o estrat√©gica, funding
- **Ajuste: +15% ‚Üí Coverage efetivo 0.75** ‚Üí Propor DONE

**Exemplo 2 - Startup Pr√©-S√©rie A:**
- Raw coverage: 0.55 (55% perguntas respondidas)
- Lacunas: Receita, valuation, cap table (PRIVADOS pr√©-IPO)
- Proxies: Funding rodada (p√∫blico), team size (LinkedIn), clientes mencionados (press)
- **Ajuste: +10% ‚Üí Coverage efetivo 0.65** ‚Üí Propor DONE

**Exemplo 3 - Empresa Regulada (dados p√∫blicos faltando):**
- Raw coverage: 0.50
- Lacunas: Certifica√ß√µes ISO, auditorias compliance (P√öBLICOS esperados)
- Proxies: Nenhum proxy v√°lido para compliance
- **Ajuste: 0% ‚Üí Coverage 0.50** ‚Üí Propor REFINE (dados p√∫blicos n√£o encontrados)

**CRIT√âRIO:**
- Proxies respondem ‚â•70% do valor informacional da lacuna ‚Üí +15% ajuste
- Proxies respondem 40-69% do valor informacional ‚Üí +10% ajuste  
- Proxies <40% ou lacuna √© dado p√∫blico ‚Üí 0% ajuste (manter raw coverage)

üå≤ **QUANDO USAR NEW_PHASE:**
- Lacunas essenciais + 2 loops flat ‚Üí √¢ngulo esgotado
- Coverage <50% + 2 loops flat ‚Üí hip√≥teses erradas
- Blind spots que INVALIDAM premissas (loops‚â•1) ‚Üí contexto mudou
- Entidades ausentes + loops‚â•2 ‚Üí NEW_PHASE focada
- Contradi√ß√µes persistentes (2+ loops) ‚Üí fonte oficial
- Janela temporal errada ‚Üí ajustar per√≠odo
**SEN√ÉO ‚Üí REFINE ou DONE**

**EXEMPLOS:**

**NEW_PHASE por blind spot cr√≠tico:**
- Descoberta: "Processo SEC contra Heidrick 2024" invalida premissa "reputa√ß√£o s√≥lida"
- seed_query: "Processos regulat√≥rios SEC lit√≠gios trabalhistas executive search 2023-2024 impactos"
- por_que: "Fases anteriores focaram perfis comerciais; dimens√£o regulat√≥ria ausente"

**REFINE para lacunas espec√≠ficas:**
- Lacuna MERCADO: "Tamanho e participa√ß√£o boutiques vs internacionais Brasil 2022-2024"
- Lacuna EMPRESAS: "Portf√≥lio servi√ßos rankings Flow EF Vila Nova Brasil"
- ‚ùå N√ÉO: "Buscar dados" (gen√©rico) ou "Korn Ferry" (entidade n√£o priorizada)

**ESTRAT√âGIA DE REFINEMENT ANTI-REDUND√ÇNCIA (CR√çTICO):**

‚ö†Ô∏è **SE AP√ìS 2 LOOPS COM POUCAS URLs NOVAS** ‚Üí MUDE A FONTE, N√ÉO APENAS OS TERMOS!

**√ÇNGULOS DE BUSCA (ordenados por probabilidade de sucesso):**

1. **FONTE DIRETA (buscar em empresas/produtos mencionados)**
   - Exemplo: "Vila Nova Partners LinkedIn about team size"
   - Exemplo: "Heidrick Struggles Brazil earnings revenue 2023"

2. **FONTE SETORIAL (associa√ß√µes, relat√≥rios de mercado)**
   - Exemplo: "ABRH relat√≥rio mercado RH Brasil estat√≠sticas"
   - Exemplo: "SHRM Brazil talent acquisition report"

3. **FONTE PROXY (dados relacionados que inferem a resposta)**
   - Exemplo: "custo contrata√ß√£o executivo Brasil sal√°rio C-level"
   - Exemplo: "tempo m√©dio hiring senior leadership Brazil"

4. **FONTE COMPARATIVA (benchmarks setoriais)**
   - Exemplo: "market share consultoria RH Brasil ranking"
   - Exemplo: "top headhunters Brazil comparison"

**REGRAS ANTI-DUPLICA√á√ÉO:**
- ‚ùå N√ÉO trocar sin√¥nimos: "tamanho" ‚Üí "valor" ‚Üí "faturamento" S√ÉO A MESMA QUERY!
- ‚ùå N√ÉO apenas adicionar ano: "mercado Brasil" ‚Üí "mercado Brasil 2023" GERA MESMAS URLs!
- ‚úÖ MUDAR FONTE: "tamanho mercado" ‚Üí "ABRH relat√≥rio setor RH" ‚Üí URLs NOVAS!
- ‚úÖ MUDAR √ÇNGULO: "volume total" ‚Üí "custo m√©dio por contrata√ß√£o" ‚Üí PROXY DIFERENTE!

**PRINC√çPIO**: Se ap√≥s 2 loops ainda faltam dados, provavelmente s√£o **privados/n√£o publicados**.
‚Üí Busque PROXIES ou considere DONE (dados parciais s√£o √∫teis).

‚ö†Ô∏è **ENTIDADES AMB√çGUAS (contexto setorial obrigat√≥rio):**

Se entidade pode ter m√∫ltiplos significados ‚Üí INCLUIR setor/ind√∫stria na query

**Entidades amb√≠guas t√≠picas:**
- Nomes muito curtos (‚â§4 chars): "Exec", "Flow", "Link", "Run"
- Palavras comuns em ingl√™s/tech: "exec", "search", "data", "flow"

**REGRA CR√çTICA:**
- Se next_query mencionar entidade com NOME GEN√âRICO/CURTO (‚â§4 chars OU palavra comum)
- E query N√ÉO cont√©m contexto setorial
- ‚Üí ADICIONAR contexto setorial no in√≠cio

**Exemplos:**
‚úÖ CORRETO:
  - "executive search Exec aquisi√ß√£o Brasil" (desambigua: Exec = consultoria)
  - "fintech Nubank receita Brasil" (desambigua: Nubank = banco)
  - "headhunting Flow EF posicionamento Brasil" (desambigua: Flow = consultoria)

‚ùå INCORRETO (amb√≠guo):
  - "Exec aquisi√ß√£o Brasil" ‚Üí pode ser fun√ß√£o exec() programa√ß√£o
  - "Flow aquisi√ß√£o Brasil" ‚Üí pode ser flow de dados
  - "Run receita Brasil" ‚Üí pode ser fun√ß√£o run()

**Como adicionar contexto:**
1. Identifique o setor principal da pesquisa (do contract/fase)
2. Mapeamento setor ‚Üí termo:
   - RH/Headhunting ‚Üí "executive search" ou "headhunting"
   - Tech/Software ‚Üí "software" ou "tecnologia" ou "startup"
   - Finance ‚Üí "fintech" ou "banco" ou "cr√©dito"
3. Prefixe a query com o termo setorial

**Exemplo de corre√ß√£o:**
- Query proposta: "Exec aquisi√ß√£o 90 dias Brasil"
- Setor detectado: RH/Headhunting
- Query corrigida: "executive search Exec aquisi√ß√£o 90 dias Brasil"

üö® **NEXT_QUERY: 1 frase rica (‚â§150 chars, SEM operadores)**
- Contexto completo: aspecto + setor/entidades + geo + per√≠odo
- MERCADO: "<aspecto> mercado <setor> <geo> <per√≠odo>"
- EMPRESAS: "<aspecto> <entidades priorizadas> <geo> <per√≠odo>"
- ‚ùå "buscar dados" (gen√©rico) | operadores (site:, filetype:) | entidades n√£o-priorizadas
{entities_block}
{analyst_proposals_block}
**OBJETIVO DA FASE:** {user_prompt}

**AN√ÅLISE DO ANALYST:**
{json.dumps(analysis, ensure_ascii=False, indent=2)}

‚ö†Ô∏è **PR√â-JSON CHECKLIST:**
- verdict=REFINE ‚Üí next_query espec√≠fica (mercado OU entidades priorizadas, ‚â§150 chars, sem operadores)
- verdict=NEW_PHASE ‚Üí seed_query contextualizada (responde blind spot + contrasta fases anteriores)
- selected_index ‚Üí escolher op√ß√£o do Analyst (se aplic√°vel) OU criar pr√≥pria (deixar null)

üî¥ **VALIDA√á√ÉO CR√çTICA PARA REFINE:**
- Se verdict=refine, next_query DEVE incluir ‚â•1 entidade das listadas acima
- ‚ùå REJEITAR queries gen√©ricas como "mercado executive search Brasil" (sem entidades)
- ‚úÖ ACEITAR queries espec√≠ficas como "Exec Vila Nova portf√≥lio servi√ßos Brasil" (com entidades)

**SA√çDA JSON:**
{{
  "verdict": "done|refine|new_phase",
  "reasoning": "<1-2 frases CONSISTENTES com verdict>",
  "selected_index": <int or null>,  // ‚Üê NOVO: √≠ndice da op√ß√£o escolhida (se aplic√°vel)
  "key_questions_status": {{
    "relevant_to_phase": [<√≠ndices>],
    "answered_in_phase": [<√≠ndices>],
    "unanswered_in_phase": [<√≠ndices>],
    "coverage": <0.0-1.0>,
    "blind_spots": ["<descobertas cr√≠ticas>"]
  }},
  "refine": {{
    "next_query": "<3-8 palavras, SEM operadores>",  // Short for UI/telemetry
    "seed_core": "<12-200 chars, 1 frase rica, SEM operadores, contexto completo>",  // Rich for Discovery
    "focused_objective": "<objetivo espec√≠fico focado na lacuna>",  // Focused objective
    "por_que": ["<lacuna A>", "<lacuna B>"],
    "operadores_sugeridos": []  // DEPRECATED - n√£o use
  }},
  "new_phase": {{
    "objective": "<objetivo mensur√°vel>",
    "seed_query": "<1 frase rica ‚â§150 chars, SEM operadores, POSITIVA>",
    "por_que": "<por que n√£o cabe na fase atual>",
    "phase_type": "industry|profiles|news|regulatory|technical"
  }},
  "unexpected_findings": ["<descoberta 1>"]
}}

‚ö†Ô∏è **SEED_CORE (OBRIGAT√ìRIO para refine E new_phase):**
- Formato: 1 frase rica (12-200 chars), linguagem natural, SEM operadores
- Inclui: entidades + tema + aspecto + recorte geotemporal
- Contexto completo para Discovery Tool executar busca efetiva
- Exemplos:
  ‚úÖ "Flow Executive Finders posicionamento competitivo e portf√≥lio de servi√ßos no mercado brasileiro de executive search 2023-2024"
  ‚úÖ "M√©tricas operacionais e taxas de sucesso de boutiques de headhunting no Brasil √∫ltimos 12 meses fontes verific√°veis"
  ‚ùå "Flow CNPJ Brasil" (muito curta, sem contexto)

**FOCUSED_OBJECTIVE (OBRIGAT√ìRIO para refine):**
- Reescreva o objective da fase para FOCAR na lacuna espec√≠fica
- Use o reasoning + lacunas para criar objective direcionado
- Exemplo:
  Original: "Mapear portf√≥lio e posicionamento de Flow Executive no Brasil"
  Lacuna: "Falta CNPJ oficial e data de funda√ß√£o"
  ‚Üí focused_objective: "Obter CNPJ oficial, raz√£o social completa e data de registro da Flow Executive Finders no Brasil via Receita Federal ou CNPJ.info"

‚ö†Ô∏è **CONSIST√äNCIA REASONING ‚Üî VERDICT (VALIDA√á√ÉO CR√çTICA):**

**CORRETO (reasoning alinhado com verdict):**
‚úÖ verdict=DONE + reasoning="Evid√™ncias s√≥lidas sobre posicionamento (250+ placements EXEC, setores VN, perfil Flow). Lacunas (TAM, pricing) s√£o dados privados; proxies respondem ao objetivo."
‚úÖ verdict=REFINE + reasoning="Fatos gen√©ricos sem especificidade. Lacunas cr√≠ticas (certifica√ß√µes ISO, auditorias) impedem avaliar conformidade. Dados s√£o p√∫blicos mas n√£o foram encontrados."

**INCORRETO (contradi√ß√£o interna):**
‚ùå verdict=DONE + reasoning="Faltam dados essenciais sobre TAM e pricing..." ‚Üí CONTRADI√á√ÉO (reasoning insatisfeito + verdict satisfeito)
‚ùå verdict=REFINE + reasoning="H√° evid√™ncias s√≥lidas sobre capacidades..." ‚Üí CONTRADI√á√ÉO (reasoning satisfeito + verdict insatisfeito)

**REGRA DE OURO:**
- Reasoning menciona "evid√™ncias s√≥lidas" / "dados substanciais" / "proxies suficientes" ‚Üí verdict DEVE ser DONE
- Reasoning menciona "faltam dados cr√≠ticos" / "lacunas impedem resposta" / "evid√™ncias fracas" ‚Üí verdict DEVE ser REFINE/NEW_PHASE
- Se racioc√≠nio diz "MAS falta X" ‚Üí Pergunte: X √© privado? X tem proxy? Se sim ‚Üí DONE

Retorne APENAS o JSON."""


# MOVED (v4.5): _extract_contract_from_history ‚Üí agora √© m√©todo da classe Pipe (linha ~4690)
# Corrigido AttributeError quando usu√°rio digita "siga"


class PlannerLLM:
    def __init__(self, valves):
        self.valves = valves
        # Usar modelo espec√≠fico se configurado, sen√£o usa modelo padr√£o
        model = valves.LLM_MODEL_PLANNER or valves.LLM_MODEL
        self.model_name = model
        self.llm = _get_llm(valves, model_name=model)
        # Base kwargs: ser√£o filtrados por get_safe_llm_params
        self.generation_kwargs = {"temperature": 0}

    def _build_prompt(
        self,
        user_prompt: str,
        phases: int,
        current_date: Optional[str] = None,
        detected_context: Optional[dict] = None,
    ) -> str:
        """Use unified Planner prompt."""
        return _build_planner_prompt(
            user_prompt,
            phases,
            current_date=current_date,
            detected_context=detected_context,
        )

    async def _generate_seed_core_with_llm(
        self, phase: dict, entities: List[str], geo_bias: List[str]
    ) -> Optional[str]:
        """Gera seed_core usando LLM (1 frase rica, sem operadores).

        Args:
            phase: Dicion√°rio com objective, seed_family_hint
            entities: Lista de entidades can√¥nicas
            geo_bias: Lista de bias geogr√°fico (ex: ["BR", "global"])

        Returns:
            seed_core string ou None se falhar
        """
        try:
            objective = phase.get("objective", "")[:150]
            seed_family = phase.get("seed_family_hint", "entity-centric")

            # Templates por fam√≠lia (orientar LLM)
            family_templates = {
                "entity-centric": "entidade + tema + recorte geotemporal",
                "problem-centric": "problema/risco + drivers/causas + contexto",
                "outcome-centric": "efeito/resultado + indicadores + stakeholders",
                "regulatory": "norma/regulador + exig√™ncias + abrang√™ncia",
                "counterfactual": "tese/controv√©rsia + obje√ß√£o + evid√™ncia-chave",
            }

            template = family_templates.get(seed_family, "entidade + tema + contexto")
            entities_str = ", ".join(entities[:3]) if entities else "N/A"
            geo_str = ", ".join(geo_bias[:2]) if geo_bias else "Brasil"

            prompt = f"""Gere seed_core (1 frase, 12-200 chars, sem operadores).

OBJETIVO: {objective}
ENTIDADES: {entities_str}
GEO: {geo_str}
FAM√çLIA: {seed_family} ‚Üí {template}

REGRAS:
- SEM operadores (site:, filetype:, after:, before:)
- Linguagem natural, clara
- Incluir 1-2 entidades can√¥nicas
- Incluir geo quando relevante

SA√çDA (JSON puro):
{{"seed_core": "sua frase aqui"}}"""

            # Chamar LLM com timeout curto (20s)
            safe_kwargs = get_safe_llm_params(self.model_name, self.generation_kwargs)
            safe_kwargs["request_timeout"] = 20

            result = await asyncio.wait_for(
                self.llm.run(prompt, generation_kwargs=safe_kwargs),
                timeout=25,  # 25s total (20s HTTP + 5s margem)
            )

            if not result or "content" not in result:
                logger.warning("[Planner] LLM seed_core: resposta vazia")
                return None

            content = result["content"].strip()

            # Parse JSON
            parsed = parse_json_resilient(content)
            if not parsed or not isinstance(parsed, dict):
                logger.warning(
                    f"[Planner] LLM seed_core: JSON inv√°lido - {content[:100]}"
                )
                return None

            seed_core = parsed.get("seed_core", "").strip()

            # Validar
            if not seed_core or len(seed_core) < 12 or len(seed_core) > 200:
                logger.warning(
                    f"[Planner] LLM seed_core: tamanho inv√°lido ({len(seed_core)} chars)"
                )
                return None

            # Verificar operadores proibidos
            forbidden_ops = ["site:", "filetype:", "after:", "before:"]
            if any(op in seed_core for op in forbidden_ops):
                logger.warning(
                    f"[Planner] LLM seed_core cont√©m operadores proibidos: {seed_core}"
                )
                return None

            logger.info(
                f"[Planner] LLM seed_core gerado com sucesso: '{seed_core[:80]}...'"
            )
            return seed_core

        except asyncio.TimeoutError:
            logger.warning("[Planner] LLM seed_core: timeout ap√≥s 25s")
            return None
        except Exception as e:
            logger.warning(f"[Planner] LLM seed_core falhou: {e}")
            return None

    def _validate_contract(self, obj: dict, phases: int, user_prompt: str) -> dict:
        """Valida e normaliza o contrato do novo formato JSON

        Args:
            phases: M√°ximo de fases permitidas (n√£o obrigat√≥rio atingir)
        """
        phases_list = obj.get("phases", [])
        intent_profile = obj.get("intent_profile", "company_profile")

        if not phases_list:
            raise ValueError("Nenhuma fase encontrada")

        # Validar n√∫mero de fases (pode ser MENOS que o m√°ximo, mas n√£o MAIS)
        if len(phases_list) > phases:
            raise ValueError(
                f"Excesso de fases: {len(phases_list)} > {phases} (m√°ximo permitido)"
            )

        # Aceitar qualquer quantidade ‚â•1 e ‚â§ phases (flexibilidade para o Planner decidir)

        # Defaults do perfil
        profile_defaults = getattr(self.valves, "PROFILE_DEFAULTS", {})
        profile = (
            intent_profile if intent_profile in profile_defaults else "company_profile"
        )
        defaults = profile_defaults.get(profile, {})

        # Validar cada fase
        validated_phases = []
        for i, phase in enumerate(phases_list, 1):
            # Validar campos obrigat√≥rios
            required_fields = [
                "name",
                "objective",
                "seed_query",
                "seed_core",
                "must_terms",
                "avoid_terms",
                "time_hint",
                "source_bias",
                "evidence_goal",
                "lang_bias",
                "geo_bias",
            ]

            for field in required_fields:
                if field not in phase:
                    raise ValueError(f"Fase {i} falta campo obrigat√≥rio: {field}")

            # Validar seed_query (3-6 palavras, sem operadores)
            seed_query = phase["seed_query"].strip()
            # Se for fase de not√≠cias, garantir @noticias na seed (para Discovery news mode)
            try:
                if getattr(self.valves, "FORCE_NEWS_SEED_ATNOTICIAS", True):
                    name_obj = (
                        f"{phase.get('name','')} {phase.get('objective','')}".lower()
                    )
                    news_keys = [
                        "not√≠cia",
                        "noticias",
                        "not√≠cias",
                        "news",
                        "aquisi√ß√£o",
                        "fus√µes",
                        "fus√£o",
                        "mudan√ßas de lideran√ßa",
                        "nomea",
                        "eventos",
                    ]
                    is_news_phase_name = any(k in name_obj for k in news_keys)
                    is_news_seed = "@noticias" in seed_query.lower()
                    if is_news_phase_name and not is_news_seed:
                        # Prefixar com @noticias mantendo regra de 3-6 palavras (permite o token especial)
                        seed_words = seed_query.split()
                        # Se a seed ficar maior que 6, cortar √∫ltimo termo
                        updated = ["@noticias"] + seed_words
                        if len(updated) > 6:
                            updated = updated[:6]
                        seed_query = " ".join(updated)
                        phase["seed_query"] = seed_query
                        # Nota: seed_core ser√° sincronizado DEPOIS da gera√ß√£o (linha ~4273)
            except Exception:
                pass
            # Validar seed_query (3-8 palavras, SEM contar @noticias) - Ajustado para nomes de empresas
            clean_words = [
                w for w in seed_query.split() if w.lower() != "@noticias" and w.strip()
            ]
            if len(clean_words) < 3 or len(clean_words) > 8:
                raise ValueError(
                    f"Fase {i}: seed_query (sem @noticias) deve ter 3-8 palavras, tem {len(clean_words)} palavras: {clean_words}"
                )

            # Validar proibi√ß√£o de operadores
            forbidden_ops = [
                "site:",
                "filetype:",
                "after:",
                "before:",
                "AND",
                "OR",
                '"',
                "'",
            ]
            for op in forbidden_ops:
                if op in seed_query:
                    raise ValueError(
                        f"Fase {i}: seed_query n√£o pode conter operador '{op}'"
                    )

            # üî¥ P0: Validar POL√çTICA ENTITY-CENTRIC (seed_query deve conter entidades)
            entities = obj.get("entities", {}).get("canonical", [])
            must_terms = phase["must_terms"]

            # ‚úÖ P0.1: Validar must_terms cont√©m entidades (j√° existia)
            if entities and not any(
                entity.lower() in " ".join(must_terms).lower() for entity in entities
            ):
                # Warning, n√£o erro
                logger.warning(
                    f"[PLANNER] Fase {i}: must_terms pode n√£o conter entidades can√¥nicas"
                )

            # üî¥ P0.2: CRITICAL - Validar seed_query cont√©m entidades (NOVO)
            # Se ‚â§3 entidades E fase √© entity-centric ‚Üí OBRIGAT√ìRIO incluir na seed_query
            phase_type = phase.get("phase_type", "")
            entity_centric_types = ["industry", "profiles", "financials"]

            if (
                len(entities) <= 3
                and len(entities) > 0
                and phase_type in entity_centric_types
                and "@noticias" not in seed_query.lower()
            ):  # News pode usar @noticias em vez de entidades

                # Verificar se TODAS as entidades principais aparecem na seed_query
                seed_lower = seed_query.lower()
                missing_entities = []

                for entity in entities[:3]:  # Apenas as 3 primeiras (principais)
                    # Verificar se o nome (ou primeira palavra) aparece
                    entity_tokens = entity.split()
                    first_word = entity_tokens[0].lower()

                    # Aceitar se qualquer token significativo da entidade aparece
                    if not any(
                        token.lower() in seed_lower
                        for token in entity_tokens
                        if len(token) > 2
                    ):
                        missing_entities.append(entity)

                if missing_entities and getattr(
                    self.valves, "ENTITY_COVERAGE_STRICT", True
                ):
                    # HARD FAIL (default)
                    raise ValueError(
                        f"Fase {i} ({phase.get('name', 'sem nome')}): seed_query DEVE conter as entidades principais.\n"
                        f"Pol√≠tica entity-centric: ‚â§3 entidades ‚Üí incluir TODAS na seed_query.\n"
                        f"Entidades faltando: {missing_entities}\n"
                        f"seed_query atual: '{seed_query}'\n"
                        f"Sugest√£o: '{' '.join(entities[:3])} {seed_query}'"
                    )
                elif missing_entities:
                    # SOFT WARNING (se strict=False)
                    logger.warning(
                        f"[PLANNER] Fase {i}: seed_query pode violar pol√≠tica entity-centric. "
                        f"Entidades faltando: {missing_entities}. seed_query: '{seed_query}'"
                    )

            # Validar avoid_terms n√£o sobrep√µe must_terms
            avoid_terms = phase["avoid_terms"]
            overlap = set(must_terms) & set(avoid_terms)
            if overlap:
                raise ValueError(
                    f"Fase {i}: must_terms e avoid_terms sobrep√µem: {overlap}"
                )

            # Validar time_hint
            time_hint = phase.get("time_hint") or defaults.get(
                "time_hint", {"recency": "1y", "strict": False}
            )
            # Se a seed_query tiver @noticias, planner define janela e strict=True
            if "@noticias" in seed_query.lower():
                # Priorizar recency do planner; se ausente, default para 1y
                rec = time_hint.get("recency") or "1y"
                if rec not in ["90d", "1y", "3y"]:
                    rec = "1y"
                time_hint = {"recency": rec, "strict": True}
            # REMOVIDO: Enforcement r√≠gido de news window (v4.2)
            # RAZ√ÉO: Em estudos de mercado, Planner deve criar 2 fases separadas:
            #   - Fase "tend√™ncias/evolu√ß√£o" com 1y (captura 12 meses)
            #   - Fase "breaking news" com 90d (eventos pontuais)
            # For√ßar 1y aqui impede o Planner de criar a arquitetura correta.
            # A valida√ß√£o agora √© feita via prompt guidance + key_questions coverage check.

            if "recency" not in time_hint or time_hint["recency"] not in [
                "90d",
                "1y",
                "3y",
            ]:
                raise ValueError(f"Fase {i}: time_hint.recency deve ser 90d, 1y ou 3y")

            # P1: Validate seed_core (should be provided by Planner LLM now)
            seed_core = phase.get("seed_core", "").strip()
            
            if not seed_core or len(seed_core) < 12:
                logger.warning(f"[PLANNER] Phase '{phase.get('name', 'unnamed')}' missing valid seed_core (len={len(seed_core) if seed_core else 0}), using fallback")
                # Keep minimal fallback for edge cases only
                canonical = obj.get("entities", {}).get("canonical", [])
                objective_words = phase["objective"].split()[:10]
                seed_core = f"{' '.join(canonical[:2])} {seed_query} {objective_words}".strip()[:200]
                seed_core_source = "orchestrator_fallback"
            else:
                seed_core_source = "planner_llm"  # From LLM

            # Store seed_core and source for telemetry
            phase["seed_core"] = seed_core
            phase["seed_core_source"] = seed_core_source
            
            # Log seed_core source for telemetry
            logger.info(
                f"[SEED][TELEMETRY] Fase {i}: seed_core source={seed_core_source}, len={len(seed_core)}"
            )

            # üîß FIX: Sincronizar seed_core quando @noticias estiver presente em seed_query
            # IMPORTANTE: Fazer DEPOIS da gera√ß√£o de seed_core para evitar sobrescrita
            try:
                if "@noticias" in seed_query.lower():
                    current_seed_core = phase.get("seed_core", "")
                    if (
                        current_seed_core
                        and "@noticias" not in current_seed_core.lower()
                    ):
                        phase["seed_core"] = f"@noticias {current_seed_core}"
                        logger.info(
                            f"[PLANNER] Fase {i}: @noticias adicionado ao seed_core (fase de not√≠cias detectada)"
                        )
            except Exception as e:
                logger.warning(
                    f"[PLANNER] Erro ao sincronizar @noticias no seed_core: {e}"
                )

            # ‚úÖ v4.7: Garantir seed_family_hint (default: entity-centric)
            seed_family_hint = phase.get("seed_family_hint", "entity-centric")
            if not seed_family_hint or seed_family_hint not in [
                "entity-centric",
                "problem-centric",
                "outcome-centric",
                "regulatory",
                "counterfactual",
            ]:
                seed_family_hint = "entity-centric"
                phase["seed_family_hint"] = seed_family_hint

            # Validar source_bias
            valid_sources = ["oficial", "primaria", "secundaria", "terciaria"]
            source_bias = phase.get("source_bias") or defaults.get(
                "source_bias", ["oficial", "primaria", "secundaria"]
            )
            if not all(s in valid_sources for s in source_bias):
                raise ValueError(
                    f"Fase {i}: source_bias deve conter apenas: {valid_sources}"
                )

            # Validar evidence_goal
            evidence_goal = phase.get("evidence_goal") or {
                **{"official_or_two_independent": True},
                **defaults.get("evidence_goal", {"min_domains": 3}),
            }
            if (
                "official_or_two_independent" not in evidence_goal
                or "min_domains" not in evidence_goal
            ):
                raise ValueError(
                    f"Fase {i}: evidence_goal deve conter official_or_two_independent e min_domains"
                )

            validated_phases.append(
                {
                    "id": i,
                    "objetivo": phase["objective"],
                    "query_sugerida": seed_query,  # Para compatibilidade
                    "name": phase["name"],
                    "seed_query": seed_query,
                    "seed_core": phase.get("seed_core", ""),  # ‚úÖ v4.7
                    "seed_family_hint": phase.get(
                        "seed_family_hint", "entity-centric"
                    ),  # ‚úÖ v4.7
                    "must_terms": must_terms,
                    "avoid_terms": avoid_terms,
                    "time_hint": time_hint,
                    "source_bias": source_bias,
                    "evidence_goal": evidence_goal,
                    "lang_bias": phase.get("lang_bias")
                    or defaults.get("lang_bias", ["pt-BR", "en"]),
                    "geo_bias": phase.get("geo_bias")
                    or defaults.get("geo_bias", ["BR", "global"]),
                    "suggested_domains": phase.get("suggested_domains", []),  # ‚úÖ v4.7
                    "suggested_filetypes": phase.get(
                        "suggested_filetypes", []
                    ),  # ‚úÖ v4.7
                    "accept_if_any_of": [
                        f"Info sobre {phase['objective']}"
                    ],  # Para compatibilidade
                }
            )

        # üì∞ FASE 1: News Slot Telemetry (rastreia se news foi adicionada/pulada)
        news_slot_telemetry = {
            "attempted": False,
            "reason": "not_requested",
            "market_study_detected": False,
        }

        # P0 enhancement: Enforce automatic 12m news phase for market/study intents
        try:
            research_objectives = obj.get("research_objectives", []) or []
            intent_text = str(obj.get("intent", user_prompt or "")).lower()
            # detect keywords indicating a market study / panorama request
            market_terms = [
                "estudo",
                "mercado",
                "panorama",
                "mercados",
                "setor",
                "analysis",
                "an√°lise",
            ]
            is_market_study = any(t in intent_text for t in market_terms) or any(
                any(t in str(ro).lower() for t in market_terms)
                for ro in research_objectives
            )

            news_slot_telemetry["market_study_detected"] = is_market_study

            # Only enforce when there are >=3 phases planned (user requested multi-phase study)
            if is_market_study and len(validated_phases) >= 3:
                news_slot_telemetry["attempted"] = True

                # Check if a news-like phase already exists (by seed or by name/objective)
                news_present = False
                for p in validated_phases:
                    name_obj = f"{p.get('name','')} {p.get('objetivo','')}"
                    # look for @noticias or obvious news keywords
                    if "@noticias" in p.get("seed_query", "").lower() or any(
                        k in name_obj.lower()
                        for k in [
                            "not√≠cia",
                            "noticias",
                            "news",
                            "evento",
                            "fus√£o",
                            "aquisi√ß√£o",
                        ]
                    ):
                        news_present = True
                        break

                if news_present:
                    news_slot_telemetry["reason"] = "already_present"
                elif len(validated_phases) >= phases:
                    news_slot_telemetry["reason"] = "skipped_exceed_limit"
                    logger.warning(
                        f"[PLANNER] Skipping automatic news phase: would exceed allowed phases "
                        f"({len(validated_phases)+1} > {phases}). Consider increasing DEFAULT_PHASE_COUNT."
                    )
                else:
                    # Add news phase
                    # construct sensible central theme
                    central = (
                        obj.get("topic")
                        or obj.get("intent")
                        or user_prompt
                        or "noticias"
                    ).strip()
                    # take up to 3 significant words
                    words = [w for w in re.split(r"\W+", central) if w]
                    core = " ".join(words[:3]) if words else "noticias"
                    # build seed components ensuring 3-6 words excluding @noticias
                    seed_parts = (core + " Brasil").split()
                    # ensure between 3 and 6 words
                    if len(seed_parts) < 3:
                        seed_parts += ["noticias"]
                    if len(seed_parts) > 6:
                        seed_parts = seed_parts[:6]
                    seed_query_new = "@noticias " + " ".join(seed_parts)

                    new_phase = {
                        "id": len(validated_phases) + 1,
                        "objetivo": "Not√≠cias e eventos relevantes dos √∫ltimos 12 meses que impactam o tema",
                        "query_sugerida": seed_query_new,
                        "name": "Eventos & Not√≠cias (12m)",
                        "seed_query": seed_query_new,
                        "must_terms": [],
                        "avoid_terms": [],
                        "time_hint": {"recency": "1y", "strict": True},
                        "source_bias": defaults.get(
                            "source_bias", ["oficial", "primaria", "secundaria"]
                        ),
                        "evidence_goal": {
                            "official_or_two_independent": True,
                            "min_domains": max(self.valves.MIN_UNIQUE_DOMAINS, phases),
                        },
                        "lang_bias": defaults.get("lang_bias", ["pt-BR", "en"]),
                        "geo_bias": defaults.get("geo_bias", ["BR", "global"]),
                        "accept_if_any_of": ["Not√≠cias e eventos relevantes"],
                    }
                    validated_phases.append(new_phase)
                    news_slot_telemetry["reason"] = "added"
                    logger.info(
                        f"[PLANNER] Auto-added news phase: {len(validated_phases)}/{phases} phases"
                    )
        except Exception:
            # never fail contract validation for this enhancement; log and continue
            news_slot_telemetry["reason"] = "error"
            logger.exception("Failed to enforce automatic 12m news phase")

        if len(validated_phases) < 2:
            raise ValueError(f"Apenas {len(validated_phases)} fases")

        # ‚úÖ FIX: Final validation to ensure phases limit is never exceeded
        if len(validated_phases) > phases:
            raise ContractValidationError(
                f"Contract validation failed: {len(validated_phases)} phases exceed limit of {phases}. "
                f"This should not happen after the auto-addition fix. Please check the logic."
            )

        # üìã FASE 1: Entity Coverage Validation (Strict/Soft mode)
        entities_canonical = obj.get("entities", {}).get("canonical", [])
        contract_dict = {
            "versao": "3.0",
            "intent": obj.get("intent", f"Pesquisar: {user_prompt}"),
            "intent_profile": intent_profile,
            "entities": obj.get("entities", {"canonical": [], "aliases": []}),
            "fases": validated_phases,
            "quality_rails": obj.get(
                "quality_rails",
                {
                    "min_unique_domains": max(self.valves.MIN_UNIQUE_DOMAINS, phases),
                    "need_official_or_two_independent": self.valves.REQUIRE_OFFICIAL_OR_TWO_INDEPENDENT,
                },
            ),
            "budget": obj.get("budget", {"max_rounds": 2}),
            # üì∞ FASE 1: News slot telemetry
            "_news_slot_attempted": news_slot_telemetry["attempted"],
            "_news_slot_reason": news_slot_telemetry["reason"],
        }

        # üîß FASE 1: Seed Patch (se modo relax)
        seed_strict = getattr(self.valves, "SEED_VALIDATION_STRICT", False)
        if not seed_strict:
            for phase in validated_phases:
                _patch_seed_if_needed(phase, seed_strict, {}, logger)

        # Validar entity coverage usando helpers da FASE 1
        if entities_canonical:
            min_coverage = getattr(self.valves, "MIN_ENTITY_COVERAGE", 0.70)
            strict_mode = getattr(self.valves, "MIN_ENTITY_COVERAGE_STRICT", True)

            coverage = _calc_entity_coverage(validated_phases, entities_canonical)

            if coverage < min_coverage:
                if strict_mode:
                    # Hard-fail: lan√ßar exce√ß√£o
                    missing = _list_missing_entity_phases(
                        validated_phases, entities_canonical
                    )
                    raise ContractValidationError(
                        f"‚ùå ENTITY COVERAGE VIOLATION: Com {len(entities_canonical)} entidades, "
                        f"pelo menos {min_coverage:.0%} das fases devem incluir essas entidades em must_terms.\n"
                        f"Cobertura atual: {coverage:.0%}\n"
                        f"Entidades alvo: {entities_canonical}\n"
                        f"Fases sem entidades: {missing}\n"
                        f"üîß FIX: Inclua as entidades em must_terms de mais fases"
                    )
                else:
                    # Soft mode: warning + metadados no contract
                    _check_entity_coverage_soft(
                        contract_dict, entities_canonical, min_coverage, logger
                    )

        # ‚úÖ FASE 2: MECE Light Integration (P0.2)
        key_questions = obj.get("key_questions", [])
        if key_questions:
            uncovered = _check_mece_basic(validated_phases, key_questions)
            if uncovered:
                contract_dict["_mece_uncovered"] = uncovered
                logger.warning(
                    f"[MECE] {len(uncovered)} key_questions n√£o cobertas por nenhuma fase: {uncovered[:3]}"
                )
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[PLANNER][MECE] Key questions √≥rf√£s: {uncovered}")

        # ‚úÖ FASE 2: Economy Validation + TF-IDF Overlap Detection (Commit 6 + 8)
        actual_count = len(validated_phases)
        economy_threshold = getattr(self.valves, "PLANNER_ECONOMY_THRESHOLD", 0.75)

        # Layer 2 (Commit 8): Validar contador e justificativa (campos OPCIONAIS)
        declared_count = obj.get("total_phases_used", actual_count)  # Infere se ausente

        # Se fornecido, validar consist√™ncia
        if "total_phases_used" in obj and declared_count != actual_count:
            raise ContractValidationError(
                f"‚ùå Inconsist√™ncia: declarou {declared_count} fases em 'total_phases_used' "
                f"mas criou {actual_count} fases no array 'phases'. "
                f"Corrija o contador ou remova o campo (ser√° inferido automaticamente)."
            )

        # Log autom√°tico de economia (sempre)
        budget_pct = (actual_count / phases * 100) if phases > 0 else 0
        logger.info(
            f"[PLANNER][ECONOMY] {actual_count}/{phases} fases criadas ({budget_pct:.0f}% budget)"
        )

        # Warning se ‚â•80% budget SEM justificativa de economia
        if actual_count >= int(0.8 * phases):
            justification = obj.get("phases_justification", "").lower()
            economy_keywords = [
                "economia",
                "combinar",
                "comparativa",
                "suficiente",
                "necess√°rio",
                "econ√¥mico",
            ]
            has_economy_mention = any(kw in justification for kw in economy_keywords)

            if not has_economy_mention and justification:
                logger.warning(
                    f"[PLANNER][ECONOMY] Usou {actual_count}/{phases} fases (‚â•80%) mas justificativa n√£o menciona economia. "
                    f"Justificativa: '{obj.get('phases_justification', 'N/A')[:80]}'"
                )
            elif not justification:
                logger.warning(
                    f"[PLANNER][ECONOMY] Usou {actual_count}/{phases} fases (‚â•80%) SEM campo 'phases_justification'. "
                    f"Considere adicionar justificativa para auditoria."
                )

        # Soft warning se >threshold
        if actual_count > phases * economy_threshold:
            logger.warning(
                f"[PLANNER][ECONOMY] Usou {actual_count}/{phases} fases (>{economy_threshold*100:.0f}% budget) - Validando overlap..."
            )

            # TF-IDF overlap detection (reutilizar sklearn)
            try:
                from sklearn.feature_extraction.text import TfidfVectorizer
                from sklearn.metrics.pairwise import cosine_similarity

                phase_objectives = [p.get("objetivo", "") for p in validated_phases]
                overlap_threshold = getattr(
                    self.valves, "PLANNER_OVERLAP_THRESHOLD", 0.70
                )

                if len(phase_objectives) >= 2:
                    vectorizer = TfidfVectorizer()
                    vectors = vectorizer.fit_transform(phase_objectives)

                    # Matriz de similaridade
                    sim_matrix = cosine_similarity(vectors)

                    # Detectar pares com >overlap_threshold (excluir diagonal)
                    overlaps_found = []
                    for i in range(len(phase_objectives)):
                        for j in range(i + 1, len(phase_objectives)):
                            if sim_matrix[i][j] > overlap_threshold:
                                overlap_info = {
                                    "phase_i": i + 1,
                                    "phase_j": j + 1,
                                    "similarity": round(float(sim_matrix[i][j]), 3),
                                    "objective_i": phase_objectives[i][:80],
                                    "objective_j": phase_objectives[j][:80],
                                }
                                overlaps_found.append(overlap_info)

                                logger.warning(
                                    f"[PLANNER][OVERLAP] Fases {i+1} e {j+1} t√™m {sim_matrix[i][j]*100:.0f}% similaridade (>{overlap_threshold*100:.0f}%). "
                                    f"Considere combinar:\n"
                                    f"  - Fase {i+1}: {phase_objectives[i][:60]}...\n"
                                    f"  - Fase {j+1}: {phase_objectives[j][:60]}..."
                                )

                    if overlaps_found:
                        # Armazenar no contract para Judge/Synth usar
                        contract_dict["_overlap_warnings"] = overlaps_found
                        logger.info(
                            f"[PLANNER][OVERLAP] {len(overlaps_found)} pares de overlap detectados e armazenados no contract"
                        )
                    else:
                        logger.info(
                            f"[PLANNER][OVERLAP] Nenhum overlap significativo detectado (threshold={overlap_threshold*100:.0f}%)"
                        )

            except Exception as e:
                logger.debug(f"[PLANNER][OVERLAP] Detec√ß√£o falhou (n√£o-cr√≠tico): {e}")

        return contract_dict

    async def run(
        self,
        user_prompt: str,
        phases: int = 2,
        current_date: Optional[str] = None,
        previous_plan: Optional[str] = None,
        detected_context: Optional[dict] = None,
    ) -> Dict[str, Any]:
        if not self.llm:
            raise ValueError("LLM n√£o configurado")

        phases = max(2, min(10, int(phases or 2)))

        # Se houver plano anterior, contextualize para permitir refinamento
        if previous_plan:
            contextual_prompt = f"""PLANO ANTERIOR:
{previous_plan}

PEDIDO DE REFINAMENTO/AJUSTE:
{user_prompt}

INSTRU√á√ïES:
- Se o pedido for um refinamento/ajuste do plano anterior (ex: "pesquise not√≠cias de 2025", "adicione mais fases"), ATUALIZE o plano anterior
- Mantenha as fases existentes e ajuste apenas o que foi solicitado
- Se for um pedido COMPLETAMENTE NOVO (sem rela√ß√£o com o plano anterior), crie um novo plano
- Responda com o plano completo (anterior ajustado OU novo)"""
            prompt = self._build_prompt(
                contextual_prompt,
                phases,
                current_date=current_date,
                detected_context=detected_context,
            )
        else:
            prompt = self._build_prompt(
                user_prompt,
                phases,
                current_date=current_date,
                detected_context=detected_context,
            )

        for attempt in range(1, 3):
            try:
                # Base params (ser√£o filtrados para GPT-5/O1)
                base_params = dict(self.generation_kwargs)

                # JSON mode to reduce latency/noise
                if getattr(self.valves, "FORCE_JSON_MODE", True):
                    base_params["response_format"] = {"type": "json_object"}

                # Planner fast-read timeout (fail fast)
                prt = int(
                    getattr(
                        self.valves,
                        "PLANNER_REQUEST_TIMEOUT",
                        getattr(self.valves, "LLM_TIMEOUT_PLANNER", 180),
                    )
                    or 180
                )
                cap = int(getattr(self.valves, "HTTPX_READ_TIMEOUT", 180) or 180)
                base_params["request_timeout"] = max(20, min(prt, cap))

                # Filtrar par√¢metros incompat√≠veis com GPT-5/O1
                gen_kwargs = get_safe_llm_params(self.model_name, base_params)

                # Use retry function if enabled, otherwise single attempt
                if getattr(self.valves, "ENABLE_LLM_RETRY", True):
                    max_retries = int(getattr(self.valves, "LLM_MAX_RETRIES", 3) or 3)
                    out = await _safe_llm_run_with_retry(
                        self.llm,
                        prompt,
                        gen_kwargs,
                        timeout=int(
                            getattr(
                                self.valves,
                                "LLM_TIMEOUT_PLANNER",
                                self.valves.LLM_TIMEOUT_DEFAULT,
                            )
                            or self.valves.LLM_TIMEOUT_DEFAULT
                        ),
                        max_retries=max_retries,
                    )
                else:
                    out = await _safe_llm_run_with_retry(
                        self.llm,
                        prompt,
                        gen_kwargs,
                        timeout=int(
                            getattr(
                                self.valves,
                                "LLM_TIMEOUT_PLANNER",
                                self.valves.LLM_TIMEOUT_DEFAULT,
                            )
                            or self.valves.LLM_TIMEOUT_DEFAULT
                        ),
                        max_retries=1,
                    )
                if not out or not out.get("replies"):
                    raise ValueError("LLM vazio")

                obj = _extract_json_from_text(out["replies"][0])
                if not obj:
                    raise ValueError("JSON inv√°lido")

                contract = self._validate_contract(obj, phases, user_prompt)
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[Planner] {len(contract['fases'])} fases")

                return {"contract": contract, "contract_hash": _hash_contract(contract)}

            except (json.JSONDecodeError, ValueError, KeyError) as e:
                # Erros de parse/valida√ß√£o - tentar novamente
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[Planner] Tentativa {attempt} - Parse error: {e}")
                if attempt < 2:
                    # Retry with compact prompt (avoid appending error text)
                    prompt = _build_planner_prompt(
                        user_prompt,
                        phases,
                        current_date=current_date,
                        detected_context=detected_context,
                    )
                else:
                    raise ContractGenerationError(
                        f"Failed to generate valid contract after 3 attempts: {e}"
                    ) from e
            except ContractValidationError as e:
                # Erro de valida√ß√£o espec√≠fico - propagar
                raise
            except Exception as e:
                # Erro inesperado - tentar uma vez, depois propagar
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[Planner] Tentativa {attempt} - Unexpected error: {e}")
                if attempt < 2:
                    # Retry with compact prompt as above
                    prompt = _build_planner_prompt(
                        user_prompt,
                        phases,
                        current_date=current_date,
                        detected_context=detected_context,
                    )
                else:
                    raise ContractGenerationError(
                        f"Unexpected error generating contract: {e}"
                    ) from e


# ===== PiPeOpenaiPipe: OpenWebUI-style pipe compatible with existing pipes =====
# ===== Orchestrator with Cache and State (from PipeHay3) =====
class Orchestrator:
    """Orchestrator multi-fase com cache, acumula√ß√£o de contexto e m√©tricas de novidade

    RESPONSABILIDADES:
    - Executar itera√ß√µes de pesquisa: Discovery ‚Üí Scrape ‚Üí Reduce ‚Üí Analyze ‚Üí Judge
    - Manter cache de URLs scraped (evita re-scraping)
    - Acumular contexto filtrado de todas as fases (para Context Reducer)
    - Rastrear novidade global (fatos e dom√≠nios j√° usados)
    - Aplicar rails de qualidade do contrato a cada itera√ß√£o

    ESTADO GLOBAL:
    - contract: Plano completo com todas as fases (definido via set_contract())
    - all_phase_queries: Lista de queries de TODAS as fases (para Context Reducer)
    - scraped_cache: {url: content} - Cache persistente entre itera√ß√µes
    - filtered_accumulator: Contexto acumulado de todas as fases
    - used_claim_hashes: Set de hashes de fatos j√° vistos (novelty tracking)
    - used_domains: Set de dom√≠nios j√° consultados (novelty tracking)
    - intent_profile: Perfil de inten√ß√£o sincronizado com Pipe._detected_context

    INTEGRA√á√ÉO COM LLM COMPONENTS:
    - Analyst: Processa contexto acumulado completo (todas fases at√© agora)
    - Judge: Decide pr√≥ximo passo com gates program√°ticos + telemetria

    GERENCIAMENTO DE CONTRACT:
    - Contract armazenado em self.contract (N√ÉO _last_contract)
    - Definido via set_contract(contract) pelo Pipe
    - Usado para extrair entidades, rails e phase_context
    - Passado ao Judge para prevenir duplica√ß√£o de fases
    """

    def __init__(
        self,
        valves,
        discovery_call,
        scraper_call,
        context_reducer_call=None,
        job_id=None,
    ):
        self.valves = valves
        self.job_id = job_id

        self.discovery_tool = discovery_call
        self.scraper_tool = scraper_call
        self.context_reducer_tool = context_reducer_call

        self.analyst = AnalystLLM(valves)
        self.judge = JudgeLLM(valves)

        # v4.4: Deduplica√ß√£o centralizada
        self.deduplicator = Deduplicator(valves)

        # ===== ESTADO GLOBAL =====
        self.contract = None  # Plano completo (todas as fases)
        self.all_phase_queries = []  # TODAS as queries de TODAS as fases
        self.scraped_cache = {}  # {url: content} - Cache de URLs j√° scraped
        self.filtered_accumulator = ""  # Contexto filtrado acumulado
        # Novidade global
        self.used_claim_hashes: set[str] = set()
        self.used_domains: set[str] = set()

    def set_contract(self, contract: dict):
        """Define contrato e extrai TODAS as queries"""
        self.contract = contract
        self.all_phase_queries = [
            fase["query_sugerida"] for fase in contract.get("fases", [])
        ]
        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[Orchestrator] Contract set: {len(self.all_phase_queries)} queries")
        # Atualizar perfil de inten√ß√£o, se fornecido
        self.intent_profile = contract.get(
            "intent_profile", getattr(self, "_intent_profile", "company_profile")
        )

    def _extract_focus_entities(
        self, query: str, original_entities: List[str]
    ) -> List[str]:
        """
        Extrai entidades que est√£o presentes em uma query focada.
        Usado em refinamentos para reduzir pipe_must_terms apenas ao relevante.

        Usa matching por palavras + sin√¥nimos conhecidos para casos como "Exec" ‚Üí "executive".
        """
        query_lower = query.lower()
        focus_entities = []

        # Mapeamento de sin√¥nimos conhecidos (expans√≠vel)
        synonyms = {
            "exec": ["executive", "executivo", "executiva"],
            "flow ef": ["flowef", "flow"],
            "vila nova": ["vilanova"],
            # Adicionar mais conforme necess√°rio
        }

        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[FOCUS] Extra√ß√£o de entidades focadas:")
            print(f"[FOCUS] Query: '{query}'")
            print(f"[FOCUS] Entidades originais: {original_entities}")

        for entity in original_entities:
            entity_lower = entity.lower()
            entity_words = entity.split()

            # Tentativa 1: Match direto por palavras
            matched = any(
                word.lower() in query_lower for word in entity_words if len(word) > 2
            )

            if matched:
                focus_entities.append(entity)
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[FOCUS] ‚úÖ '{entity}' encontrada (match direto, palavras: {entity_words})"
                    )
                continue

            # Tentativa 2: Match por sin√¥nimos
            if entity_lower in synonyms:
                synonym_matched = any(
                    syn in query_lower for syn in synonyms[entity_lower]
                )
                if synonym_matched:
                    focus_entities.append(entity)
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[FOCUS] ‚úÖ '{entity}' encontrada (match por sin√¥nimo: {synonyms[entity_lower]})"
                        )
                    continue

            # Nenhum match
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[FOCUS] ‚ùå '{entity}' n√£o encontrada (palavras: {entity_words}, sin√¥nimos: {synonyms.get(entity_lower, 'N/A')})"
                )

        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[FOCUS] Entidades focadas extra√≠das: {focus_entities}")

        return focus_entities

    def _extract_entities_from_query(self, query: str) -> List[str]:
        """
        Extrai entidades preservando nomes compostos.
        
        Estrat√©gias:
        1. Quoted strings (entidades expl√≠citas)
        2. Multi-token proper nouns (2-3 palavras capitalizadas consecutivas)
        3. Single proper nouns (n√£o capturados acima)
        """
        import re
        
        entities = []
        
        # 1. Quoted entities (prioridade m√°xima)
        quoted = re.findall(r'"([^"]+)"', query)
        entities.extend(quoted)
        
        # 2. Extrair entidades multi-token de forma mais inteligente
        words = query.split()
        proper_nouns = []
        i = 0
        
        while i < len(words):
            word = words[i]
            
            # Verificar se √© palavra capitalizada
            if re.match(r'^[A-Z][a-z√†-√∫]+$', word):
                # Tentar formar entidade multi-token (m√°ximo 3 palavras)
                entity_parts = [word]
                j = i + 1
                
                # Buscar palavras consecutivas capitalizadas (m√°ximo 2 adicionais)
                while j < len(words) and len(entity_parts) < 3:
                    next_word = words[j]
                    if re.match(r'^[A-Z][a-z√†-√∫]+$', next_word):
                        entity_parts.append(next_word)
                        j += 1
                    else:
                        break
                
                # Se temos pelo menos 2 palavras, formar entidade
                if len(entity_parts) >= 2:
                    proper_nouns.append(' '.join(entity_parts))
                    i = j  # Pular as palavras j√° processadas
                else:
                    # Palavra √∫nica capitalizada
                    if len(word) > 2:
                        proper_nouns.append(word)
                    i += 1
            else:
                i += 1
        
        entities.extend(proper_nouns)
        
        # 4. Fallback simples: deixar LLM extrair entidades relevantes
        if not entities:
            # LLM-first: apenas stopwords b√°sicas, deixar LLM decidir relev√¢ncia
            basic_stopwords = {"para", "com", "sobre", "em", "de", "da", "do", "que", "os", "as", "the", "and", "or"}
            entities = [
                word for word in query.split()
                if len(word) > 3 and word.lower() not in basic_stopwords
            ][:5]
        
        # Dedupe preservando ordem
        seen = set()
        unique_entities = []
        for e in entities:
            if e not in seen:
                seen.add(e)
                unique_entities.append(e)
        
        return unique_entities

    def prepare_planner_context(
        self,
        phase_context: Dict,
        judge_result: Optional[Dict] = None,
        loop_number: int = 0,
    ) -> Dict:
        """
        Prepara contexto para o Planner baseado no estado da fase.

        Modos:
        1. Itera√ß√£o inicial (loop=0): Usa phase_objective completo
        2. Refinamento (refine): Foca em lacuna espec√≠fica
        3. Nova fase (new_phase): N√£o aplic√°vel (nova fase tem contexto limpo)
        """
        # Modo 1: Itera√ß√£o inicial - usar contexto original completo
        if loop_number == 0 or judge_result is None:
            return {
                "phase_objective": phase_context.get("objective", ""),
                "pipe_must_terms": phase_context.get("must_terms", []),
                "pipe_avoid_terms": phase_context.get("avoid_terms", []),
                "pipe_time_hint": phase_context.get("time_hint", {}),
                "pipe_lang_bias": phase_context.get("lang_bias", ["pt-BR", "en"]),
                "pipe_geo_bias": phase_context.get("geo_bias", ["BR", "global"]),
                "pipe_source_bias": phase_context.get(
                    "source_bias", ["oficial", "primaria", "secundaria"]
                ),
                "is_refinement": False,
            }

        # Modo 2: Refinamento - foco em lacuna espec√≠fica
        verdict = judge_result.get("verdict", "")

        if verdict == "refine":
            refine_dict = judge_result.get("refine", {})
            
            # Extract seed_core from Judge (priority)
            seed_core = refine_dict.get("seed_core", "").strip()
            seed_core_source = "judge_llm"
            
            # Fallback if Judge didn't provide valid seed_core
            if not seed_core or len(seed_core) < 12:
                logger.warning("[ORCH] Judge didn't provide valid seed_core, generating fallback")
                seed_core = self._generate_seed_core_fallback(refine_dict, phase_context)
                seed_core_source = "orchestrator_fallback"
            
            # Extract next_query for focus_entities extraction
            next_query = refine_dict.get("next_query", "")
            if not next_query:
                # Fallback: usar objective original
                return self.prepare_planner_context(phase_context, None, 0)

            # Extrair entidades relevantes da next_query
            original_entities = (
                self.contract.get("entities", {}).get("canonical", [])
                if self.contract
                else []
            )
            focus_entities = self._extract_focus_entities(next_query, original_entities)

            # Se n√£o encontrou entidades na query, usar termos da pr√≥pria query como must_terms
            if not focus_entities:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[FOCUS] ‚ö†Ô∏è Nenhuma entidade encontrada na query, ativando fallback"
                    )

                # Extrair entidades multi-token usando regex melhorado
                focus_entities = self._extract_entities_from_query(next_query)

                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[FOCUS] Palavras-chave extra√≠das (fallback): {focus_entities}"
                    )

            return {
                "phase_objective": refine_dict.get("focused_objective", ""),  # From Judge
                "seed_core": seed_core,  # From Judge or fallback
                "seed_core_source": seed_core_source,
                "pipe_must_terms": focus_entities,
                "pipe_avoid_terms": phase_context.get("avoid_terms", []),
                "pipe_time_hint": phase_context.get("time_hint", {}),
                "pipe_lang_bias": phase_context.get("lang_bias", ["pt-BR", "en"]),
                "pipe_geo_bias": phase_context.get("geo_bias", ["BR", "global"]),
                "pipe_source_bias": phase_context.get(
                    "source_bias", ["oficial", "primaria", "secundaria"]
                ),
                "is_refinement": True,
                "refinement_focus": next_query,
                "refinement_reason": judge_result.get("reasoning", ""),
            }

        # Fallback: usar contexto original
        return self.prepare_planner_context(phase_context, None, 0)

    def _generate_seed_core_fallback(self, refine_dict: Dict, phase_context: Dict) -> str:
        """Fallback for generating seed_core when Judge doesn't provide it (edge case)"""
        next_query = refine_dict.get("next_query", "")
        objective = phase_context.get("objetivo", "")[:80]
        entities = self.contract.get("entities", {}).get("canonical", [])[:2] if self.contract else []
        
        # Build basic seed_core
        entity_names = " ".join(entities) if entities else ""
        seed_core = f"{entity_names} {next_query} {objective}".strip()[:200]
        
        return seed_core

    async def run_iteration(
        self, query_text: str, phase_context: Dict = None
    ) -> Dict[str, Any]:
        """Executa itera√ß√£o: Discovery ‚Üí Cache Check ‚Üí Scrape ‚Üí Reduce ‚Üí Accumulate ‚Üí Analyze

        Args:
            query_text: Query para descoberta
            phase_context: Contexto da fase (objetivo, must_terms, etc)
                          NOTA: Em refinamentos, phase_context j√° vem focado (ajustado pelo caller)
        """
        # ===== TELEMETRY SETUP =====
        correlation_id = str(uuid.uuid4())[:8]
        self._current_query = query_text  # Store for telemetry
        
        # ===== ORCHESTRATION HIGH-LEVEL =====
        discovered_urls = await self._run_discovery(query_text, phase_context, correlation_id)
        
        # ===== CACHE CALCULATION (BEFORE SCRAPING) =====
        # Calculate new_urls and cached_urls BEFORE scraping to get accurate telemetry
        cached_urls = list(set(discovered_urls) & set(self.scraped_cache.keys()))
        new_urls = [url for url in discovered_urls if url not in self.scraped_cache]
        
        scraped_content = await self._run_scraping(discovered_urls, correlation_id)
        reduced_context = await self._run_context_reduction(scraped_content, correlation_id)
        analysis = await self._run_analysis(reduced_context, phase_context, correlation_id)
        
        # ===== METRICS & JUDGEMENT =====
        evidence_metrics = self._calculate_evidence_metrics_new(
            analysis.get("facts", []), discovered_urls
        )
        
        # Novelty metrics
        new_facts_ratio, new_domains_ratio = self._calculate_novelty_metrics(analysis)
        
        # Judge decision
        judge_loops = [
            {
                "new_facts_ratio": new_facts_ratio, 
                "new_domains_ratio": new_domains_ratio,
                "unique_domains": evidence_metrics.get("unique_domains", 0),  # P0: Incluir unique_domains
                "evidence_metrics": evidence_metrics,  # P0: Incluir evidence_metrics completo
                "n_facts": len(analysis.get("facts", []))  # P0: Incluir contagem de fatos
            }
        ]
        # Extract previous queries from telemetry
        previous_queries = []
        if judge_loops:
            for loop in judge_loops[-3:]:  # Last 3 loops only
                if "query" in loop:
                    previous_queries.append(loop["query"])

        judgement = await self.judge.run(
            user_prompt=query_text,
            analysis=analysis,
            phase_context=phase_context,
            telemetry_loops=judge_loops,
            intent_profile=getattr(self, "intent_profile", "company_profile"),
            full_contract=self.contract,
            refine_queries=analysis.get("refine_queries", [])[:3],
            phase_candidates=analysis.get("phase_candidates", [])[:2],
            previous_queries=previous_queries,  # ‚Üê NEW
            failed_queries=analysis.get("failed_queries", []),  # ‚Üê WIN #3: Failed queries context
        )

        # Validate for semantic overlap if REFINE verdict
        if judgement.get("verdict") == "REFINE":
            next_query = judgement.get("next_query", "")
            
            # Check semantic overlap with recent queries
            if previous_queries and next_query:
                def semantic_overlap(q1: str, q2: str) -> float:
                    """Calculate token overlap ratio between two queries"""
                    tokens1 = set(q1.lower().split())
                    tokens2 = set(q2.lower().split())
                    if not tokens1 or not tokens2:
                        return 0.0
                    return len(tokens1 & tokens2) / len(tokens1 | tokens2)
                
                # Check against last 2 queries
                max_overlap = 0.0
                for prev_q in previous_queries[-2:]:
                    overlap = semantic_overlap(next_query, prev_q)
                    max_overlap = max(max_overlap, overlap)
                
                # If > 70% overlap, force angle change
                if max_overlap > 0.70:
                    logger.warning(
                        f"[JUDGE] ‚ö†Ô∏è Query redundante detectada: {max_overlap:.0%} overlap "
                        f"entre '{next_query}' e queries anteriores"
                    )
                    
                    # Override verdict to NEW_PHASE or inject warning
                    if len(previous_queries) >= 2:
                        # After 2+ redundant attempts, force NEW_PHASE
                        logger.warning(
                            f"[JUDGE] For√ßando NEW_PHASE ap√≥s {len(previous_queries)} queries redundantes"
                        )
                        judgement["verdict"] = "NEW_PHASE"
                        judgement["new_phase_reason"] = (
                            f"Queries redundantes (>70% overlap): mudan√ßa de √¢ngulo necess√°ria. "
                            f"Queries anteriores falharam em gerar URLs novas com varia√ß√µes superficiais."
                        )
                    else:
                        # First redundant attempt: warn but allow
                        logger.warning(
                            f"[JUDGE] Permitindo query com overlap alto pela primeira vez. "
                            f"Pr√≥xima redund√¢ncia for√ßar√° NEW_PHASE."
                        )
        
        # Coverage metrics
        sa = analysis.get("self_assessment", {})
        coverage_score = sa.get("coverage_score", 0)
        entities_covered = self._calculate_entities_covered(analysis)
        
        return {
            "query": query_text,
            "discovered_urls": discovered_urls,
            "new_urls": new_urls,  # Use pre-calculated values
            "cached_urls": cached_urls,  # Use pre-calculated values
            "filtered_content": reduced_context,
            "accumulated_context_size": len(self.filtered_accumulator),
            "accumulated_context": self.filtered_accumulator,
            "analysis": analysis,
            "judgement": judgement,
            "evidence_metrics": evidence_metrics,
            "new_facts_ratio": new_facts_ratio,
            "new_domains_ratio": new_domains_ratio,
            "coverage_score": coverage_score,
            "entities_covered": entities_covered,
            "n_facts": len(analysis.get("facts", [])),
            "unique_domains": evidence_metrics.get("unique_domains", 0),
            "seed_core_source": getattr(self, "_current_seed_core_source", "fallback"),
            "analyst_proposals": {
                "refine_queries_count": len(analysis.get("refine_queries", [])),
                "phase_candidates_count": len(analysis.get("phase_candidates", [])),
            },
        }

    # ===== HELPER METHODS FOR run_iteration =====
    
    def _calculate_weighted_fact_delta(self, analysis: dict) -> float:
        """
        Calculate weighted fact delta based on confidence scores.
        
        WIN #2: Instead of simple count, weight facts by confidence:
        - alta confian√ßa = 1.0
        - m√©dia confian√ßa = 0.7  
        - baixa confian√ßa = 0.4
        
        Args:
            analysis: Analysis dict containing facts list
            
        Returns:
            Weighted delta (float) - sum of confidence scores for new facts
        """
        facts = analysis.get("facts", [])
        if not facts:
            return 0.0
            
        # Map confidence levels to weights
        confidence_weights = {
            "alta": 1.0,
            "m√©dia": 0.7,
            "baixa": 0.4
        }
        
        # Calculate weighted sum
        weighted_sum = 0.0
        for fact in facts:
            confidence = fact.get("confian√ßa", "m√©dia")  # Default to m√©dia
            weight = confidence_weights.get(confidence, 0.7)  # Default weight
            weighted_sum += weight
            
        return weighted_sum
    
    def _calculate_multi_dimensional_similarity(
        self, new_obj: str, new_seed: str, new_type: str, existing_phases: list
    ) -> tuple[float, int]:
        """
        Calculate multi-dimensional similarity for duplicate detection.
        
        CORE FIX: Compare 3 dimensions with weights:
        - 0.5 * objective similarity (TF-IDF cosine similarity)
        - 0.3 * seed_query similarity (Jaccard similarity)
        - 0.2 * phase_type overlap (exact match)
        
        Args:
            new_obj: New phase objective
            new_seed: New phase seed query
            new_type: New phase type
            existing_phases: List of existing phases
            
        Returns:
            Tuple of (max_weighted_score, index_of_most_similar_phase)
        """
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity
        
        max_weighted_score = 0.0
        max_sim_idx = 0
        
        if not existing_phases:
            return max_weighted_score, max_sim_idx
            
        # Extract existing objectives
        existing_objs = [
            p.get("objetivo") or p.get("objective", "")
            for p in existing_phases
        ]
        existing_seeds = [
            p.get("seed_query", "") for p in existing_phases
        ]
        existing_types = [
            p.get("phase_type", "") for p in existing_phases
        ]
        
        # 1. Objective similarity (TF-IDF cosine similarity)
        objective_sim = 0.0
        if new_obj and existing_objs and any(existing_objs):
            all_objs = [new_obj] + existing_objs
            vectorizer = TfidfVectorizer()
            vectors = vectorizer.fit_transform(all_objs)
            similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()
            objective_sim = similarities.max() if len(similarities) > 0 else 0.0
        
        # 2. Seed query similarity (Jaccard similarity)
        seed_sim = 0.0
        if new_seed and existing_seeds and any(existing_seeds):
            new_tokens = set(new_seed.lower().split())
            max_jaccard = 0.0
            for existing_seed in existing_seeds:
                if existing_seed:
                    existing_tokens = set(existing_seed.lower().split())
                    intersection = len(new_tokens & existing_tokens)
                    union = len(new_tokens | existing_tokens)
                    jaccard = intersection / union if union > 0 else 0.0
                    max_jaccard = max(max_jaccard, jaccard)
            seed_sim = max_jaccard
        
        # 3. Phase type overlap (exact match)
        type_overlap = 0.0
        if new_type and existing_types:
            type_overlap = 1.0 if new_type in existing_types else 0.0
        
        # Calculate weighted score
        weighted_score = (
            0.5 * objective_sim +
            0.3 * seed_sim +
            0.2 * type_overlap
        )
        
        # Find the most similar phase by iterating and tracking max
        if existing_phases:
            for idx, phase in enumerate(existing_phases):
                phase_obj = phase.get('objetivo') or phase.get('objective', '')
                phase_seed = phase.get('seed_query', '')
                phase_type = phase.get('phase_type', '')
                
                p_obj_sim = 0.0
                if new_obj and phase_obj:
                    try:
                        all_o = [new_obj, phase_obj]
                        vect = TfidfVectorizer()
                        vecs = vect.fit_transform(all_o)
                        sims = cosine_similarity(vecs[0:1], vecs[1:]).flatten()
                        p_obj_sim = sims[0] if len(sims) > 0 else 0.0
                    except: pass
                
                p_seed_sim = 0.0
                if new_seed and phase_seed:
                    nt = set(new_seed.lower().split())
                    pt = set(phase_seed.lower().split())
                    p_seed_sim = len(nt & pt) / len(nt | pt) if len(nt | pt) > 0 else 0.0
                
                p_type_over = 1.0 if new_type == phase_type and new_type else 0.0
                phase_score = 0.5 * p_obj_sim + 0.3 * p_seed_sim + 0.2 * p_type_over
                
                if phase_score > max_weighted_score:
                    max_weighted_score = phase_score
                    max_sim_idx = idx
            
        return max_weighted_score, max_sim_idx
    
    async def _run_discovery(self, query_text: str, phase_context: Dict = None, correlation_id: str = None) -> List[str]:
        """Discovery logic (~80 linhas)
        
        Extrai de run_iteration:
        - Prepara√ß√£o de discovery_params
        - Chamada ao discovery_tool
        - Parse de discovery_result
        """
        # ===== TELEMETRY =====
        tel = StepTelemetry(
            step="discovery",
            correlation_id=correlation_id or "unknown",
            start_ms=time.time() * 1000,
            inputs_brief=f"query={query_text[:50]}...",
            counters={"urls": 0},
        )
        # CAMADA 1: Enriquecer seed com entidades priorit√°rias
        enriched_query = query_text
        
        if phase_context and self.contract:
            must_terms = phase_context.get("must_terms", [])
            entities = self.contract.get("entities", {})
            canonical = entities.get("canonical", [])
            
            query_lower = query_text.lower()
            
            # Identificar entidades ausentes na seed
            missing_entities = []
            for entity in canonical:
                entity_words = entity.split()
                if not any(
                    word.lower() in query_lower
                    for word in entity_words
                    if len(word) > 2
                ):
                    missing_entities.append(entity.split()[0])
            
            # Adicionar entidades se cabem
            if missing_entities:
                current_words = len(query_text.split())
                can_add = max(0, min(len(missing_entities), 12 - current_words))
                entities_to_add = missing_entities[:can_add]
                
                if entities_to_add:
                    enriched_query = f"{' '.join(entities_to_add)} {query_text}".strip()
                    
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(f"[ORCH][ENRICHMENT] Seed original: '{query_text}'")
                        print(f"[ORCH][ENRICHMENT] Seed enriquecida: '{enriched_query}'")
                        print(f"[ORCH][ENRICHMENT] Entidades adicionadas: {entities_to_add}")
        
        # üîß FIX: Add debug logging for query without prioritized entities
        if must_terms and getattr(self.valves, "DEBUG_LOGGING", False):
            query_has_entities = any(term.lower() in query_text.lower() for term in must_terms[:3])
            if not query_has_entities:
                print(f"[DISCOVERY] ‚ö†Ô∏è Query sem entidades priorit√°rias. Must_terms: {must_terms[:3]}")
                print(f"[DISCOVERY] Query original: '{query_text}'")
        
        # PRIORITY: seed_core from Judge/Planner (rich) > enriched_query (short)
        query_for_discovery = enriched_query
        seed_core_source = "enriched_query_fallback"

        if phase_context:
            seed_core = phase_context.get("seed_core", "").strip()
            seed_core_source = phase_context.get("seed_core_source", "unknown")

            if seed_core and len(seed_core) >= 12:
                query_for_discovery = seed_core
                logger.info(f"[ORCH] Using seed_core from {seed_core_source}: '{seed_core[:80]}...'")
            else:
                logger.warning(f"[ORCH] seed_core absent or invalid (len={len(seed_core) if seed_core else 0}), using enriched_query")
        else:
            # Fallback determin√≠stico
            logger.warning("[ORCH] seed_core ausente, gerando fallback determin√≠stico")
            try:
                entities = (self.contract or {}).get("entities", {})
                canon = [str(x) for x in entities.get("canonical", [])]
                alias = [str(x) for x in entities.get("aliases", [])]
                all_names = [n for n in (canon + alias) if n][:2]
                
                objective = phase_context.get("objetivo") or phase_context.get("objective", "")
                objective_words = objective.split()[:10] if objective else []
                
                geo_bias = phase_context.get("geo_bias", ["BR"])
                # N√ÉO adicionar geo diretamente ao query (vai para geo_bias depois)
                geo_hint = ""  # Removido - geo vai apenas para discovery_params["geo_bias"]
                
                entity_part = " ".join(all_names) if all_names else ""
                objective_part = " ".join(objective_words)
                query_for_discovery = f"{entity_part} {objective_part}".strip()
                # geo_hint removido - contexto geogr√°fico vai via discovery_params["geo_bias"]
                
                if len(query_for_discovery) > 200:
                    query_for_discovery = query_for_discovery[:197] + "..."
                
                seed_core_source = "orchestrator_fallback"
                
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[ORCH] Fallback determin√≠stico: '{query_for_discovery[:80]}...'")
                    
            except Exception as e:
                logger.error(f"[ORCH] Falha no fallback determin√≠stico: {e}")
        
        # Store for telemetry
        self._current_seed_core_source = seed_core_source
        
        # Preparar discovery_params
        discovery_params = {"query": query_for_discovery}
        
        # Adicionar rails do Planner
        if phase_context:
            if phase_context.get("must_terms"):
                discovery_params["must_terms"] = phase_context["must_terms"]
            if phase_context.get("avoid_terms"):
                discovery_params["avoid_terms"] = phase_context["avoid_terms"]
            if phase_context.get("time_hint"):
                discovery_params["time_hint"] = phase_context["time_hint"]
            if phase_context.get("lang_bias"):
                discovery_params["lang_bias"] = phase_context["lang_bias"]
            if phase_context.get("geo_bias"):
                discovery_params["geo_bias"] = phase_context["geo_bias"]
            if phase_context.get("seed_family_hint"):
                discovery_params["seed_family_hint"] = phase_context["seed_family_hint"]
            if phase_context.get("suggested_domains"):
                discovery_params["suggested_domains"] = phase_context["suggested_domains"]
            if phase_context.get("suggested_filetypes"):
                discovery_params["suggested_filetypes"] = phase_context["suggested_filetypes"]
            
            # Propagar phase_objective
            objective = phase_context.get("objetivo") or phase_context.get("objective", "")
            if objective:
                discovery_params["phase_objective"] = objective
                objective_sentences = objective.split(".")[:2]
                discovery_params["phase_objective_short"] = ". ".join(
                    s.strip() for s in objective_sentences if s.strip()
                )
            
            # Empurrar APENAS entidades relevantes (n√£o geo) para must_terms
            try:
                def _is_geographic_term(term: str) -> bool:
                    """Detecta se um termo √© geogr√°fico baseado em caracter√≠sticas estruturais"""
                    term_lower = term.strip().lower()
                    
                    # Termos muito curtos (< 3 chars) s√£o provavelmente c√≥digos geogr√°ficos
                    if len(term_lower) < 3:
                        return True
                    
                    # Pa√≠ses conhecidos (lista m√≠nima, apenas os mais comuns)
                    countries = {"brasil", "brazil", "portugal", "argentina", "chile", "colombia", "mexico"}
                    if term_lower in countries:
                        return True
                    
                    # C√≥digos de pa√≠s (2-3 letras, mai√∫sculas ou min√∫sculas)
                    if len(term_lower) <= 3 and term_lower.isalpha():
                        # C√≥digos comuns de pa√≠s/regi√£o
                        geo_codes = {"br", "pt", "ar", "cl", "co", "mx", "us", "uk", "fr", "de", "es", "it"}
                        if term_lower in geo_codes:
                            return True
                    
                    # Termos geogr√°ficos gen√©ricos (sem contexto setorial)
                    geo_generics = {
                        "global", "mundial", "nacional", "internacional", 
                        "latam", "latinamerica", "america", "europa"
                    }
                    if term_lower in geo_generics:
                        return True
                    
                    # N√ÉO filtrar se cont√©m contexto setorial/empresarial
                    business_indicators = [
                        "executive", "search", "consultoria", "partners", 
                        "associados", "group", "corporation", "ltda", "sa"
                    ]
                    if any(indicator in term_lower for indicator in business_indicators):
                        return False  # Manter - tem contexto empresarial
                    
                    return False
                
                entities = (self.contract or {}).get("entities", {})
                canon = [str(x) for x in entities.get("canonical", [])]
                alias = [str(x) for x in entities.get("aliases", [])]
                all_names = [n for n in (canon + alias) if n]
                
                # Filtrar usando detec√ß√£o estrutural (n√£o blacklist hardcoded)
                filtered_names = [
                    n for n in all_names 
                    if n.strip() and not _is_geographic_term(n)
                ]
                
                if filtered_names:
                    merged = list(dict.fromkeys(
                        (discovery_params.get("must_terms") or []) + filtered_names
                    ))
                    discovery_params["must_terms"] = merged
                    
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        filtered_out = set(all_names) - set(filtered_names)
                        if filtered_out:
                            logger.info(f"[ORCH] Filtered geo terms from must_terms: {filtered_out}")
                        logger.info(f"[ORCH] Final must_terms: {merged}")
                    
                    logger.info(f"[ORCH] Enriched must_terms with entities: {len(merged)} total terms, {len(filtered_names)} entities (filtered {len(all_names) - len(filtered_names)} geo terms)")
                
                # Garantir geo separado em geo_bias (n√£o em must_terms)
                if any(n.lower() in GEO_BLACKLIST for n in all_names):
                    # Adicionar geo_bias se ainda n√£o existe
                    if "geo_bias" not in discovery_params or not discovery_params["geo_bias"]:
                        discovery_params["geo_bias"] = ["BR", "global"]
                        
            except Exception as e:
                logger.error(f"[ORCH] Error filtering must_terms: {e}")
        
        # Perfil do Planner ‚Üí Discovery.profile
        try:
            profile_map = {
                "company_profile": "general",
                "regulation_review": "regulatory",
                "technical_spec": "technical",
                "literature_review": "academic",
                "history_review": "history",
            }
            eff_profile = profile_map.get(
                getattr(self, "intent_profile", "company_profile"), "general"
            )
            discovery_params["profile"] = eff_profile
        except Exception:
            discovery_params["profile"] = "general"
        
        # Dom√≠nios oficiais agregados
        try:
            all_official = []
            for arr in self.valves.OFFICIAL_DOMAINS.values():
                all_official.extend(arr)
            discovery_params["official_domains"] = list(sorted(set(all_official)))
        except Exception:
            pass
        
        # Chamar discovery tool
        try:
            discovery_result = await (
                self.discovery_tool(**discovery_params)
                if asyncio.iscoroutinefunction(self.discovery_tool)
                else asyncio.to_thread(self.discovery_tool, **discovery_params)
            )
        except Exception as e:
            logger.error(f"[DISCOVERY] Tool call failed: {e}")
            discovery_result = {"urls": []}
        
        # Parse discovery result
        if isinstance(discovery_result, str):
            try:
                discovery_result = json.loads(discovery_result)
            except json.JSONDecodeError as e:
                logger.error(f"[DISCOVERY] Failed to parse JSON: {e}")
                return []
        
        try:
            discovered_urls = self._parse_discovery_result(discovery_result)
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Discovery] {len(discovered_urls)} URLs priorizadas")
        except Exception as e:
            logger.error(f"[DISCOVERY] Parse error: {e}")
            discovered_urls = []
        
        # ===== TELEMETRY FINAL =====
        tel.end_ms = time.time() * 1000
        tel.counters["urls"] = len(discovered_urls)
        tel.outputs_brief = f"urls={len(discovered_urls)}"
        logger.info(f"[{tel.step.upper()}] {json.dumps(tel.to_dict())}")
        
        return discovered_urls
    
    async def _run_scraping(self, discovered_urls: List[str], correlation_id: str = None) -> str:
        """Scraping + cache check (~60 linhas)
        
        Extrai de run_iteration:
        - Cache check
        - Chamada ao scraper_tool
        - Atualiza√ß√£o de scraped_cache
        """
        # ===== TELEMETRY =====
        tel = StepTelemetry(
            step="scraper",
            correlation_id=correlation_id or "unknown",
            start_ms=time.time() * 1000,
            inputs_brief=f"urls={len(discovered_urls)}",
            counters={"new_urls": 0, "cached_urls": 0, "chars": 0},
        )
        cached_urls = set(discovered_urls) & set(self.scraped_cache.keys())
        new_urls = [url for url in discovered_urls if url not in self.scraped_cache]
        
        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[Cache] {len(cached_urls)} URLs j√° scraped, {len(new_urls)} novas")
        
        raw_content = ""
        if new_urls:
            scraper_result = await (
                self.scraper_tool(**{"urls": new_urls})
                if asyncio.iscoroutinefunction(self.scraper_tool)
                else asyncio.to_thread(self.scraper_tool, **{"urls": new_urls})
            )
            
            if isinstance(scraper_result, str):
                scraper_result = json.loads(scraper_result)
            
            # Parsear scraped_content
            scraped_content = self._extract_scraped_content(scraper_result)
            for item in scraped_content:
                if isinstance(item, dict):
                    url = item.get("url")
                    content = item.get("content") or item.get("text") or ""
                    if url and content:
                        self.scraped_cache[url] = content
                        raw_content += f"\nURL: {url}\n{content}\n---\n"
            
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Scraper] {len(new_urls)} URLs scraped, {len(raw_content)} chars")
        else:
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Scraper] Nenhuma URL nova para scrape")
        
        # ===== TELEMETRY FINAL =====
        tel.end_ms = time.time() * 1000
        tel.counters["new_urls"] = len(new_urls)
        tel.counters["cached_urls"] = len(cached_urls)
        tel.counters["chars"] = len(raw_content)
        tel.outputs_brief = f"content={len(raw_content)} chars"
        logger.info(f"[{tel.step.upper()}] {json.dumps(tel.to_dict())}")
        
        return raw_content
    
    async def _run_context_reduction(self, raw_content: str, correlation_id: str = None) -> str:
        """Context Reducer call (~40 linhas)"""
        if not raw_content or not self.valves.ENABLE_CONTEXT_REDUCER or not self.context_reducer_tool:
            return raw_content
        
        # ===== TELEMETRY =====
        tel = StepTelemetry(
            step="context_reducer",
            correlation_id=correlation_id or "unknown",
            start_ms=time.time() * 1000,
            inputs_brief=f"content={len(raw_content)} chars",
            counters={"input_chars": len(raw_content), "output_chars": 0},
        )
        
        try:
            context_params = {
                "corpo": {"ultrasearcher_result": {"scraped_content": raw_content}},
                "mode": "coarse",
                "queries": self.all_phase_queries,
                "tipo": "fase",
            }
            
            if self.job_id:
                context_params["job_id"] = self.job_id
            
            context_result = await (
                self.context_reducer_tool(**context_params)
                if asyncio.iscoroutinefunction(self.context_reducer_tool)
                else asyncio.to_thread(self.context_reducer_tool, **context_params)
            )
            
            if isinstance(context_result, str):
                context_result = json.loads(context_result)
            
            filtered_content = context_result.get("final_markdown", raw_content)
            reduction = (
                (1 - len(filtered_content) / len(raw_content)) * 100
                if len(raw_content) > 0
                else 0
            )
            
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Context Reducer] coarse: {len(raw_content)} ‚Üí {len(filtered_content)} chars (-{reduction:.1f}%)")
            
            # ===== TELEMETRY FINAL =====
            tel.end_ms = time.time() * 1000
            tel.counters["output_chars"] = len(filtered_content)
            tel.outputs_brief = f"reduced={len(filtered_content)} chars (-{reduction:.1f}%)"
            logger.info(f"[{tel.step.upper()}] {json.dumps(tel.to_dict())}")
            
            return filtered_content
            
        except (KeyError, ValueError, TypeError) as e:
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Context Reducer] Parse error: {e}, usando raw")
            return raw_content
        except Exception as e:
            logger.error(f"Context reducer failed unexpectedly: {e}")
            raise ToolExecutionError(f"Context reducer execution failed: {e}") from e
    
    async def _run_analysis(self, filtered_content: str, phase_context: Dict, correlation_id: str = None) -> Dict:
        """Analyst LLM call (~50 linhas)"""
        # ===== TELEMETRY =====
        tel = StepTelemetry(
            step="analyst",
            correlation_id=correlation_id or "unknown",
            start_ms=time.time() * 1000,
            inputs_brief=f"context={len(self.filtered_accumulator)} chars",
            counters={"facts": 0, "lacunas": 0},
        )
        if filtered_content:
            self.filtered_accumulator += f"\n\n{filtered_content}"
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Accumulator] Total acumulado: {len(self.filtered_accumulator)} chars")
        
        # Deduplica√ß√£o opcional para Analyst
        analyst_context = self.filtered_accumulator
        
        if self.valves.ENABLE_ANALYST_DEDUPLICATION and self.filtered_accumulator:
            # Divis√£o mais agressiva para garantir ativa√ß√£o da deduplica√ß√£o
            paragraphs = [
                p.strip() for p in self.filtered_accumulator.split("\n\n") if p.strip()
            ]
            
            # Se ainda n√£o tem par√°grafos suficientes, dividir por senten√ßas
            if len(paragraphs) < self.valves.MAX_ANALYST_PARAGRAPHS:
                # Dividir por senten√ßas (pontos seguidos de espa√ßo)
                sentences = [
                    s.strip() for s in self.filtered_accumulator.replace('\n', ' ').split('. ') if s.strip()
                ]
                # Agrupar senten√ßas em par√°grafos de ~3 senten√ßas
                paragraphs = []
                for i in range(0, len(sentences), 3):
                    paragraph = '. '.join(sentences[i:i+3])
                    if paragraph and not paragraph.endswith('.'):
                        paragraph += '.'
                    paragraphs.append(paragraph)
            
            if len(paragraphs) > self.valves.MAX_ANALYST_PARAGRAPHS:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEDUP ANALYST] ‚úÖ ATIVADO: {len(paragraphs)} par√°grafos > {self.valves.MAX_ANALYST_PARAGRAPHS} ‚Üí deduplicando para Analyst...")
                
                # Calcular preserva√ß√£o de contexto recente
                # üìä PRESERVATION STRATEGY (v4.8.2):
                # - preserve_recent_pct = % of paragraphs preserved from deduplication
                # - reference_first=True ‚Üí dedupe OLD against NEW (NEW is reference)
                # - Goal: Protect current iteration findings from being lost
                # - Default: ANALYST_PRESERVE_RECENT_PCT = 1.0 (100% preservation of new content)
                # - Formula: min(valve_cap, new_count / total_count)
                #   ‚Üí If all content is new (Loop 1): 100% preserved
                #   ‚Üí If 30/250 is new (Loop 3): min(100%, 12%) = 12% preserved (only the 30 new paragraphs)
                # - Trade-off: Higher preservation = more tokens to Analyst, but zero information loss
                if filtered_content:
                    new_paragraphs = [
                        p.strip() for p in filtered_content.split("\n\n") if p.strip()
                    ]
                    new_count = len(new_paragraphs)
                    
                    # Use valve to control preservation (default 1.0 = 100%)
                    # Ensures new content from current iteration is never lost
                    preserve_recent_pct = min(
                        self.valves.ANALYST_PRESERVE_RECENT_PCT,  # Configurable cap (default 1.0)
                        new_count / len(paragraphs)  # Dynamic ratio based on new vs accumulated
                    )
                    
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(f"[DEDUP ANALYST] üîí Preservation: {preserve_recent_pct:.1%} ({new_count} new / {len(paragraphs)} total)")
                else:
                    # No new content - use lower preservation for old accumulated data
                    preserve_recent_pct = 0.2
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(f"[DEDUP ANALYST] ‚ö†Ô∏è No new content - preserving {preserve_recent_pct:.1%} of accumulated")
                
                # Usar estrat√©gia espec√≠fica do Analyst
                algorithm = getattr(self.valves, "ANALYST_DEDUP_ALGORITHM", "semantic")
                model_name = getattr(self.valves, "ANALYST_DEDUP_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
                print(f"[DEDUP ANALYST] üß† Algoritmo: {algorithm.upper()}")
                print(f"[DEDUP ANALYST] üìä Input: {len(paragraphs)} par√°grafos ‚Üí Target: {self.valves.MAX_ANALYST_PARAGRAPHS}")
                
                # Deduplicar com context-aware
                dedupe_result = self.deduplicator.dedupe(
                    chunks=paragraphs,
                    max_chunks=self.valves.MAX_ANALYST_PARAGRAPHS,
                    algorithm=algorithm,
                    threshold=getattr(self.valves, "DEDUP_SIMILARITY_THRESHOLD", 0.85),
                    preserve_order=True,
                    preserve_recent_pct=preserve_recent_pct,
                    shuffle_older=True,
                    reference_first=True,
                    # NOVO: Context-aware parameters
                    must_terms=phase_context.get("must_terms", []),
                    key_questions=phase_context.get("key_questions", []),
                    enable_context_aware=self.valves.ENABLE_CONTEXT_AWARE_DEDUP,
                )
                
                analyst_context = "\n\n".join(dedupe_result["chunks"])
                
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEDUP ANALYST] {dedupe_result['original_count']} ‚Üí {dedupe_result['deduped_count']} par√°grafos ({dedupe_result['reduction_pct']:.1f}% redu√ß√£o)")
                    
                    # Additional telemetry
                    preserved_count = int(len(paragraphs) * preserve_recent_pct)
                    print(f"[DEDUP ANALYST] üìå Recent preservation: {preserved_count} paragraphs ({preserve_recent_pct:.1%}) protected from deduplication")
                    print(f"[DEDUP ANALYST] üéØ Valve setting: ANALYST_PRESERVE_RECENT_PCT = {self.valves.ANALYST_PRESERVE_RECENT_PCT}")
        
        # Chamar Analyst
        analysis = await self.analyst.run(
            query=getattr(self, "_current_query", ""),
            accumulated_context=analyst_context,
            phase_context=phase_context,
        )
        
        # Validar resultado
        if not isinstance(analysis, dict):
            logger.error(f"[CRITICAL] Analyst returned non-dict: {type(analysis)}")
            analysis = {
                "summary": "",
                "facts": [],
                "lacunas": ["Erro: Analyst retornou tipo inv√°lido"],
            }
        
        # Garantir campos m√≠nimos
        if not analysis.get("facts"):
            analysis["facts"] = []
        if not analysis.get("lacunas"):
            analysis["lacunas"] = []
        if not analysis.get("summary"):
            analysis["summary"] = ""
        
        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[DEBUG] [ITERATION] Analyst completed, got {len(analysis.get('summary', ''))} chars summary")
            print(f"[DEBUG] [ITERATION] Analyst facts count: {len(analysis.get('facts', []))}")
            print(f"[DEBUG] [ITERATION] Analyst lacunas count: {len(analysis.get('lacunas', []))}")
        
        # ===== TELEMETRY FINAL =====
        tel.end_ms = time.time() * 1000
        tel.counters["facts"] = len(analysis.get("facts", []))
        tel.counters["lacunas"] = len(analysis.get("lacunas", []))
        tel.outputs_brief = f"facts={len(analysis.get('facts', []))}, lacunas={len(analysis.get('lacunas', []))}"
        logger.info(f"[{tel.step.upper()}] {json.dumps(tel.to_dict())}")
        
        return analysis
    
    def _calculate_novelty_metrics(self, analysis: Dict) -> tuple[float, float]:
        """Calculate novelty metrics for facts and domains"""
        def _norm_text(s: str) -> str:
            return (s or "").strip().lower()
        
        def _hash_text(s: str) -> str:
            return hashlib.sha256(_norm_text(s).encode("utf-8")).hexdigest()
        
        facts_list = analysis.get("facts", []) or []
        current_hashes = set()
        for f in facts_list:
            if isinstance(f, dict):
                current_hashes.add(_hash_text(f.get("texto", "")))
            else:
                current_hashes.add(_hash_text(str(f)))
        
        # Domains from evidences
        current_domains = set()
        for f in facts_list:
            if isinstance(f, dict):
                for ev in f.get("evidencias", []) or []:
                    url = (ev or {}).get("url") or ""
                    try:
                        dom = url.split("/")[2] if "/" in url else ""
                        if dom:
                            current_domains.add(dom)
                    except Exception:
                        pass
        
        new_facts = [h for h in current_hashes if h not in self.used_claim_hashes]
        new_domains = [d for d in current_domains if d not in self.used_domains]
        
        new_facts_ratio = (
            (len(new_facts) / max(len(current_hashes), 1)) if current_hashes else 0.0
        )
        new_domains_ratio = (
            (len(new_domains) / max(len(current_domains), 1))
            if current_domains
            else 0.0
        )
        
        # Update global sets
        self.used_claim_hashes.update(current_hashes)
        self.used_domains.update(current_domains)
        
        return new_facts_ratio, new_domains_ratio
    
    def _calculate_entities_covered(self, analysis: Dict) -> int:
        """Calculate how many entities from contract appear in facts"""
        entities_covered = 0
        if self.contract and self.contract.get("entities"):
            canonical = self.contract["entities"].get("canonical", [])
            aliases = self.contract["entities"].get("aliases", [])
            all_entities = canonical + aliases
            
            # Verificar quantas entidades aparecem nos fatos
            facts_text = " ".join(
                [f.get("texto", "") for f in analysis.get("facts", [])]
            ).lower()
            for entity in all_entities:
                if entity.lower() in facts_text:
                    entities_covered += 1
        
        return entities_covered

        # üìã FASE 2: Aplicar decis√µes do Judge (incremental)
        if self.contract and (refine_queries or phase_candidates):
            verdict = judgement.get("verdict", "done")
            selected_index = judgement.get("selected_index")

            if (
                verdict == "refine"
                and selected_index is not None
                and selected_index < len(refine_queries)
            ):
                # Aplicar refine_query selecionada
                selected_query = refine_queries[selected_index]
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[FASE2] Aplicando refine_query selecionada: {selected_query}"
                    )

            elif (
                verdict == "new_phase"
                and selected_index is not None
                and selected_index < len(phase_candidates)
            ):
                # Aplicar phase_candidate selecionada
                selected_candidate = phase_candidates[selected_index]

                # Verificar se cabe no limite de fases
                max_phases = getattr(self.valves, "MAX_PHASES", 6)
                current_phases = len(self.contract.get("fases", []))

                if current_phases < max_phases:
                    _append_phase(self.contract, selected_candidate)
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[FASE2] Aplicando phase_candidate selecionada: {selected_candidate.get('name', 'N/A')}"
                        )
                else:
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[FASE2] Limite de fases atingido ({current_phases}/{max_phases}), ignorando new_phase"
                        )

    def _empty_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas vazias para casos de erro ou sem dados"""
        return {
            "total_facts": 0,
            "facts_with_evidence": 0,
            "evidence_per_fact": 0.0,
            "unique_domains": 0,
            "facts_with_multiple_sources": 0,
            "evidence_coverage": 0.0,
            "high_confidence_facts": 0,
            "contradictions": 0,
        }

    def _calculate_evidence_metrics_new(self, facts_list, discovered_urls):
        """Calcula m√©tricas de evid√™ncia para auditoria e qualidade (nova estrutura)

        REFACTORED (v4.3.1 - P1C): Usa _extract_quality_metrics() para evitar duplica√ß√£o

        Args:
            facts_list: Lista de fatos extra√≠dos pelo Analyst
            discovered_urls: URLs descobertas pela Discovery

        Returns:
            Dict com m√©tricas de evid√™ncia ou m√©tricas vazias se input inv√°lido
        """
        # Validate inputs with null safety
        if not facts_list or not isinstance(facts_list, list):
            return self._empty_metrics()

        # Usar fun√ß√£o consolidada para extrair m√©tricas base
        metrics = _extract_quality_metrics(facts_list)

        # Retornar formato esperado pela telemetria
        return {
            "total_facts": len(facts_list),
            "facts_with_evidence": metrics["facts_with_evidence"],
            "evidence_per_fact": metrics["total_evidence"] / max(len(facts_list), 1),
            "unique_domains": len(metrics["domains"]),
            "facts_with_multiple_sources": metrics["facts_with_multiple_sources"],
            "evidence_coverage": metrics["facts_with_evidence"]
            / max(len(facts_list), 1),
            "high_confidence_facts": metrics["high_confidence_facts"],
            "contradictions": metrics["contradictions"],
        }

    def _extract_scraped_content(self, scraper_result):
        """Extrai scraped_content com contrato expl√≠cito (P0.1)"""
        if not isinstance(scraper_result, dict):
            raise ValueError(f"Scraper result must be dict, got {type(scraper_result)}")

        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[DEBUG] Scraper result keys: {list(scraper_result.keys())}")

        # Contract A: {"scraped_content": [...]}
        if "scraped_content" in scraper_result:
            content = scraper_result["scraped_content"]
            if isinstance(content, list):
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG] Contract A: Found {len(content)} items in scraped_content"
                    )
                return content
            else:
                raise ValueError(
                    f"Contract A: scraped_content must be list, got {type(content)}"
                )

        # Contract B: {"results": [...]}
        elif "results" in scraper_result:
            results = scraper_result["results"]
            if isinstance(results, list):
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEBUG] Contract B: Found {len(results)} items in results")
                return results
            else:
                raise ValueError(
                    f"Contract B: results must be list, got {type(results)}"
                )

        # Contract C: {"url": "...", "content": "..."} (single URL)
        elif "url" in scraper_result and "content" in scraper_result:
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[DEBUG] Contract C: Found single URL format")
            return [scraper_result]

        # Unknown format
        else:
            available_keys = list(scraper_result.keys())
            raise ValueError(
                f"Unknown scraper result format. Available keys: {available_keys}. Expected: scraped_content, results, or url+content"
            )

    async def finalize_global_context(self, mode: str = "light") -> str:
        """Context Reducer global com TODAS as queries"""
        if not (self.valves.ENABLE_CONTEXT_REDUCER and self.context_reducer_tool):
            raise ValueError("Context Reducer n√£o dispon√≠vel")

        try:
            # Build params and only include job_id when not null (P0.1)
            global_params = {
                "corpo": {"accumulated_content": [self.filtered_accumulator]},
                "mode": mode,
                "queries": self.all_phase_queries,  # ‚Üê CR√çTICO: TODAS as queries
                "tipo": "global",
            }
            if self.job_id:
                global_params["job_id"] = self.job_id

            global_result = await (
                self.context_reducer_tool(**global_params)
                if asyncio.iscoroutinefunction(self.context_reducer_tool)
                else asyncio.to_thread(self.context_reducer_tool, **global_params)
            )

            if isinstance(global_result, str):
                global_result = json.loads(global_result)

            final_markdown = global_result.get("final_markdown", "")

            total = len(self.filtered_accumulator)
            reduction = (1 - len(final_markdown) / total) * 100 if total > 0 else 0
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[Context Reducer] {mode}: {total} ‚Üí {len(final_markdown)} chars (-{reduction:.1f}%)"
                )

            return final_markdown

        except Exception as e:
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(f"[Context Reducer] global falhou: {e}")
            raise

    def _parse_discovery_result(self, discovery_result):
        """Parse discovery result with explicit contract (P0.1)"""
        if not isinstance(discovery_result, dict):
            raise ValueError(
                f"Discovery result must be dict, got {type(discovery_result)}"
            )

        logger.debug("Discovery result keys: %s", list(discovery_result.keys()))

        discovered_urls = []

        # Contract A: {"urls": [...]}
        if "urls" in discovery_result:
            urls = discovery_result.get("urls", [])
            if isinstance(urls, list):
                discovered_urls = urls
                logger.debug(
                    "Contract A: Found %d URLs in discovery_result.urls",
                    len(discovered_urls),
                )
            else:
                raise ValueError(f"Contract A: urls must be list, got {type(urls)}")

        # Contract B: {"candidates": [{"url": ...}]}
        elif "candidates" in discovery_result:
            candidates = discovery_result.get("candidates", [])
            if isinstance(candidates, list):
                for candidate in candidates:
                    if isinstance(candidate, dict) and candidate.get("url"):
                        discovered_urls.append(candidate["url"])
                    elif hasattr(candidate, "url"):  # UrlCandidate object
                        discovered_urls.append(candidate.url)
                    else:
                        logger.warning("Invalid candidate format: %s", type(candidate))
                logger.debug(
                    "Contract B: Found %d URLs in discovery_result.candidates",
                    len(discovered_urls),
                )
            else:
                raise ValueError(
                    f"Contract B: candidates must be list, got {type(candidates)}"
                )

        # Contract C: Legacy format {"discovery_results": {"candidates": [...]}}
        elif "discovery_results" in discovery_result:
            discovery_results = discovery_result.get("discovery_results", {})
            if isinstance(discovery_results, dict):
                candidates = discovery_results.get("candidates", [])
                if isinstance(candidates, list):
                    for candidate in candidates:
                        if isinstance(candidate, dict) and candidate.get("url"):
                            discovered_urls.append(candidate["url"])
                    logger.debug(
                        "Contract C: Found %d URLs in discovery_results.candidates",
                        len(discovered_urls),
                    )
                else:
                    raise ValueError(
                        f"Contract C: candidates must be list, got {type(candidates)}"
                    )
            else:
                raise ValueError(
                    f"Contract C: discovery_results must be dict, got {type(discovery_results)}"
                )

        # Unknown format
        else:
            available_keys = list(discovery_result.keys())
            raise ValueError(
                f"Unknown discovery result format. Available keys: {available_keys}. Expected: urls, candidates, or discovery_results"
            )

        if not discovered_urls:
            logger.warning("Discovery returned 0 URLs - possible empty result")

        return discovered_urls


class Pipe:
    """Context-Aware Research Orchestration Pipeline (v4.5)

    OpenWebUI Manifold Pipe com detec√ß√£o unificada de contexto, s√≠ntese adaptativa,
    error handling robusto, Planner inteligente com valida√ß√£o de key_questions coverage,
    e integra√ß√£o otimizada com discovery tool (dict return + config propagation).

    FLUXO PRINCIPAL:
    1. **Context Detection**: Detecta setor, tipo e perfil da pesquisa (fonte √∫nica)
    2. **Intelligent Planning**: LLM gera plano multi-fase com valida√ß√£o de key_questions coverage
    3. **Orchestration**: Executa fases com Discovery ‚Üí Scrape ‚Üí Reduce ‚Üí Analyze ‚Üí Judge
    4. **Adaptive Synthesis**: Gera relat√≥rio final adaptado ao contexto detectado

    COMPONENTES LLM:
    - **Planner**: Cria contract com fases, rails e entidades (valida√ß√£o rigorosa + key_questions coverage)
    - **Analyst**: Extrai fatos com evid√™ncias do contexto acumulado
    - **Judge**: Decide DONE/REFINE/NEW_PHASE com gates de qualidade program√°ticos
    - **Context Detector**: Classifica setor/tipo e mapeia para perfil apropriado
    - **Synthesizer**: Gera relat√≥rio final com estrutura adaptada ao contexto

    PERFIS E DETEC√á√ÉO:
    - Detec√ß√£o autom√°tica de 10+ setores (tech, sa√∫de, finan√ßas, direito, etc.)
    - Classifica√ß√£o de 6 tipos de pesquisa (acad√™mica, regulat√≥ria, t√©cnica, etc.)
    - Mapeamento inteligente setor ‚Üí perfil de inten√ß√£o
    - Sincroniza√ß√£o autom√°tica entre _detected_context e _intent_profile

    QUALITY RAILS (aplicados em Judge):
    - Evidence coverage: 100% fatos com ‚â•1 evid√™ncia
    - Domain diversity: ‚â•2 dom√≠nios √∫nicos por fase
    - Staleness: valida√ß√£o de recency por perfil
    - Novelty gates: thresholds de novos fatos/dom√≠nios por perfil

    INTELLIGENT PLANNING (v4.3):
    - Key_questions coverage: TODAS as key_questions t√™m fase correspondente
    - Market study architecture: 3y baseline + 1y trends + 90d breaking news
    - Customized seed_queries: Baseadas nos aspectos √∫nicos dos objectives (n√£o templates)
    - MECE phase validation: Sem overlap, sem lacunas cr√≠ticas

    INTEGRA√á√ÉO:
    - Tools: discovery, scraper, context_reducer (resolu√ß√£o determin√≠stica)
    - Valves: Configura√ß√£o completa via UI (LLM, rails, deduplica√ß√£o, etc.)
    - GPT-5/O1 Support: Automatic parameter filtering for new models

    ROTAS E CONSIST√äNCIA:
    **EXECU√á√ÉO MANUAL √öNICA:**

    **FLUXO √öNICO:**
       - Context Detection ‚Üí Planner LLM ‚Üí Contract ‚Üí Orchestrator ‚Üí Synthesis
       - Contract.intent_profile sincronizado com _detected_context
       - Orchestrator.intent_profile = _detected_context['perfil']
       - Orchestrator.contract gerenciado via set_contract()

    **GARANTIAS DE CONSIST√äNCIA:**
    - _detected_context detectado UMA VEZ no in√≠cio (pipe method)
    - _intent_profile sincronizado imediatamente ap√≥s detec√ß√£o
    - Todos os contracts validados contra _detected_context
    - Orchestrator sempre recebe intent_profile do _detected_context
    - Synthesis sempre usa _detected_context (n√£o re-detecta)

    **CHANGELOG v4.0 ‚Üí v4.4:**
    - ‚úÖ v4.4: DEDUPLICATION & CONTEXT DETECTION UPGRADES
      - Deduplication: Unified Deduplicator class with 3 algorithms (MMR, MinHash, TF-IDF)
      - Threshold: 0.9 ‚Üí 0.85 (-75% duplicates), Shingles: n=5 ‚Üí n=3 (+40% detection)
      - Removed dangerous fallback, Analyst preserve_recent: DYNAMIC (100% current iteration)
      - Analyst reference_first: dedupe older AGAINST new data
      - Context Detection: SOURCE OF TRUTH (Planner follows detected profile)
      - Added RH/Headhunting sector with 18 keywords
      - Seed Queries: Mandatory tema central + ALL entity names (1-3 entities)
      - News Default: 1y (not 90d) - 90d only for explicit breaking news
    - ‚úÖ v4.4.1: ANALYST AUTO-ASSESSMENT & CONFIDENCE-BASED EXIT
      - Analyst: self_assessment (coverage_score, gaps_critical, suggest_pivot/refine)
      - Analyst: calibration examples (0.3/0.6/0.9/1.0) to prevent optimism/pessimism
      - Judge: cross-check coverage_score vs objective metrics (facts/lacunas count)
      - Judge: confidence-based exit (DONE if coverage ‚â• 70% even with low novelty)
      - Judge: auto-convert REFINE ‚Üí NEW_PHASE when loops >= MAX_AGENT_LOOPS
      - Judge: 6 explicit NEW_PHASE cases (entities, contradictions, unexpected, temporal, angle, source)
      - Telemetry: enriched with coverage_score, suggest_pivot, failed_query per loop
      - Performance: MinHash 100x faster than MMR
    - ‚úÖ v4.3.1: CODE CLEANUP & CONSOLIDATION (P0 + P1)
      - P0 - Dead code: 115 lines of orphan functions/models removed
      - P1A - JSON parsing: 3 implementations ‚Üí 1 unified (parse_json_resilient)
      - P1B - LLM retry: removed _safe_llm_run wrapper (14 call sites updated)
      - P1C - Quality metrics: 3 functions ‚Üí 1 shared (_extract_quality_metrics)
      - P1D - Synthesis sections: extracted _build_synthesis_sections
      - Total: ~265 lines consolidated, better maintainability
    - ‚úÖ v4.3: PLANNER INTELLIGENCE UPGRADE
      - Mandatory key_questions coverage validation
      - Market study phase architecture (3y + 1y + 90d)
      - Customized seed_query generation
      - Enhanced prompt guidance with MECE examples
    - ‚úÖ v4.2: Corre√ß√£o cr√≠tica Orchestrator._last_contract ‚Üí self.contract
    - ‚úÖ v4.1: GPT-5/O1 compatibility (automatic parameter filtering)
    - ‚úÖ v4.0: Robustness refactor (custom exceptions, constants, helpers)
    - ‚úÖ 4 exce√ß√µes customizadas + error handling espec√≠fico
    - ‚úÖ Classe PipeConstants com 15+ configura√ß√µes centralizadas
    - ‚úÖ 4 m√©todos helper + state validation
    - ‚úÖ Retry com backoff exponencial (LLM calls)
    - ‚úÖ Timeouts din√¢micos e configur√°veis
    - ‚úÖ Suite de testes: 33 tests - 100% passing

    **VERS√ïES ANTERIORES:**
    - v3.2: Context detection unificado + adaptive synthesis
    - v3.0: Multi-phase orchestration baseline
    """

    def _check_diminishing_returns(self, phase_telemetry, evidence_metrics):
        """Verifica diminishing returns program√°tico com telemetria integrada (P0.2)"""
        loops = phase_telemetry.get("loops", [])

        if len(loops) < 2:
            return None  # Precisa de pelo menos 2 loops para comparar

        # Comparar √∫ltimos 2 loops
        loop1 = loops[-2]
        loop2 = loops[-1]

        # Calcular crescimento de dom√≠nios √∫nicos
        domains1 = loop1.get("unique_domains", 0)
        domains2 = loop2.get("unique_domains", 0)
        domains_growth = (domains2 - domains1) / max(domains1, 1) if domains1 > 0 else 0

        # Calcular crescimento de fatos
        facts1 = loop1.get("n_facts", 0)
        facts2 = loop2.get("n_facts", 0)
        facts_growth = (facts2 - facts1) / max(facts1, 1) if facts1 > 0 else 0

        # Calcular crescimento de evid√™ncia
        evidence1 = loop1.get("evidence_coverage", 0)
        evidence2 = loop2.get("evidence_coverage", 0)
        evidence_growth = (
            (evidence2 - evidence1) / max(evidence1, 1) if evidence1 > 0 else 0
        )

        # Calcular crescimento de m√∫ltiplas fontes
        multi1 = loop1.get("facts_with_multiple_sources", 0)
        multi2 = loop2.get("facts_with_multiple_sources", 0)
        multi_growth = (multi2 - multi1) / max(multi1, 1) if multi1 > 0 else 0

        # KPI: <10% crescimento em dom√≠nios E fatos E evid√™ncia
        if domains_growth < 0.1 and facts_growth < 0.1 and evidence_growth < 0.1:
            return {
                "reason": f"Diminishing returns: dom√≠nios {domains_growth*100:.0f}%, fatos {facts_growth*100:.0f}%, evid√™ncia {evidence_growth*100:.0f}% (KPI: ‚â•10%)"
            }

        return None

    # (legacy signature docstring kept for reference; single pipe uses optional args)
    """
    It looks up tools in `__tools__` by names defined in `Valves` and falls back to
    internal default implementations defined above.
    """

    class Valves(BaseModel):
        # UX
        DEBUG_LOGGING: bool = Field(default=False, description="Logs detalhados")
        ENABLE_LINE_BUDGET_GUARD: bool = Field(
            default=False,
            description="Ativar Line-Budget Guard na inicializa√ß√£o (alerta sobre fun√ß√µes muito grandes)",
        )

        # Orquestra√ß√£o
        USE_PLANNER: bool = Field(default=True, description="Usar planner")
        MAX_AGENT_LOOPS: int = Field(
            default=3,
            ge=1,
            le=10,
            description="Max loops/fase (aumentado de 2‚Üí3 para evitar new_phases for√ßadas prematuramente)",
        )
        DEFAULT_PHASE_COUNT: int = Field(
            default=3,
            ge=2,
            le=10,
            description="M√°ximo de fases iniciais (Planner cria AT√â este n√∫mero)",
        )
        MAX_PHASES: int = Field(
            default=6,
            ge=3,
            le=15,
            description="M√°ximo TOTAL de fases (iniciais + criadas pelo Judge)",
        )
        VERBOSE_DEBUG: bool = Field(
            default=False, description="Habilitar logs detalhados de debug"
        )

        # Timeouts (segundos)
        LLM_TIMEOUT_DEFAULT: int = Field(
            default=60,
            ge=30,
            le=300,
            description="Timeout padr√£o para chamadas LLM (Planner, Judge)",
        )
        LLM_TIMEOUT_ANALYST: int = Field(
            default=90,
            ge=30,
            le=300,
            description="Timeout para Analyst (processa mais contexto)",
        )

        # ‚úÖ NOVO: Timeout dedicado para s√≠ntese sem cap
        LLM_TIMEOUT_SYNTHESIS: int = Field(
            default=600,  # ‚¨ÜÔ∏è Aumentado: 300‚Üí600s (10 minutos)
            ge=60,
            le=1800,  # ‚¨ÜÔ∏è M√°ximo: 900‚Üí1800s (30 minutos para casos extremos)
            description="Timeout para S√≠ntese Final (processa muito contexto) - Default 600s (10min), Max 1800s (30min). IMPORTANTE: Se aumentar, garanta que HTTPX_READ_TIMEOUT tamb√©m suba ou ser√° ignorado.",
        )

        # Planner/API behavior
        FORCE_JSON_MODE: bool = Field(
            default=True,
            description="For√ßar response_format=json (quando suportado) para reduzir lat√™ncia e ru√≠do",
        )
        PLANNER_REQUEST_TIMEOUT: int = Field(
            default=180,
            ge=20,
            le=600,
            description="Timeout de leitura HTTP do Planner em segundos (falha r√°pida) ‚Äì default elevado para 180s",
        )
        ENABLE_LLM_RETRY: bool = Field(
            default=True,
            description="Habilitar retry com backoff exponencial para chamadas LLM",
        )
        LLM_MAX_RETRIES: int = Field(
            default=3,
            ge=1,
            le=5,
            description="M√°ximo de tentativas com backoff exponencial",
        )
        HTTPX_READ_TIMEOUT: int = Field(
            default=180,
            ge=60,
            le=600,  # ‚¨ÜÔ∏è Aumentado: 300‚Üí600s
            description="Timeout de leitura HTTP base (httpx client). Para s√≠ntese final, usar LLM_TIMEOUT_SYNTHESIS.",
        )
        LLM_TIMEOUT_PLANNER: int = Field(
            default=180,
            ge=60,
            le=600,
            description="Timeout externo espec√≠fico do Planner (prompts maiores)",
        )

        # Synthesis Control
        ENABLE_DEDUPLICATION: bool = Field(
            default=True, description="Habilitar deduplica√ß√£o na s√≠ntese final"
        )
        PRESERVE_PARAGRAPH_ORDER: bool = Field(
            default=True,
            description="Shuffle para sele√ß√£o justa + reordenar para preservar narrativa (True=recomendado); False=ordenar por tamanho",
        )
        MAX_CONTEXT_CHARS: int = Field(
            default=150000,
            description="M√°ximo de caracteres no contexto para LLM (reduzido para melhor qualidade)",
        )

        # Deduplication Parameters - CALIBRADO PARA QUALIDADE (v4.4)
        MAX_DEDUP_PARAGRAPHS: int = Field(
            default=200,  # ‚¨áÔ∏è Reduzido: 300‚Üí200 par√°grafos (~24k chars, ~6k tokens)
            ge=50,
            le=1000,
            description="M√°ximo de par√°grafos ap√≥s deduplica√ß√£o - Default 200 (~24k chars). ATEN√á√ÉO: >300 pode causar prompt >12k tokens levando a timeout (300s+) ou s√≠ntese gen√©rica!",
        )
        DEDUP_SIMILARITY_THRESHOLD: float = Field(
            default=0.80,  # ‚¨áÔ∏è Reduzido: 0.85‚Üí0.80 (mais agressivo, -20% duplicatas)
            ge=0.0,
            le=1.0,
            description="Threshold de similaridade (0.0-1.0, mais baixo = mais agressivo)",
        )
        DEDUP_RELEVANCE_WEIGHT: float = Field(
            default=0.7,
            ge=0.0,
            le=1.0,
            description="Peso da relev√¢ncia vs diversidade (0.0-1.0, mais alto = mais conservador)",
        )
        DEDUP_ALGORITHM: str = Field(
            default="mmr",
            description="Algoritmo de deduplica√ß√£o: 'mmr' (padr√£o) | 'minhash' (r√°pido) | 'tfidf' (sem√¢ntico) | 'semantic' (Haystack embeddings)",
        )


        CONTEXT_AWARE_PRIORITY_THRESHOLD: float = Field(
            default=0.75,
            ge=0.0,
            le=1.0,
            description="Threshold de prioridade para SEMPRE preservar chunk (0.75 = preserva top 25%)"
        )

        SEMANTIC_MODEL: str = Field(
            default="sentence-transformers/all-MiniLM-L6-v2",
            description="Modelo de embeddings para deduplica√ß√£o sem√¢ntica (lightweight por padr√£o)"
        )

        # Analyst Dedup Strategy
        ANALYST_DEDUP_ALGORITHM: str = Field(
            default="semantic",
            description="Algoritmo para Analyst: 'mmr' | 'minhash' | 'tfidf' | 'semantic'"
        )
        ANALYST_DEDUP_MODEL: str = Field(
            default="sentence-transformers/all-MiniLM-L6-v2",
            description="Modelo embeddings para Analyst (se semantic)"
        )

        # Synthesis Dedup Strategy
        SYNTHESIS_DEDUP_ALGORITHM: str = Field(
            default="mmr",
            description="Algoritmo para Synthesis: 'mmr' | 'minhash' | 'tfidf' | 'semantic'"
        )
        SYNTHESIS_DEDUP_MODEL: str = Field(
            default="sentence-transformers/paraphrase-MiniLM-L3-v2",
            description="Modelo embeddings para Synthesis (se semantic, mais r√°pido)"
        )

        # Context-Aware
        ENABLE_CONTEXT_AWARE_DEDUP: bool = Field(
            default=True,
            description="Ativar dedup context-aware (preserva must_terms/key_questions)"
        )
        CONTEXT_AWARE_PRESERVE_PCT: float = Field(
            default=0.12,  # P0: Reduzido temporariamente para evitar preserva√ß√£o excessiva
            description="% de chunks high-priority a preservar (0.0-1.0)"
        )

        # Deduplication for Analyst (per-iteration)
        ENABLE_ANALYST_DEDUPLICATION: bool = Field(
            default=False,
            description="Dedupe contexto ANTES de enviar ao Analyst (reduz tokens, mant√©m contexto completo para pr√≥ximas itera√ß√µes)",
        )
        MAX_ANALYST_PARAGRAPHS: int = Field(
            default=200,
            ge=50,
            le=500,
            description="M√°ximo de par√°grafos para Analyst (~24k chars, ~6k tokens) - Analyst processa menos que S√≠ntese",
        )
        ANALYST_PRESERVE_RECENT_PCT: float = Field(
            default=1.0,  # 100% by default - preserve ALL new content
            ge=0.0,
            le=1.0,
            description="% of recent content to preserve intact in Analyst deduplication (1.0 = 100% preserved, 0.95 = old behavior, 0.0 = dedupe everything)"
        )

        # Judge Duplicate Detection
        DUPLICATE_DETECTION_THRESHOLD: float = Field(
            default=0.70,
            ge=0.5,
            le=0.9,
            description="Threshold for NEW_PHASE duplicate detection (0.70 = 70% similarity blocks duplicate, lower = more lenient, higher = more strict)"
        )

        # Quality Rails Parameters
        MIN_UNIQUE_DOMAINS: int = Field(
            default=2, description="M√≠nimo de dom√≠nios √∫nicos por fase"
        )
        REQUIRE_OFFICIAL_OR_TWO_INDEPENDENT: bool = Field(
            default=True, description="Exigir fonte oficial ou duas independentes"
        )

        # --- FASE 1: Entity Coverage ---
        MIN_ENTITY_COVERAGE: float = Field(
            default=0.70,
            ge=0.0,
            le=1.0,
            description="Cobertura m√≠nima de entidades nas fases (0.70 = 70% das fases devem conter entidades)",
        )
        MIN_ENTITY_COVERAGE_STRICT: bool = Field(
            default=True,
            description="True = hard-fail se coverage < MIN_ENTITY_COVERAGE | False = warning + Judge decide",
        )

        # --- FASE 1: Seeds ---
        SEED_VALIDATION_STRICT: bool = Field(
            default=False,
            description="False = tenta patch leve em seeds magras; True = s√≥ valida (sem patch)",
        )

        # --- FASE 1: News slot ---
        ENFORCE_NEWS_SLOT: bool = Field(
            default=True,
            description="Manter a pol√≠tica existente de news slot; adicionamos telemetria",
        )

        # --- FASE 1: M√©tricas simples inline ---

        # --- FASE 2: Planner economy controls ---
        PLANNER_ECONOMY_THRESHOLD: float = Field(
            default=0.75,
            ge=0.0,
            le=1.0,
            description="Threshold de uso de budget de fases para warning (0.75 = warn se >75% usado)",
        )

        PLANNER_OVERLAP_THRESHOLD: float = Field(
            default=0.70,
            ge=0.0,
            le=1.0,
            description="Threshold de similaridade entre objectives para detectar overlap (0.70 = 70% similaridade via TF-IDF)",
        )

        # Preferred tools mapping (deterministic resolution)
        PREFERRED_TOOLS: Dict[str, str] = Field(
            default={}, description="Preferred tool names for deterministic resolution"
        )

        # Official domains mapping (P1.1)
        OFFICIAL_DOMAINS: Dict[str, List[str]] = Field(
            default={
                "gov": ["gov.br", "gov.uk", "gov.au", "gov.ca", "europa.eu"],
                "regulatory": [
                    "anpd.gov.br",
                    "cnpj.gov.br",
                    "receita.fazenda.gov.br",
                    "bcb.gov.br",
                ],
                "academic": [
                    "arxiv.org",
                    "scholar.google.com",
                    "doi.org",
                    "ieee.org",
                    "acm.org",
                ],
                "standards": ["iso.org", "ietf.org", "w3.org", "nist.gov"],
                "health": ["who.int", "cdc.gov", "ans.gov.br", "saude.gov.br"],
                "tech": [
                    "github.com",
                    "stackoverflow.com",
                    "developer.mozilla.org",
                    "docs.python.org",
                ],
                "news": [
                    "reuters.com",
                    "bloomberg.com",
                    "valor.globo.com",
                    "folha.uol.com.br",
                ],
            },
            description="Mapa de dom√≠nios oficiais por vertical",
        )

        # LLM Configuration
        OPENAI_BASE_URL: str = Field(
            default="https://api.openai.com/v1", description="API Base"
        )
        OPENAI_API_KEY: str = Field(default="", description="API Key")
        LLM_MODEL: str = Field(
            default="gpt-4o", description="Modelo padr√£o para todos os componentes"
        )
        LLM_TEMPERATURE: float = Field(
            default=0.2, ge=0.0, le=1.0, description="Temperature"
        )
        LLM_MAX_TOKENS: int = Field(
            default=2048,
            ge=100,
            le=4000,
            description="‚ö†Ô∏è DEPRECATED: N√£o usado pelo Pipe (incompat√≠vel GPT-5/O1). Mantido para compatibilidade.",
        )

        # Modelos espec√≠ficos por componente (opcional - deixe vazio para usar LLM_MODEL)
        LLM_MODEL_PLANNER: str = Field(
            default="", description="Modelo para Planner (vazio = usa LLM_MODEL)"
        )
        LLM_MODEL_ANALYST: str = Field(
            default="", description="Modelo para Analyst (vazio = usa LLM_MODEL)"
        )
        LLM_MODEL_JUDGE: str = Field(
            default="", description="Modelo para Judge (vazio = usa LLM_MODEL)"
        )
        LLM_MODEL_SYNTHESIS: str = Field(
            default="",
            description="Modelo para S√≠ntese Final (vazio = usa LLM_MODEL) - Use modelo mais capaz aqui!",
        )

        # Context Reducer
        ENABLE_CONTEXT_REDUCER: bool = Field(
            default=True, description="Habilitar Context Reducer"
        )
        CONTEXT_MODE: str = Field(
            default="light", description="Modo: coarse|light|ultra"
        )

        # ‚úÖ NOVO: Controle de exporta√ß√£o PDF
        AUTO_EXPORT_PDF: bool = Field(
            default=False,
            description="Exportar automaticamente relat√≥rio para PDF ao final da s√≠ntese",
        )

        EXPORT_FULL_CONTEXT: bool = Field(
            default=True,
            description="Se True, exporta contexto bruto completo; se False, apenas relat√≥rio final",
        )

        # Gates por perfil (P1) - EXPANDIDO v4.7: phase_score thresholds + two_flat_loops
        GATES_BY_PROFILE: Dict[str, Dict[str, Any]] = Field(
            default={
                "company_profile": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.60,
                    "two_flat_loops": 2,
                },
                "regulation_review": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.62,
                    "two_flat_loops": 1,
                },
                "technical_spec": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.60,
                    "two_flat_loops": 2,
                },
                "literature_review": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": False,
                    "threshold": 0.58,
                    "two_flat_loops": 2,
                },
                "history_review": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": False,
                    "threshold": 0.58,
                    "two_flat_loops": 2,
                },
                # Phase-type specific gates (usado quando phase_context tem phase_type)
                "news": {
                    "min_new_facts": 0.7,
                    "min_new_domains": 0.5,
                    "staleness_strict": True,
                    "threshold": 0.65,
                    "two_flat_loops": 2,
                },
                "industry": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": False,
                    "threshold": 0.58,
                    "two_flat_loops": 2,
                },
                "profiles": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.60,
                    "two_flat_loops": 2,
                },
                "tech": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": False,
                    "threshold": 0.60,
                    "two_flat_loops": 2,
                },
                "regulatory": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.62,
                    "two_flat_loops": 1,
                },
                "financials": {
                    "min_new_facts": 0.6,
                    "min_new_domains": 0.4,
                    "staleness_strict": True,
                    "threshold": 0.64,
                    "two_flat_loops": 1,
                },
            },
            description="Gates de novidade/staleness por perfil + phase_score thresholds (v4.7)",
        )

        # ‚úÖ NOVO v4.7: Phase Score Weights (audit√°vel, configur√°vel)
        PHASE_SCORE_WEIGHTS: Dict[str, float] = Field(
            default={
                "w_cov": 0.35,  # Peso: coverage (key_questions respondidas)
                "w_nf": 0.25,  # Peso: novel_fact_ratio (fatos novos)
                "w_nd": 0.15,  # Peso: novel_domain_ratio (dom√≠nios novos)
                "w_div": 0.15,  # Peso: domain_diversity (distribui√ß√£o uniforme)
                "w_contra": 0.40,  # Penalidade: contradiction_score (contradi√ß√µes)
            },
            description="Pesos para c√°lculo de phase_score (v4.7) - Score = w_cov*coverage + w_nf*novel_facts + w_nd*novel_domains + w_div*diversity - w_contra*contradictions",
        )

        # ‚úÖ NOVO v4.7: Coverage target global (usado em decis√£o DONE)
        COVERAGE_TARGET: float = Field(
            default=0.70,
            ge=0.0,
            le=1.0,
            description="Target m√≠nimo de coverage para considerar DONE (0.0-1.0, default 0.70 = 70%)",
        )

        # ‚úÖ NOVO v4.7: Contradiction hard gate (for√ßa NEW_PHASE imediato)
        CONTRADICTION_HARD_GATE: float = Field(
            default=0.75,
            ge=0.0,
            le=1.0,
            description="Threshold de contradiction_score para for√ßar NEW_PHASE imediato (0.0-1.0, default 0.75)",
        )

        # Defaults por perfil (Planner ‚Üí fases)
        PROFILE_DEFAULTS: Dict[str, Dict[str, Any]] = Field(
            default={
                "company_profile": {
                    "time_hint": {"recency": "1y", "strict": False},
                    "source_bias": ["oficial", "primaria", "secundaria"],
                    "evidence_goal": {"min_domains": 3},
                    "lang_bias": ["pt-BR", "en"],
                    "geo_bias": ["BR", "global"],
                },
                "regulation_review": {
                    "time_hint": {"recency": "1y", "strict": True},
                    "source_bias": ["oficial", "primaria", "secundaria"],
                    "evidence_goal": {"min_domains": 3},
                    "lang_bias": ["pt-BR", "en"],
                    "geo_bias": ["BR", "global"],
                },
                "technical_spec": {
                    "time_hint": {"recency": "3y", "strict": False},
                    "source_bias": ["oficial", "primaria", "secundaria"],
                    "evidence_goal": {"min_domains": 3},
                    "lang_bias": ["en", "pt-BR"],
                    "geo_bias": ["global"],
                },
                "literature_review": {
                    "time_hint": {"recency": "3y", "strict": False},
                    "source_bias": ["primaria", "secundaria", "terciaria"],
                    "evidence_goal": {"min_domains": 3},
                    "lang_bias": ["en"],
                    "geo_bias": ["global"],
                },
                "history_review": {
                    "time_hint": {"recency": "3y", "strict": False},
                    "source_bias": ["primaria", "secundaria", "terciaria"],
                    "evidence_goal": {"min_domains": 3},
                    "lang_bias": ["pt-BR", "en"],
                    "geo_bias": ["BR", "global"],
                },
            },
            description="Defaults de fase por perfil de inten√ß√£o",
        )

        # Ensure seed_query includes @noticias for news phases (to activate discovery news mode)
        FORCE_NEWS_SEED_ATNOTICIAS: bool = Field(
            default=True,
            description="Garante que seed_query de fases de not√≠cias contenha '@noticias'",
        )

        # Discovery query expansion
        EXPAND_DISCOVERY_QUERY_WITH_ENTITIES: bool = Field(
            default=True,
            description="Expandir a query do discovery com todos os nomes de entidades do plano",
        )

    def __init__(self):
        self.valves = self.Valves()
        self._last_contract: Optional[dict] = None
        self._last_hash: Optional[str] = None
        self._intent_profile: str = "company_profile"
        self._detected_context: Optional[Dict[str, Any]] = (
            None  # Centralizar contexto detectado
        )
        self._context_locked: bool = False  # Prevenir re-detec√ß√£o ap√≥s lock (para SIGA)

        # ‚úÖ NOVO: Inicializar refer√™ncia para export_pdf_tool (ser√° preenchida no pipe())
        self._export_pdf_tool = None
        
        # ‚úÖ LINE-BUDGET GUARD: Validar tamanho de fun√ß√µes cr√≠ticas
        # Executado na inicializa√ß√£o para alertar sobre fun√ß√µes que excedem limites
        if getattr(self.valves, "ENABLE_LINE_BUDGET_GUARD", False):
            try:
                _warn_if_too_long(self.pipe, soft=500, hard=800)
                _warn_if_too_long(self._synthesize_final, soft=400, hard=600)
                _warn_if_too_long(_build_planner_prompt, soft=250, hard=400)
                _warn_if_too_long(_build_judge_prompt, soft=250, hard=400)
                _warn_if_too_long(_build_analyst_prompt, soft=200, hard=350)
            except Exception as e:
                # N√£o falhar a inicializa√ß√£o por erro no Line-Budget Guard
                logger.debug(f"[LBG] Line-Budget Guard failed: {e}")

    # No pipes() method needed - OpenWebUI auto-detects Pipe class

    # ==================== HELPER METHODS ====================
    # M√©todos utilit√°rios para reduzir duplica√ß√£o e melhorar legibilidade

    async def _safe_export_pdf(
        self, content: str, filename: str, title: str, __event_emitter__=None
    ) -> dict:
        """Wrapper seguro para chamar export_pdf_tool"""
        if not self._export_pdf_tool:
            return {"success": False, "error": "Export PDF Tool not available"}

        try:
            # Tentar chamar como async
            if asyncio.iscoroutinefunction(self._export_pdf_tool):
                result = await self._export_pdf_tool(
                    content=content,
                    filename=filename,
                    title=title,
                    __event_emitter__=__event_emitter__,  # ‚úÖ Passar event emitter
                )
            else:
                # Chamar como sync e converter para async
                result = await asyncio.to_thread(
                    self._export_pdf_tool,
                    content=content,
                    filename=filename,
                    title=title,
                    __event_emitter__=__event_emitter__,  # ‚úÖ Passar event emitter
                )

            # Parsear resultado se for string
            if isinstance(result, str):
                return json.loads(result)
            return result

        except Exception as e:
            return {"success": False, "error": str(e)}

    def _debug_log(self, message: str, context: str = "PIPE") -> None:
        """
        Helper para logs de debug verbose.

        Args:
            message: Mensagem de debug
            context: Contexto da mensagem (PIPE, SDK, MANUAL, etc.)

        Uso:
            self._debug_log("Context locked for SIGA", "SDK")
        """
        if getattr(self.valves, "VERBOSE_DEBUG", False):
            print(f"[DEBUG][{context}] {message}")

    def _get_current_profile(self) -> str:
        """
        Extrai perfil atual do contexto detectado com fallback seguro.

        Returns:
            Perfil atual ou DEFAULT_PROFILE se n√£o detectado

        Uso:
            profile = self._get_current_profile()
        """
        if self._detected_context:
            return self._detected_context.get("perfil", PipeConstants.DEFAULT_PROFILE)
        return PipeConstants.DEFAULT_PROFILE

    def _sync_contract_with_context(self, contract: dict) -> dict:
        """
        Garante que contract.intent_profile est√° sincronizado com _detected_context.

        Args:
            contract: Contract a ser sincronizado

        Returns:
            Contract com intent_profile sincronizado

        Uso:
            contract = self._sync_contract_with_context(contract)
        """
        if self._detected_context and "intent_profile" in contract:
            detected_profile = self._get_current_profile()
            current_profile = contract.get("intent_profile")

            if current_profile != detected_profile:
                print(
                    f"[SYNC] Profile mismatch: contract='{current_profile}' vs detected='{detected_profile}'. Using detected profile."
                )
                contract["intent_profile"] = detected_profile

        return contract

    def _emit_status(self, message: str, emoji: str = "üìã") -> str:
        """
        Formata mensagem de status para yield.

        Args:
            message: Mensagem de status
            emoji: Emoji prefixo (padr√£o: üìã)

        Returns:
            String formatada para yield

        Uso:
            yield self._emit_status("Context detected", "üîç")
        """
        return f"**[STATUS]** {emoji} {message}\n"

    def _validate_pipeline_state(self) -> None:
        """Valida consist√™ncia do estado interno do pipeline

        Verifica e corrige inconsist√™ncias entre estado interno.
        Chama este m√©todo no in√≠cio de pipe() para prevenir estados inv√°lidos.
        """
        # Check context lock consistency
        if self._context_locked and not self._detected_context:
            logger.warning("Context locked but no detected context - resetting lock")
            self._context_locked = False

        # Check contract consistency
        if self._last_contract:
            if not isinstance(self._last_contract, dict):
                logger.error("Invalid contract type, clearing")
                self._last_contract = None
                self._last_hash = None
            elif "fases" not in self._last_contract:
                logger.error("Contract missing fases, clearing")
                self._last_contract = None
                self._last_hash = None
            elif not isinstance(self._last_contract.get("fases"), list):
                logger.error("Contract fases is not a list, clearing")
                self._last_contract = None
                self._last_hash = None

        # Check profile sync
        if self._detected_context and self._intent_profile:
            detected = self._detected_context.get("perfil")
            if detected and detected != self._intent_profile:
                logger.warning(f"Profile mismatch syncing to detected: {detected}")
                self._intent_profile = detected

    # ==================== END HELPER METHODS ====================

    def _resolve_tool_deterministic(
        self,
        name_hint: str,
        available_keys: List[str],
        fallback_hints: List[str] = None,
    ) -> Optional[str]:
        """Resolve tool deterministically: nome exato > prefixo > substring"""
        # 1. Nome exato (via valves preferred tools)
        preferred = getattr(self.valves, "PREFERRED_TOOLS", {})
        if name_hint in preferred and preferred[name_hint] in available_keys:
            return preferred[name_hint]

        # 2. Nome exato direto
        if name_hint in available_keys:
            return name_hint

        # 3. Prefixo (case-insensitive)
        for k in available_keys:
            if k.lower().startswith(name_hint.lower()):
                return k

        # 4. Fallback hints (prefixo)
        if fallback_hints:
            for hint in fallback_hints:
                for k in available_keys:
                    if k.lower().startswith(hint.lower()):
                        return k

        # 5. Substring (case-insensitive) - √∫ltimo recurso
        for k in available_keys:
            if name_hint.lower() in k.lower():
                return k

        # 6. Fallback hints (substring)
        if fallback_hints:
            for hint in fallback_hints:
                for k in available_keys:
                    if hint.lower() in k.lower():
                        return k

        return None

    def _resolve_tools(self, __tools__: Dict[str, Dict[str, Any]]):
        """Resolve tools using deterministic heuristics"""
        if not __tools__:
            raise RuntimeError(
                "No tools available. Please configure tools in OpenWebUI."
            )

        keys = list(__tools__.keys())
        logger.debug("Available tools: %s", keys)

        # Resolu√ß√£o determin√≠stica: nome exato > prefixo > substring
        discover_key = self._resolve_tool_deterministic(
            "discovery", keys, ["discover", "search"]
        )
        scrape_key = self._resolve_tool_deterministic(
            "scraper", keys, ["scrape", "scraper"]
        )
        context_reducer_key = self._resolve_tool_deterministic(
            "context_reducer", keys, ["reduce", "context"]
        )

        # Check if we found the required tools
        if not discover_key:
            raise RuntimeError(f"Discovery tool not found. Available tools: {keys}")
        if not scrape_key:
            raise RuntimeError(f"Scraper tool not found. Available tools: {keys}")

        logger.debug("Using discovery tool: %s", discover_key)
        logger.debug("Using scraper tool: %s", scrape_key)
        if context_reducer_key:
            logger.debug("Using context reducer tool: %s", context_reducer_key)

        # Get the callables
        d_callable_raw = __tools__[discover_key]["callable"]
        s_callable = __tools__[scrape_key]["callable"]
        cr_callable = (
            __tools__[context_reducer_key]["callable"] if context_reducer_key else None
        )

        # Resolve discovery tool using deepresearcher logic
        def _resolve_discovery_tool(tools_dict: Dict[str, Any]) -> Optional[str]:
            """Resolve discovery tool preferring rails-capable callable.

            Order:
            1) PREFERRED_TOOLS valve (discover)
            2) Signature-first: callable that accepts 'must_terms' (rails)
            3) Name-based candidates
            """
            if not tools_dict:
                return None

            # 1) Prefer explicit valve mapping
            try:
                preferred = getattr(self.valves, "PREFERRED_TOOLS", {}) or {}
                if isinstance(preferred, dict):
                    for key in ("discover", "discovery", "discovery_tool"):
                        name = preferred.get(key)
                        if name and name in tools_dict:
                            return name
            except Exception:
                pass

            # 2) Signature-first: pick callable that supports rails
            try:
                import inspect

                for name, info in (tools_dict or {}).items():
                    fn = (info or {}).get("callable")
                    if not fn:
                        continue
                    try:
                        params = set(inspect.signature(fn).parameters.keys())
                    except Exception:
                        continue
                    if {
                        "must_terms",
                        "avoid_terms",
                        "time_hint",
                        "lang_bias",
                        "geo_bias",
                        "min_domains",
                        "official_domains",
                    } & params:
                        return name
            except Exception:
                pass

            # 3) Fallback: name-based resolution
            discover_candidates = [
                "discovery_tool",
                "discovery_tool_clone",
                "discover",
                "search_web",
                "search",
                "supersearch",
                "discovery",
                "exa_search",
                "discoverywexa",
                "url searcher",
                "url_searcher",
                "discoverywExa",
            ]

            for candidate in discover_candidates:
                if candidate in tools_dict:
                    return candidate

            for tool_name in tools_dict.keys():
                if any(
                    candidate.lower() in tool_name.lower()
                    for candidate in discover_candidates
                ):
                    return tool_name

            return None

        # Find the actual discovery tool
        discovery_tool_name = _resolve_discovery_tool(__tools__)
        if discovery_tool_name:
            discovery_tool_with_rails = __tools__[discovery_tool_name]["callable"]
        else:
            discovery_tool_with_rails = d_callable_raw  # Fallback

        # Create wrapper for discovery tool to handle extra parameters
        async def d_callable_wrapper(
            query: str,
            must_terms: Optional[List[str]] = None,
            avoid_terms: Optional[List[str]] = None,
            time_hint: Optional[Dict[str, Any]] = None,
            lang_bias: Optional[List[str]] = None,
            geo_bias: Optional[List[str]] = None,
            source_bias: Optional[str] = None,
            min_domains: Optional[int] = None,
            official_domains: Optional[List[str]] = None,
            profile: Optional[str] = None,
            phase_objective: Optional[str] = None,
            **kwargs,
        ):
            """Wrapper to handle discovery tool parameters"""
            # Extract time_hint parameters
            after = None
            before = None
            if time_hint:
                after = time_hint.get("after")
                before = time_hint.get("before")

            # If it's a news profile/phase, enforce @noticias and derive date range from recency
            try:
                eff_profile = (profile or "general").lower()
                is_news = ("news" in eff_profile) or (
                    "@noticias" in (query or "").lower()
                )
                if not is_news:
                    # Heuristic: if seed suggests 'not√≠cias' explicitly
                    if any(
                        tok in (query or "").lower()
                        for tok in ["noticias", "not√≠cias", "@noticias"]
                    ):
                        is_news = True
                if is_news:
                    # Force profile to news for downstream tool behavior
                    profile = "news"
                    if "@noticias" not in (query or ""):
                        query = f"@noticias {query}".strip()
                    # derive after/before if not explicitly provided using recency
                    if not after or not before:
                        from datetime import datetime, timedelta

                        recency = (time_hint or {}).get("recency", "90d")
                        now = datetime.utcnow()
                        if recency == "90d":
                            start = now - timedelta(days=90)
                            temporal_phrase = "√∫ltimos 90 dias"
                        elif recency == "1y":
                            start = now - timedelta(days=365)
                            temporal_phrase = "√∫ltimos 12 meses"
                        elif recency == "3y":
                            start = now - timedelta(days=365 * 3)
                            temporal_phrase = "√∫ltimos 3 anos"
                        else:
                            start = now - timedelta(days=365)
                            temporal_phrase = "√∫ltimos 12 meses"
                        # Set day-precision ISO
                        after = after or start.strftime("%Y-%m-%d")
                        before = before or now.strftime("%Y-%m-%d")
                    else:
                        # If explicit after/before provided, add a generic phrase to help parser
                        temporal_phrase = None

                    # Strengthen time_hint for news: strict window
                    if time_hint is None:
                        time_hint = {
                            "recency": (time_hint or {}).get("recency", "1y"),
                            "strict": True,
                        }
                    else:
                        time_hint.setdefault("recency", "1y")
                        time_hint["strict"] = True

                    # Help tool-side parser by embedding a natural language temporal hint
                    try:
                        if temporal_phrase:
                            low_q = (query or "").lower()
                            if temporal_phrase not in low_q:
                                query = f"{query} {temporal_phrase}".strip()
                    except Exception:
                        pass
            except Exception:
                pass

            # Make time filters PREFERENTIAL (soft) rather than RIGID (hard)
            # This allows comprehensive coverage while still prioritizing recent sources

            # Detect if this is clearly a historical topic that needs full temporal coverage
            is_clearly_historical = any(
                term in (query or "").lower()
                for term in [
                    "revolu√ß√£o",
                    "hist√≥ria",
                    "hist√≥rico",
                    "passado",
                    "antigo",
                    "cl√°ssico",
                    "medieval",
                    "renascimento",
                    "guerra mundial",
                    "imp√©rio",
                    "monarquia",
                    "s√©culo",
                    "idade m√©dia",
                    "antiguidade",
                    "pr√©-hist√≥ria",
                ]
            )

            # Detect if this is clearly a current event that needs recent focus
            is_current_event = any(
                term in (query or "").lower()
                for term in [
                    "hoje",
                    "agora",
                    "atual",
                    "recente",
                    "√∫ltimo",
                    "novo",
                    "lan√ßamento",
                    "elei√ß√µes 2024",
                    "copa 2024",
                    "olimp√≠adas 2024",
                    "covid-19 2024",
                ]
            )

            if is_clearly_historical:
                # For clearly historical topics, ignore time filters completely
                after = None
                before = None
                logger.info("üîç HISTORICAL DETECTED - Ignoring time filters: %s", query)
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DISCOVERY] üîç Historical query detected, ignoring time filters: {query}"
                    )
            elif is_current_event or ("@noticias" in (query or "")):
                # For current events/news, keep/enforce time filters
                logger.info("üì∞ NEWS/CURRENT EVENT - Applying time filters: %s", query)
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DISCOVERY] üì∞ News/current event query, applying time filters: {query}"
                    )
            else:
                # For mixed topics (sectoral analysis, technology), make filters PREFERENTIAL
                # Keep the time hint but don't enforce it strictly
                if after or before:
                    logger.info("‚öñÔ∏è MIXED TOPIC - Time filters as preference: %s", query)
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DISCOVERY] ‚öñÔ∏è Mixed topic query, time filters as preference: {query}"
                        )
                else:
                    logger.info(
                        "üåê NO TIME FILTERS - Full temporal coverage: %s", query
                    )
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DISCOVERY] üåê No time filters, full temporal coverage: {query}"
                        )

            # Build kwargs dynamically based on the callable's supported parameters
            import inspect

            supported_params = set()
            try:
                supported_params = set(
                    inspect.signature(discovery_tool_with_rails).parameters.keys()
                )
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG][D_WRAPPER] Discovery tool supports params: {supported_params}"
                    )
            except Exception as e:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[WARNING][D_WRAPPER] Could not inspect discovery tool signature: {e}"
                    )
                # Assume basic params if inspection fails
                supported_params = {
                    "query",
                    "profile",
                    "after",
                    "before",
                    "whitelist",
                    "pages_per_slice",
                }

            # Check if tool supports minimum required params
            if "query" not in supported_params:
                logger.error(
                    "[D_WRAPPER] Discovery tool does not support 'query' parameter!"
                )
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[ERROR][D_WRAPPER] Discovery tool missing 'query' param. Available: {supported_params}"
                    )
                return {"urls": []}

            base_kwargs = {
                "query": query,
                "profile": profile or "general",
                "after": after,
                "before": before,
                "whitelist": "",
                "pages_per_slice": 2,
            }

            # üî¥ P0: Log quando phase_objective for recebido ou n√£o
            if phase_objective:
                logger.info(
                    f"[D_WRAPPER] ‚úÖ Phase objective received: '{phase_objective[:100]}...'"
                )
            else:
                logger.warning(
                    f"[D_WRAPPER] ‚ö†Ô∏è Phase objective NOT received (got {type(phase_objective)})"
                )

            rails_kwargs = {
                "must_terms": must_terms,
                "avoid_terms": avoid_terms,
                "time_hint": time_hint,
                "lang_bias": lang_bias,
                "geo_bias": geo_bias,
                "min_domains": min_domains,
                "official_domains": official_domains,
                # üî¥ P0: Propagar phase_objective para Discovery Planner e Selector
                "phase_objective": phase_objective,
            }

            # Filter kwargs to only what the callable accepts
            final_kwargs = {}
            for k, v in base_kwargs.items():
                if k in supported_params:
                    # Skip None values except for query (which is required)
                    if v is not None or k == "query":
                        final_kwargs[k] = v

            for k, v in rails_kwargs.items():
                if k in supported_params and v is not None:
                    final_kwargs[k] = v

            # Ensure query is never empty
            if not final_kwargs.get("query"):
                logger.error("[D_WRAPPER] Query is empty!")
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[ERROR][D_WRAPPER] Query is empty or None")
                return {"urls": []}

            # PATCH 3 (FASE 2): Propagar configs do Pipe para Discovery Tool
            # Alinha timeouts, retries e outras configs para evitar falhas em cascata
            if "request_timeout" in supported_params:
                final_kwargs["request_timeout"] = self.valves.LLM_TIMEOUT_DEFAULT
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG][D_WRAPPER] Setting request_timeout={self.valves.LLM_TIMEOUT_DEFAULT}s"
                    )

            if "max_retries" in supported_params:
                max_retries = getattr(self.valves, "LLM_MAX_RETRIES", 3)
                final_kwargs["max_retries"] = max_retries
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEBUG][D_WRAPPER] Setting max_retries={max_retries}")

            if "llm_timeout" in supported_params:
                final_kwargs["llm_timeout"] = self.valves.LLM_TIMEOUT_DEFAULT

            # Propagar model se discovery tool suportar
            if "llm_model" in supported_params:
                final_kwargs["llm_model"] = self.valves.LLM_MODEL
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG][D_WRAPPER] Setting llm_model={self.valves.LLM_MODEL}"
                    )

            # Propagar limite de p√°ginas se configurado
            if "pages_per_slice" in supported_params:
                pages_per_slice = getattr(self.valves, "DISCOVERY_PAGES_PER_SLICE", 2)
                final_kwargs["pages_per_slice"] = pages_per_slice

            # PATCH v4.5.1: Solicitar retorno como dict (evita json.dumps/loads overhead)
            if "return_dict" in supported_params:
                final_kwargs["return_dict"] = True
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG][D_WRAPPER] Requesting dict return (eliminates JSON parse overhead)"
                    )

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[DEBUG][D_WRAPPER] Calling discovery tool with params: {list(final_kwargs.keys())}"
                )
                print(f"[DEBUG][D_WRAPPER] Query: '{final_kwargs.get('query', 'N/A')}'")
                print(
                    f"[DEBUG][D_WRAPPER] Profile: {final_kwargs.get('profile', 'N/A')}"
                )
                print(
                    f"[DEBUG][D_WRAPPER] Must terms: {final_kwargs.get('must_terms', 'N/A')}"
                )
                print(
                    f"[DEBUG][D_WRAPPER] Avoid terms: {final_kwargs.get('avoid_terms', 'N/A')}"
                )
                if "after" in final_kwargs or "before" in final_kwargs:
                    print(
                        f"[DEBUG][D_WRAPPER] Time range: {final_kwargs.get('after', 'N/A')} to {final_kwargs.get('before', 'N/A')}"
                    )
                if "phase_objective" in final_kwargs:
                    print(
                        f"[DEBUG][D_WRAPPER] ‚úÖ Phase objective: '{final_kwargs.get('phase_objective', 'N/A')[:80]}...'"
                    )

            try:
                result = await discovery_tool_with_rails(**final_kwargs)

                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[DEBUG][D_WRAPPER] Discovery returned type: {type(result)}")
                    if isinstance(result, dict):
                        print(
                            f"[DEBUG][D_WRAPPER] Discovery result keys: {list(result.keys())}"
                        )
                        if "urls" in result:
                            print(
                                f"[DEBUG][D_WRAPPER] URLs count: {len(result.get('urls', []))}"
                            )
                        if "candidates" in result:
                            print(
                                f"[DEBUG][D_WRAPPER] Candidates count: {len(result.get('candidates', []))}"
                            )
                    elif isinstance(result, str):
                        print(
                            f"[DEBUG][D_WRAPPER] Discovery returned string, length: {len(result)}"
                        )

                # Validate result is not empty/None
                if result is None:
                    logger.warning("[D_WRAPPER] Discovery tool returned None")
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            "[WARNING][D_WRAPPER] Discovery tool returned None, returning empty dict"
                        )
                    return {"urls": []}

                return result

            except TypeError as e:
                logger.error(f"[D_WRAPPER] TypeError calling discovery tool: {e}")
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[ERROR][D_WRAPPER] TypeError: {e}")
                    print(f"[ERROR][D_WRAPPER] Supported params: {supported_params}")
                    print(
                        f"[ERROR][D_WRAPPER] Passed params: {list(final_kwargs.keys())}"
                    )
                    import traceback

                    traceback.print_exc()
                return {"urls": []}
            except Exception as e:
                logger.error(f"[D_WRAPPER] Exception calling discovery tool: {e}")
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(f"[ERROR][D_WRAPPER] Exception: {e}")
                    import traceback

                    traceback.print_exc()
                return {"urls": []}

        return d_callable_wrapper, s_callable, cr_callable

    async def _extract_contract_from_history(self, body: dict) -> Optional[dict]:
        """Extract contract from message history when 'siga' is called."""
        try:
            messages = body.get("messages", [])

            # Find the last assistant message that contains a plan
            for msg in reversed(messages):
                if msg.get("role") == "assistant":
                    content = msg.get("content", "")
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(f"[DEBUG] Checking message content: {content[:200]}...")

                    # Look for plan markers (both SDK and Manual formats)
                    has_fase = "Fase 1/" in content and "Objetivo:" in content
                    has_plano = "üìã Plano" in content
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DEBUG] Plan markers: has_fase={has_fase}, has_plano={has_plano}"
                        )

                    if has_fase or has_plano:
                        # Try to extract contract using LLM
                        planner = PlannerLLM(self.valves)

                        # Create a prompt to extract the contract from the rendered plan
                        extract_prompt = f"""Extraia o contrato JSON do plano renderizado abaixo.
                        
PLANO RENDERIZADO:
{content}

Retorne APENAS o JSON do contrato no formato:
{{
  "intent_profile": "company_profile",
  "intent": "resumo do objetivo",
  "entities": {{"canonical": ["entidade principal"], "aliases": []}},
  "phases": [
    {{
      "name": "nome da fase",
      "objective": "objetivo da fase",
      "seed_query": "<3-6 palavras, sem operadores>",
      "must_terms": ["termo1", "termo2"],
      "avoid_terms": ["ru√≠do"],
      "time_hint": {{"recency": "1y", "strict": false}},
      "source_bias": ["oficial", "primaria", "secundaria"],
      "evidence_goal": {{"official_or_two_independent": true, "min_domains": 3}},
      "lang_bias": ["pt-BR", "en"],
      "geo_bias": ["BR", "global"]
    }}
  ],
  "quality_rails": {{"min_unique_domains": 2, "need_official_or_two_independent": true}},
  "budget": {{"max_rounds": 2}}
}}

INSTRU√á√ïES:
- Extraia o objetivo principal do plano
- Identifique as fases e seus objetivos
- Se faltar seed_query, gere com 3-6 palavras (sem operadores)
- Mantenha campos obrigat√≥rios com valores padr√£o
- Retorne APENAS o JSON v√°lido"""

                        # Filter params for GPT-5/O1 compatibility
                        safe_extract_params = get_safe_llm_params(
                            planner.model_name, planner.generation_kwargs
                        )
                        result = await _safe_llm_run_with_retry(
                            planner.llm,
                            extract_prompt,
                            safe_extract_params,
                            timeout=planner.valves.LLM_TIMEOUT_DEFAULT,
                            max_retries=1,
                        )
                        if result:
                            try:
                                contract = _extract_json_from_text(result)
                                if (
                                    contract
                                    and "phases" in contract
                                    and len(contract["phases"]) > 0
                                ):
                                    # Validate that we have the essential fields
                                    for phase in contract["phases"]:
                                        if not phase.get("objective") or not phase.get(
                                            "seed_query"
                                        ):
                                            # Re-ask LLM for seed_query if missing; avoid programmatic fallback
                                            if not phase.get(
                                                "seed_query"
                                            ) and phase.get("objective"):
                                                try:
                                                    reask = f"Gere apenas uma seed query (3-6 palavras, sem operadores) para: '{phase.get('objective','')}'. Retorne s√≥ a seed."
                                                    safe_reask = get_safe_llm_params(
                                                        planner.model_name,
                                                        {"temperature": 0.2},
                                                    )
                                                    re = await _safe_llm_run_with_retry(
                                                        planner.llm,
                                                        reask,
                                                        safe_reask,
                                                        timeout=planner.valves.LLM_TIMEOUT_DEFAULT,
                                                        max_retries=1,
                                                    )
                                                    if re and re.get("replies"):
                                                        candidate = (
                                                            re["replies"][0]
                                                            .strip()
                                                            .strip('"')
                                                            .strip("'")
                                                        )
                                                        for op in [
                                                            "site:",
                                                            "filetype:",
                                                            "after:",
                                                            "before:",
                                                            "AND",
                                                            "OR",
                                                            '"',
                                                            "'",
                                                        ]:
                                                            candidate = (
                                                                candidate.replace(
                                                                    op, " "
                                                                )
                                                            )
                                                        words = candidate.split()
                                                        if 3 <= len(words) <= 6:
                                                            phase["seed_query"] = (
                                                                " ".join(words)
                                                            )
                                                except Exception:
                                                    pass
                                            if not phase.get("objective"):
                                                phase["objective"] = (
                                                    f"An√°lise: {phase.get('seed_query', 't√≥pico')}"
                                                )
                                    return contract
                            except (json.JSONDecodeError, KeyError, ValueError) as e:
                                logger.warning(
                                    f"Failed to parse extracted contract: {e}"
                                )
                            except Exception as e:
                                logger.error(f"Unexpected error parsing contract: {e}")
                                raise ContractValidationError(
                                    f"Contract parsing failed: {e}"
                                ) from e

            return None
        except ContractValidationError:
            raise  # Re-raise specific errors
        except Exception as e:
            logger.warning(f"Failed to extract contract from history: {e}")
            return None

    async def pipe(
        self,
        body: dict,
        __user__: dict = None,
        __tools__: dict = None,
        __event_emitter__: Optional[Callable] = None,
        **kwargs,
    ):
        # Generate correlation ID for request tracing
        correlation_id = str(uuid.uuid4())[:8]
        logger.info(
            "Pipeline execution started", extra={"correlation_id": correlation_id}
        )

        # Validate internal state before processing
        self._validate_pipeline_state()

        # Extract current date from OpenWebUI metadata or system
        current_date = None
        try:
            metadata = (body or {}).get("metadata", {})
            variables = metadata.get("variables", {}) if metadata else {}
            current_date = variables.get("{{CURRENT_DATE}}") or variables.get(
                "CURRENT_DATE"
            )
        except Exception:
            pass
        if not current_date:
            from datetime import datetime

            current_date = datetime.now().strftime("%Y-%m-%d")

        # Store for use in prompts
        self._current_date = current_date

        # read valves override from body
        val_in = (body or {}).get("valves")
        if val_in:
            try:
                # pydantic copy/update
                self.valves = (
                    self.valves.model_copy(update=val_in)
                    if hasattr(self.valves, "model_copy")
                    else self.Valves(**{**self.valves.__dict__, **val_in})
                )
            except Exception:
                # best-effort set attributes
                for k, v in (val_in or {}).items():
                    if hasattr(self.valves, k):
                        setattr(self.valves, k, v)

        user_msg = (
            body.get("messages", [{"content": ""}])[-1].get("content", "") or ""
        ).strip()
        low = user_msg.lower()

        # üéØ DETEC√á√ÉO DE INTEN√á√ÉO (antes de qualquer processamento)
        # Comandos de continua√ß√£o
        is_continue_command = any(
            kw in low for kw in ["siga", "continue", "prossiga", "next"]
        )

        # ‚úÖ NOVO: Detectar inten√ß√£o de refinamento de plano
        # RAZ√ÉO: Preservar contexto quando usu√°rio quer ajustar (n√£o criar novo)
        # IMPACTO: Evita mudan√ßa de perfil/setor em refinamentos simples
        refinement_keywords = [
            "adicione",
            "inclua",
            "acrescente",
            "mude",
            "altere",
            "ajuste",
            "remova",
            "tire",
            "delete",
            "corrija",
            "refine",
            "modifique",
            "aumente",
            "reduza",
            "expanda",
            "foque mais",
            "menos em",
            "troque",
            "substitua",
            "adapte",
            "personalize",
            "atualize",
        ]
        is_refinement = any(kw in low for kw in refinement_keywords)
        has_previous_plan = bool(self._last_contract)

        # üîí DECIS√ÉO: Preservar contexto ou re-detectar?
        # Preservar se: (comando "siga") OU (refinamento E tem plano anterior)
        should_preserve_context = is_continue_command or (
            is_refinement and has_previous_plan
        )

        if should_preserve_context and self._detected_context:
            # Manter contexto anterior (refinamento ou siga)
            logger.info(
                f"[PIPE] Contexto preservado: is_continue={is_continue_command}, is_refinement={is_refinement}, has_plan={has_previous_plan}"
            )
            yield f"**[CONTEXT]** üîí Mantendo contexto: {self._detected_context.get('perfil', 'N/A')}\n"
            if is_refinement:
                yield f"**[INFO]** üí° Modo refinamento detectado - ajustando plano existente\n"
        else:
            # Re-detectar contexto (nova query)
            if self._context_locked:
                logger.info("[PIPE] Nova query detectada - desbloqueando contexto")
                self._context_locked = False
                self._detected_context = None

            self._detected_context = await self._detect_unified_context(user_msg, body)
            logger.info(f"[PIPE] Contexto detectado: {self._detected_context}")

            # üîó SINCRONIZAR PERFIL DETECTADO com intent_profile (fonte √∫nica de verdade)
            if self._detected_context:
                self._intent_profile = self._detected_context.get(
                    "perfil", "company_profile"
                )
                logger.info(f"[PIPE] Perfil sincronizado: {self._intent_profile}")
                yield f"**[CONTEXT]** üîç Perfil: {self._detected_context.get('perfil', 'N/A')} | Setor: {self._detected_context.get('setor', 'N/A')} | Tipo: {self._detected_context.get('tipo', 'N/A')}\n"

        d_callable, s_callable, cr_callable = self._resolve_tools(__tools__ or {})

        # ‚úÖ NOVO: Resolver export_pdf_tool se dispon√≠vel
        if __tools__:
            export_pdf_key = self._resolve_tool_deterministic(
                "export_pdf",
                list(__tools__.keys()),
                fallback_hints=[
                    "export",
                    "pdf",
                    "export_pdf_from_json",
                    "export_pdf_from_text",
                ],
            )

            if export_pdf_key:
                self._export_pdf_tool = __tools__[export_pdf_key]["callable"]
                if self.valves.DEBUG_LOGGING:
                    yield f"**[DEBUG]** Export PDF Tool encontrada: {export_pdf_key}\n"
            else:
                self._export_pdf_tool = None
                if self.valves.DEBUG_LOGGING:
                    yield f"**[DEBUG]** Export PDF Tool n√£o dispon√≠vel\n"
        # Manual route - single execution path
        # If the user asks to continue (siga), execute stored contract
        if low in {"siga", "continue", "prosseguir"}:
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[DEBUG] SIGA mode: _last_contract exists: {bool(self._last_contract)}"
                )
            if self._last_contract:
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG] _last_contract fases: {len(self._last_contract.get('fases', []))}"
                    )

            # Try to get contract from stored state first
            if not self._last_contract:
                # Try to extract contract from message history
                yield "**[INFO]** Procurando plano no hist√≥rico...\n"
                contract = await self._extract_contract_from_history(body)
                if contract:
                    self._last_contract = contract

                    # üîó SINCRONIZAR contract recuperado com contexto ATUAL
                    # PROBLEMA: contexto detectado agora pode ser diferente do contexto original
                    # SOLU√á√ÉO: Tentar recuperar contexto do hist√≥rico ou usar atual com warning
                    if "intent_profile" in contract:
                        historical_profile = contract.get("intent_profile")
                        current_profile = (
                            self._detected_context.get("perfil", "company_profile")
                            if self._detected_context
                            else "company_profile"
                        )

                        if historical_profile != current_profile:
                            logger.warning(
                                f"[SIGA] Context drift detected: historical={historical_profile}, current={current_profile}. Using historical to maintain consistency."
                            )
                            # Usar perfil do contract hist√≥rico para manter consist√™ncia
                            if self._detected_context:
                                self._detected_context["perfil"] = historical_profile
                                self._intent_profile = historical_profile

                    yield "**[INFO]** ‚úÖ Plano recuperado do hist√≥rico\n"
                else:
                    yield "**[AVISO]** Nenhum contrato pendente ou encontrado no hist√≥rico\n"
                    yield "**[DICA]** Tente criar um novo plano primeiro\n"
                    return

            job_id = f"cached_{int(time.time() * 1000)}"

            orch = Orchestrator(
                self.valves, d_callable, s_callable, cr_callable, job_id
            )
            orch.set_contract(self._last_contract)  # ‚Üê Define contract e extrai queries

            # üîó GARANTIR que Orchestrator use perfil detectado (fonte √∫nica)
            if self._detected_context:
                orch.intent_profile = self._detected_context.get(
                    "perfil", "company_profile"
                )
                logger.info(
                    f"[ORCH] Perfil sincronizado com contexto detectado: {orch.intent_profile}"
                )

            yield f"\n### Execu√ß√£o iniciada\n"
            phase_results = []
            telemetry_data = {
                "execution_id": job_id,
                "start_time": time.time(),
                "phases": [],
            }

            for i, ph in enumerate(self._last_contract.get("fases", []), 1):
                objetivo, q = ph["objetivo"], ph["query_sugerida"]
                yield f"\n**Fase {i}** ‚Äì {objetivo}\n"

                phase_start_time = time.time()
                loops = 0
                phase_telemetry = {
                    "phase": i,
                    "objective": objetivo,
                    "query": q,
                    "start_time": phase_start_time,
                    "loops": [],
                }

                # Track queries to detect infinite loops and add phase timeout
                seen_queries = set()
                phase_timeout_start = time.time()
                PHASE_TIMEOUT = 600  # 10 minutes max per phase

                # Ensure result variable exists even if loop exits early due to error/timeout
                res = None
                res_already_added = (
                    False  # Track if result was already added to phase_results
                )
                while True:
                    # Check phase timeout
                    if time.time() - phase_timeout_start > PHASE_TIMEOUT:
                        logger.error(
                            f"Phase timeout after {PHASE_TIMEOUT}s",
                            extra={"phase": i, "correlation_id": correlation_id},
                        )
                        yield f"**[ERRO]** Timeout de fase excedido ({PHASE_TIMEOUT}s)\n"
                        break

                    loop_start_time = time.time()
                    loops += 1

                    # Safety check: prevent infinite loops
                    if (
                        loops > self.valves.MAX_AGENT_LOOPS * 2
                    ):  # Double the limit as safety
                        yield f"**[ERROR]** Loop infinito detectado! Saindo ap√≥s {loops} itera√ß√µes.\n"
                        break

                    try:
                        # NOTA: ph (phase_context) j√° foi ajustado para foco se should_refine=True
                        res = await orch.run_iteration(q, phase_context=ph)

                        # üî¥ DEFESA P0: Validar estrutura de res antes de consumir
                        if not isinstance(res, dict):
                            logger.error(
                                f"[CRITICAL] run_iteration returned non-dict: {type(res)}"
                            )
                            yield f"**[ERROR]** Itera√ß√£o retornou tipo inv√°lido: {type(res)}\n"
                            break

                        if "analysis" not in res:
                            logger.error(
                                "[CRITICAL] run_iteration missing 'analysis' key"
                            )
                            yield f"**[ERROR]** Resposta de itera√ß√£o incompleta (sem 'analysis')\n"
                            break

                    except Exception as e:
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(f"[ERROR] run_iteration failed: {e}")
                            import traceback

                            traceback.print_exc()
                        yield f"**[ERROR]** Falha na itera√ß√£o: {e}\n"
                        break
                    loop_end_time = time.time()

                    discovered_count = len(res.get("discovered_urls", []))
                    new_urls_count = len(res.get("new_urls", []))
                    accumulated_size = res.get("accumulated_context_size", 0)

                    yield f"**[discovery]** {discovered_count} URLs\n"
                    if discovered_count == 0 and accumulated_size == 0:
                        yield f"**[‚ö†Ô∏è AVISO]** Discovery retornou 0 URLs e n√£o h√° contexto acumulado. Verifique se a tool_discovery est√° funcionando corretamente.\n"
                    elif discovered_count == 0 and accumulated_size > 0:
                        yield f"**[INFO]** Discovery retornou 0 URLs novas, mas h√° {accumulated_size} chars de contexto acumulado das itera√ß√µes anteriores.\n"

                    yield f"**[cache]** {len(res['cached_urls'])} j√° scraped, {new_urls_count} novas\n"
                    yield f"**[accumulator]** {accumulated_size} chars acumulados\n"

                    # Show analyst insights
                    analysis = res["analysis"]

                    # üî¥ DEFESA P0.1: Validar que analysis √© dict
                    if not isinstance(analysis, dict):
                        logger.error(
                            f"[CRITICAL] analysis is not dict: {type(analysis)}, value: {repr(analysis)[:200]}"
                        )
                        yield f"**[ERROR]** An√°lise retornou tipo inv√°lido\n"
                        # Criar analysis vazio para continuar
                        analysis = {"summary": "", "facts": [], "lacunas": []}

                    summary = analysis.get("summary", "")
                    facts = analysis.get("facts", [])
                    evidence = analysis.get("evidence", [])
                    evidence_metrics = res.get("evidence_metrics", {})

                    # Debug: verificar contexto passado para analista
                    accumulated_context = res.get("accumulated_context", "")
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DEBUG] Accumulated context size: {len(accumulated_context)} chars"
                        )
                        print(
                            f"[DEBUG] Context preview: {accumulated_context[:300]}..."
                            if accumulated_context
                            else "[DEBUG] Empty context"
                        )

                    # Debug: verificar se h√° dados do analista
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DEBUG] Analysis keys: {list(analysis.keys()) if analysis else 'None'}"
                        )
                        print(f"[DEBUG] Evidence metrics: {evidence_metrics}")
                        print(f"[DEBUG] Facts count: {len(facts)}")
                        print(
                            f"[DEBUG] RES keys: {list(res.keys()) if res else 'None'}"
                        )
                        print(f"[DEBUG] Analysis content: {str(analysis)[:500]}...")
                        print(f"[DEBUG] Summary: {summary[:200]}...")
                    if facts:
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(
                                f"[DEBUG] First fact: {facts[0] if facts else 'None'}"
                            )
                    else:
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(f"[DEBUG] No facts found in analysis")

                    if summary:
                        yield f"**[analyst]** üí° {summary}\n"
                    if facts:
                        yield f"**[analyst]** üìä {len(facts)} fatos encontrados\n"
                        for i, fact in enumerate(facts[:3], 1):  # Show first 3 facts
                            if isinstance(fact, dict):
                                texto = fact.get("texto", str(fact))
                                confianca = fact.get("confian√ßa", "")
                                contradicao = fact.get("contradicao", False)
                                critical = fact.get("critical", False)
                                conf_emoji = (
                                    "üü¢"
                                    if confianca == "alta"
                                    else "üü°" if confianca == "m√©dia" else "üî¥"
                                )
                                contra_emoji = "‚ö†Ô∏è" if contradicao else ""
                                critical_emoji = "üî•" if critical else ""
                                yield f"   {i}. {conf_emoji} {contra_emoji} {critical_emoji} {texto}\n"
                            else:
                                yield f"   {i}. {fact}\n"
                        if len(facts) > 3:
                            yield f"   ... e mais {len(facts) - 3} fatos\n"

                    # Show evidence metrics
                    if evidence_metrics:
                        coverage = evidence_metrics.get("evidence_coverage", 0) * 100
                        multi_sources = evidence_metrics.get(
                            "facts_with_multiple_sources", 0
                        )
                        unique_domains = evidence_metrics.get("unique_domains", 0)
                        high_conf = evidence_metrics.get("high_confidence_facts", 0)
                        contradictions = evidence_metrics.get("contradictions", 0)
                        yield f"**[evidence]** üìã {coverage:.0f}% fatos com evid√™ncia, {multi_sources} com m√∫ltiplas fontes, {unique_domains} dom√≠nios √∫nicos\n"
                        yield f"**[quality]** üéØ {high_conf} alta confian√ßa, {contradictions} contradi√ß√µes\n"
                        # Expor ratios no log de execu√ß√£o para consumo do Judge gates
                        new_facts_ratio = res.get("new_facts_ratio")
                        new_domains_ratio = res.get("new_domains_ratio")
                        if (
                            new_facts_ratio is not None
                            and new_domains_ratio is not None
                        ):
                            yield f"**[telemetry]** üìà novidade: fatos {new_facts_ratio:.2f}, dom√≠nios {new_domains_ratio:.2f}\n"

                    # Show lacunas
                    lacunas = analysis.get("lacunas", [])
                    if lacunas:
                        # P0: lacunas pode ser lista de dicts (novo) ou strings (legado)
                        lacunas_display = []
                        for lac in lacunas[:2]:
                            if isinstance(lac, dict):
                                lacunas_display.append(lac.get("descricao", str(lac)))
                            else:
                                lacunas_display.append(str(lac))
                        yield f"**[lacunas]** üîç {len(lacunas)} lacunas identificadas: {', '.join(lacunas_display)}{'...' if len(lacunas) > 2 else ''}\n"

                    verdict = res["judgement"].get("verdict", "done")
                    reasoning = res["judgement"].get("reasoning", "")
                    # next_query pode vir dentro de 'refine' no JSON do Judge
                    next_query = res["judgement"].get("next_query", "")
                    if (not next_query) and isinstance(
                        res["judgement"].get("refine"), dict
                    ):
                        next_query = res["judgement"]["refine"].get("next_query", "")
                    unexpected_findings = res["judgement"].get(
                        "unexpected_findings", []
                    )
                    proposed_phase = res["judgement"].get("proposed_phase", {})

                    # Verificar diminishing returns program√°tico
                    diminishing_returns = None
                    try:
                        diminishing_returns = self._check_diminishing_returns(
                            phase_telemetry, evidence_metrics
                        )
                    except AttributeError as e:
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(
                                f"[WARNING] _check_diminishing_returns not available: {e}"
                            )
                        diminishing_returns = None

                    # v4.5.3: Preserve @noticias token in next_query if original seed had it
                    if verdict == "refine" and next_query:
                        try:
                            original_seed = (
                                ph.get("seed_query", "") if isinstance(ph, dict) else ""
                            )
                            has_noticias_original = "@noticias" in original_seed.lower()
                            has_noticias_next = "@noticias" in next_query.lower()

                            if has_noticias_original and not has_noticias_next:
                                # Adicionar @noticias ao in√≠cio da next_query
                                next_query = f"@noticias {next_query}".strip()
                                if getattr(self.valves, "VERBOSE_DEBUG", False):
                                    print(
                                        f"[DEBUG][REFINE] Adicionado @noticias √† next_query (seed original tinha @noticias)"
                                    )
                                    print(
                                        f"[DEBUG][REFINE] Query atualizada: '{next_query}'"
                                    )
                        except Exception as e:
                            if getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(f"[WARNING] Erro ao preservar @noticias: {e}")

                    # v4.4.1: Validate next_query: REJECT if generic or missing entity
                    if verdict == "refine" and next_query:
                        try:
                            # Extrair entidades dispon√≠veis (must_terms + entities canonical)
                            available_entities = []
                            if isinstance(ph, dict):
                                if ph.get("must_terms"):
                                    available_entities.extend(
                                        [
                                            t
                                            for t in ph["must_terms"]
                                            if isinstance(t, str)
                                        ]
                                    )

                            # Verificar se next_query tem pelo menos 1 entidade
                            nq_low = next_query.strip().lower()
                            has_entity = any(
                                ent.lower() in nq_low
                                for ent in available_entities
                                if len(ent) > 2
                            )

                            # Verificar se √© gen√©rica (frases proibidas)
                            generic_bad = {
                                "buscar fontes",
                                "fontes mais espec√≠ficas",
                                "dados verific√°veis",
                                "buscar dados",
                                "fontes espec√≠ficas",
                                "mais espec√≠ficas",
                                "mais verific√°veis",
                                "aprofundar",
                                "refinar busca",
                            }
                            is_generic = (
                                any(bad in nq_low for bad in generic_bad)
                                or len(nq_low.split()) <= 2
                            )

                            # Detectar queries muito restritivas (muitos operadores)
                            operator_count = 0
                            restrictive_operators = [
                                "filetype:",
                                "site:",
                                "after:",
                                "before:",
                                "intitle:",
                                "inurl:",
                            ]
                            for op in restrictive_operators:
                                operator_count += (next_query or "").lower().count(op)

                            # Detectar OR complexo (mais de 3 termos em OR)
                            or_terms = (next_query or "").upper().split(" OR ")
                            has_complex_or = len(or_terms) > 3

                            # Detectar query muito LONGA (muitos termos)
                            query_words = len((next_query or "").split())
                            query_chars = len(next_query or "")
                            is_too_long = query_words > 12 or query_chars > 100

                            # Query muito restritiva se: >3 operadores OU OR complexo OU muito longa
                            is_too_restrictive = (
                                operator_count > 3 or has_complex_or or is_too_long
                            )

                            # v4.4.1: REJEITAR agressivamente queries sem entidade ou gen√©ricas
                            needs_rewrite = (
                                (not next_query)
                                or is_generic
                                or not has_entity
                                or is_too_restrictive
                            )

                            if needs_rewrite:
                                # Re-ask Judge to rewrite next_query properly
                                if is_too_restrictive:
                                    # Determinar o motivo espec√≠fico
                                    if is_too_long:
                                        reason = f"muito longa ({query_words} palavras, {query_chars} chars)"
                                    elif operator_count > 3:
                                        reason = f"muitos operadores ({operator_count})"
                                    else:
                                        reason = f"OR muito complexo ({len(or_terms)} termos)"

                                    reask = (
                                        f"A query anterior era {reason} e pode causar timeout ou 0 URLs. "
                                        f"Reescreva como query SIMPLES (3-7 palavras, MAX 1 operador), "
                                        f"focando em termos chave. Objetivo: '{ph.get('objetivo', '')}'. "
                                        f"Seed: '{ph.get('seed_query', '')}'. Retorne apenas a query."
                                    )
                                else:
                                    # Query sem entidade OU gen√©rica
                                    problem = (
                                        "SEM ENTIDADE" if not has_entity else "GEN√âRICA"
                                    )
                                    reask = (
                                        f"Query anterior {problem} ('{next_query}'). "
                                        f"Reescreva incluindo OBRIGATORIAMENTE ‚â•1 nome: {', '.join(available_entities[:5])}. "
                                        f"Formato: 3-7 palavras, espec√≠fica. "
                                        f"Objetivo: '{ph.get('objetivo', '')[:80]}'. "
                                        f"Retorne apenas a query."
                                    )
                                safe_reask = get_safe_llm_params(
                                    self.judge.model_name, {"temperature": 0.2}
                                )
                                re = await _safe_llm_run_with_retry(
                                    self.judge.llm,
                                    reask,
                                    safe_reask,
                                    timeout=self.judge.valves.LLM_TIMEOUT_DEFAULT,
                                    max_retries=1,
                                )
                                if re and re.get("replies"):
                                    candidate = (
                                        re["replies"][0].strip().strip('"').strip("'")
                                    )
                                    if 3 <= len(candidate.split()) <= 7:
                                        next_query = candidate
                                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                                            print(
                                                f"[DEBUG] Query reescrita: '{candidate}'"
                                            )
                        except Exception:
                            pass

                    # üîß FIX: Apply sector context enrichment for ambiguous entities
                    if verdict == "refine" and next_query:
                        try:
                            # Extrair contexto do contract
                            sector = ""
                            canonical = []
                            if self.contract:
                                sector = self.contract.get("setor_principal", "")
                                if self.contract.get("entities"):
                                    canonical = self.contract["entities"].get("canonical", [])
                            
                            # Enriquecer query se tiver entidade amb√≠gua
                            original_query = next_query
                            next_query = _add_sector_context_if_ambiguous(next_query, canonical, sector)
                            
                            # Log se houve mudan√ßa
                            if next_query != original_query and getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(f"[JUDGE] Query enriquecida: '{original_query}' ‚Üí '{next_query}'")
                        except Exception as e:
                            if getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(f"[WARNING] Erro no enrichment de query: {e}")

                    should_refine = (
                        verdict == "refine"
                        and next_query
                        and loops < self.valves.MAX_AGENT_LOOPS
                        and not diminishing_returns
                    )

                    # Check TOTAL phases (planejadas no contrato + j√° executadas)
                    total_planned_phases = (
                        len(self._last_contract.get("fases", []))
                        if self._last_contract
                        else 0
                    )
                    total_executed_phases = len(phase_results)
                    total_phases = max(total_planned_phases, total_executed_phases)

                    should_new_phase = (
                        verdict == "new_phase"
                        and proposed_phase
                        and total_phases < self.valves.MAX_PHASES
                    )

                    # v4.5.3: Se Judge pediu NEW_PHASE mas atingiu MAX_PHASES ‚Üí Converter para DONE
                    if (
                        verdict == "new_phase"
                        and total_phases >= self.valves.MAX_PHASES
                    ):
                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(
                                f"[DEBUG] NEW_PHASE bloqueado: total_phases={total_phases} >= MAX_PHASES={self.valves.MAX_PHASES}"
                            )
                        yield f"**[judge]** ‚ö†Ô∏è Limite de fases atingido ({total_phases}/{self.valves.MAX_PHASES}), convertendo new_phase ‚Üí done\n"
                        verdict = "done"
                        reasoning = f"[AUTO-CORRE√á√ÉO] Limite de fases atingido ({total_phases}/{self.valves.MAX_PHASES}). {reasoning}"
                        should_new_phase = False

                    # v4.4.1: Se Judge pediu REFINE mas atingiu limite de loops ‚Üí Converter para NEW_PHASE
                    if (
                        verdict == "refine"
                        and loops >= self.valves.MAX_AGENT_LOOPS
                        and not should_new_phase
                    ):
                        # Se h√° espa√ßo para nova fase, converter refine ‚Üí new_phase
                        if total_phases < self.valves.MAX_PHASES:
                            # Criar new_phase a partir do refine intent
                            if not proposed_phase and next_query:
                                proposed_phase = {
                                    "objective": f"Busca focada: {reasoning[:100]}",
                                    "seed_query": next_query,
                                    "name": f"Busca dirigida (fase {len(phase_results)+1})",
                                    "por_que": f"Atingido limite de loops ({loops}) mas lacunas essenciais persistem",
                                }
                                should_new_phase = True
                                verdict = "new_phase"
                                if getattr(self.valves, "VERBOSE_DEBUG", False):
                                    print(
                                        f"[DEBUG] Convertido REFINE ‚Üí NEW_PHASE (max loops atingido, lacunas essenciais)"
                                    )
                                yield f"**[judge]** ‚ö†Ô∏è Limite de loops atingido ({loops}), convertendo refine ‚Üí new_phase\n"

                    # Debug: log loop conditions
                    if getattr(self.valves, "VERBOSE_DEBUG", False):
                        print(
                            f"[DEBUG] Loop {loops}: verdict={verdict}, should_refine={should_refine}, should_new_phase={should_new_phase}"
                        )
                    print(
                        f"[DEBUG] Conditions: next_query={bool(next_query)}, loops={loops}/{self.valves.MAX_AGENT_LOOPS}, diminishing_returns={bool(diminishing_returns)}"
                    )
                    print(
                        f"[DEBUG] New phase: proposed_phase={bool(proposed_phase)}, phase_results={len(phase_results)}/{self.valves.MAX_PHASES}"
                    )

                    # Se diminishing returns, avaliar se vale continuar
                    # MAS: n√£o for√ßar DONE se Judge identificou lacunas essenciais
                    if diminishing_returns and verdict == "refine":
                        # Verificar se h√° lacunas essenciais mencionadas no reasoning
                        essential_gap_keywords = [
                            "lacuna essencial",
                            "falta",
                            "ausente",
                            "necess√°rio",
                            "exigem",
                        ]
                        has_essential_gaps = any(
                            kw in reasoning.lower() for kw in essential_gap_keywords
                        )

                        # Verificar se √∫ltimo loop teve 0 URLs (query ruim, n√£o esgotamento)
                        last_loop_had_urls = len(res.get("discovered_urls", [])) > 0

                        # S√≥ for√ßar DONE se:
                        # 1. N√£o h√° lacunas essenciais E
                        # 2. √öltimo loop teve URLs (n√£o foi query ruim)
                        if not has_essential_gaps and last_loop_had_urls:
                            verdict = "done"
                            reasoning = f"Diminishing returns detectado: {diminishing_returns['reason']}. {reasoning}"
                            should_refine = False
                        else:
                            # Diminishing returns mas h√° lacunas essenciais ou query ruim
                            # Permitir mais 1 tentativa com nova abordagem
                            if getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(
                                    f"[DEBUG] Diminishing returns detectado mas permitindo refine (lacunas essenciais ou query ruim)"
                                )
                            # Manter verdict = "refine" original do Judge

                    # Coletar telemetria integrada do loop (P0.2)
                    # v4.4.1: Adicionar self_assessment do Analyst
                    sa = analysis.get("self_assessment", {})

                    loop_telemetry = {
                        "loop": loops,
                        "start_time": loop_start_time,
                        "end_time": loop_end_time,
                        "duration": loop_end_time - loop_start_time,
                        "n_urls": len(res["discovered_urls"]),
                        "n_new_urls": len(res["new_urls"]),
                        "n_cached_urls": len(res["cached_urls"]),
                        "accumulated_chars": res["accumulated_context_size"],
                        "n_facts": len(facts),
                        "evidence_coverage": (
                            evidence_metrics.get("evidence_coverage", 0)
                            if evidence_metrics
                            else 0
                        ),
                        "unique_domains": (
                            evidence_metrics.get("unique_domains", 0)
                            if evidence_metrics
                            else 0
                        ),
                        "facts_with_multiple_sources": (
                            evidence_metrics.get("facts_with_multiple_sources", 0)
                            if evidence_metrics
                            else 0
                        ),
                        "high_confidence_facts": (
                            evidence_metrics.get("high_confidence_facts", 0)
                            if evidence_metrics
                            else 0
                        ),
                        "contradictions": (
                            evidence_metrics.get("contradictions", 0)
                            if evidence_metrics
                            else 0
                        ),
                        "lacunas_count": len(lacunas),
                        "new_facts_ratio": new_facts_ratio,
                        "new_domains_ratio": new_domains_ratio,
                        "verdict": verdict,
                        "reasoning": reasoning,
                        "diminishing_returns": diminishing_returns is not None,
                        # v4.4.1: Analyst self-assessment metrics
                        "coverage_score": sa.get("coverage_score", 0),
                        "analyst_confidence": sa.get("confidence", "baixa"),
                        "suggest_pivot": sa.get("suggest_pivot", False),
                        "failed_query": (len(res["discovered_urls"]) == 0),
                        "query": res.get("query", ""),
                    }
                    phase_telemetry["loops"].append(loop_telemetry)

                    if should_refine:
                        # Check for infinite loop (repeated query)
                        if next_query in seen_queries:
                            logger.warning(
                                f"Infinite loop detected: repeated query '{next_query}'",
                                extra={"phase": i, "correlation_id": correlation_id},
                            )
                            yield f"**[AVISO]** Query repetida detectada, for√ßando DONE\n"
                            break
                        seen_queries.add(next_query)

                        q = next_query

                        # üî• FIX #13: Ajustar phase_context para refinamento focado
                        # üõ°Ô∏è VALIDA√á√ÉO DEFENSIVA: Garantir que judgement existe
                        judgement = res.get("judgement")
                        if not judgement:
                            logger.error(
                                f"[CRITICAL] res n√£o cont√©m 'judgement' ap√≥s Judge decision (should_refine=True)",
                                extra={"phase": i, "correlation_id": correlation_id},
                            )
                            yield f"**[ERROR]** Estrutura inv√°lida: 'judgement' ausente ap√≥s decis√£o do Judge. Abortando refinamento.\n"
                            break

                        # Preparar contexto focado usando o Judge result
                        focused_context = orch.prepare_planner_context(
                            ph, judgement, loops
                        )

                        # Atualizar ph (phase_context) para pr√≥xima itera√ß√£o
                        ph = {
                            **ph,  # Manter campos n√£o sobrescritos (time_hint, source_bias, etc)
                            "objective": focused_context["phase_objective"],
                            "must_terms": focused_context["pipe_must_terms"],
                            "avoid_terms": focused_context["pipe_avoid_terms"],
                            "is_refinement": True,
                            "refinement_focus": focused_context.get(
                                "refinement_focus", ""
                            ),
                            "refinement_reason": focused_context.get(
                                "refinement_reason", ""
                            ),
                        }

                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                            print(f"[REFINE] Contexto ajustado para foco:")
                            print(
                                f"[REFINE] Objective focado: {focused_context['phase_objective'][:100]}..."
                            )
                            print(
                                f"[REFINE] Must_terms focados: {focused_context['pipe_must_terms']}"
                            )

                        # REMOVED: loops += 1 (duplica√ß√£o - j√° incrementado no in√≠cio do while loop)

                        # Log da decis√£o original do Judge
                        original_verdict = res["judgement"].get(
                            "original_verdict", verdict
                        )
                        modifications = res["judgement"].get("modifications", [])

                        yield f"**[judge]** üîÑ refine ‚Üí loop {loops}\n"
                        if reasoning:
                            yield f"**[judge]** üí≠ {reasoning}\n"

                        # Mostrar modifica√ß√µes se houver
                        if (
                            getattr(self.valves, "VERBOSE_DEBUG", False)
                            and modifications
                        ):
                            yield f"**[DEBUG]** Modifica√ß√µes Judge: {', '.join(modifications)}\n"
                            yield f"**[DEBUG]** Judge original: {original_verdict} ‚Üí final: {verdict}\n"

                        # Mostrar informa√ß√µes detalhadas do refine
                        refine_info = res["judgement"].get("refine", {})
                        if refine_info:
                            por_que = refine_info.get("por_que", [])
                            operadores = refine_info.get("operadores_sugeridos", [])
                            if por_que:
                                yield f"**[judge]** üéØ Por que refine: {', '.join(por_que[:2])}\n"
                            if operadores:
                                yield f"**[judge]** üîß Operadores sugeridos: {', '.join(operadores)}\n"
                            # Construir exclude_terms a partir de lacunas para a pr√≥xima discovery (logs)
                            try:
                                lacunas = analysis.get("lacunas", [])
                                exclude_terms = []
                                # Heur√≠stica simples: sempre excluir gen√©ricos
                                generic_terms = [
                                    "defini√ß√£o",
                                    "o que √©",
                                    "hist√≥ria",
                                    "funda√ß√£o",
                                    "vis√£o geral",
                                    "marketing",
                                ]
                                exclude_terms.extend(generic_terms)
                                # Logar exclude_terms
                                yield f"**[discovery]** ‚ùå exclude_terms aplicados: {', '.join(exclude_terms)}\n"
                                # Anexar ao contexto da fase para pr√≥xima itera√ß√£o
                                if isinstance(ph, dict):
                                    ph.setdefault("avoid_terms", [])
                                    ph["avoid_terms"] = list(
                                        {*ph["avoid_terms"], *exclude_terms}
                                    )
                            except Exception:
                                pass

                        if next_query:
                            yield f"**[judge]** üîç Nova query: {next_query}\n"
                        continue
                    elif should_new_phase:
                        # Adicionar resultado atual ao phase_results ANTES de criar nova fase
                        phase_results.append(res)
                        res_already_added = True  # Mark as added to prevent duplication

                        # Garantir que seed_query exista e seja v√°lida (1 frase rica, n√£o descri√ß√£o negativa)
                        try:
                            seed_q = proposed_phase.get("seed_query", "").strip()
                            if getattr(self.valves, "VERBOSE_DEBUG", False):
                                print(
                                    f"[NEW_PHASE] Validando seed_query: '{seed_q[:80]}...'"
                                )

                            # Validar se seed_query √© in√∫til (negativa/cortada/muito curta)
                            is_invalid = (
                                not seed_q
                                or len(seed_q) < 20  # Muito curta para ser frase rica
                                or seed_q.lower().startswith("aus√™ncia")
                                or seed_q.lower().startswith("falta")
                                or len(seed_q.split())
                                < 4  # Menos de 4 palavras = pobre
                            )

                            if is_invalid:
                                if getattr(self.valves, "VERBOSE_DEBUG", False):
                                    print(
                                        f"[NEW_PHASE] Seed_query inv√°lida detectada! Regenerando..."
                                    )

                                # Construir contexto rico sobre POR QUE a nova fase foi criada
                                why_new_phase = proposed_phase.get("por_que", "")
                                blind_spots = (res.get("judgement", {}) or {}).get(
                                    "blind_spots", []
                                )
                                lacunas = (res.get("analysis", {}) or {}).get(
                                    "lacunas", []
                                )

                                # P0: lacunas pode ser lista de dicts ou strings
                                lacunas_text = []
                                for lac in lacunas[:2]:
                                    if isinstance(lac, dict):
                                        lacunas_text.append(
                                            lac.get("descricao", str(lac))
                                        )
                                    else:
                                        lacunas_text.append(str(lac))

                                # Informa√ß√µes das fases anteriores para contraste
                                previous_phases_summary = ""
                                if self._last_contract and self._last_contract.get(
                                    "fases"
                                ):
                                    phase_names = [
                                        f.get("name", "N/A")
                                        for f in self._last_contract["fases"][:3]
                                    ]
                                    previous_phases_summary = f"\nFases anteriores cobriram: {', '.join(phase_names)}"

                                reask_prompt = (
                                    f"Gere UMA FRASE RICA (‚â§150 chars) de busca para uma NOVA FASE de pesquisa.\n\n"
                                    f"**CONTEXTO - POR QUE ESTA NOVA FASE FOI CRIADA:**\n"
                                    f"Objetivo da nova fase: '{proposed_phase.get('objective', '')}'\n"
                                    f"Raz√£o: {why_new_phase or 'Lacunas cr√≠ticas identificadas'}\n"
                                    f"Blind spots: {', '.join(blind_spots[:2]) if blind_spots else 'Nenhum'}\n"
                                    f"Lacunas principais: {', '.join(lacunas_text) if lacunas_text else 'Nenhuma'}{previous_phases_summary}\n\n"
                                    f"**TAREFA:**\n"
                                    f"Crie uma query de busca que:\n"
                                    f"1. DIFERENCIE desta nova fase das fases anteriores (√¢ngulo/escopo diferente)\n"
                                    f"2. RESPONDA especificamente √†s lacunas/blind spots mencionados\n"
                                    f"3. INCLUA contexto completo (aspecto + setor/entidades + geo + per√≠odo)\n"
                                    f"4. Seja POSITIVA (busque O QUE voc√™ quer encontrar, N√ÉO 'aus√™ncia de')\n"
                                    f"5. SEM operadores (site:, filetype:, OR, aspas)\n\n"
                                    f"**EXEMPLO:**\n"
                                    f"Se lacuna = 'falta m√©trica de ado√ß√£o de assessment remoto'\n"
                                    f"‚Üí Query: 'Taxas e percentuais de ado√ß√£o de assessment remoto e ferramentas digitais no mercado brasileiro de executive search 2023-2024'\n\n"
                                    f"Retorne APENAS a frase de busca (‚â§150 chars)."
                                )
                                safe_reask = get_safe_llm_params(
                                    self.judge.model_name, {"temperature": 0.2}
                                )
                                reask_out = await _safe_llm_run_with_retry(
                                    self.judge.llm,
                                    reask_prompt,
                                    safe_reask,
                                    timeout=self.judge.valves.LLM_TIMEOUT_DEFAULT,
                                    max_retries=1,
                                )
                                if reask_out and reask_out.get("replies"):
                                    candidate = (
                                        reask_out["replies"][0]
                                        .strip()
                                        .strip('"')
                                        .strip("'")
                                    )
                                    # Sanitizar operadores
                                    for op in [
                                        "site:",
                                        "filetype:",
                                        "after:",
                                        "before:",
                                        "AND",
                                        "OR",
                                        '"',
                                        "'",
                                    ]:
                                        candidate = candidate.replace(op, " ")
                                    # Aceitar se >= 20 chars e >= 4 palavras
                                    if (
                                        len(candidate) >= 20
                                        and len(candidate.split()) >= 4
                                    ):
                                        seed_q = candidate[:150]  # Limitar a 150 chars
                                        if getattr(self.valves, "VERBOSE_DEBUG", False):
                                            print(
                                                f"[NEW_PHASE] Seed_query regenerada: '{seed_q[:80]}...'"
                                            )
                                    else:
                                        logger.warning(
                                            f"[NEW_PHASE] Seed_query regenerada inv√°lida: '{candidate[:80]}...'"
                                        )
                        except Exception as e:
                            logger.error(
                                f"[NEW_PHASE] Erro ao validar/regenerar seed_query: {e}"
                            )
                            pass

                        # Adicionar nova fase proposta (formato novo)
                        new_phase = {
                            "objetivo": proposed_phase.get("objective", ""),
                            "query_sugerida": seed_q or proposed_phase.get("query", ""),
                            "name": proposed_phase.get("name", ""),
                            "seed_query": seed_q
                            or proposed_phase.get("seed_query", ""),
                            "seed_core": seed_q
                            or proposed_phase.get(
                                "seed_query", ""
                            ),  # ‚úÖ Adicionar seed_core para evitar fallback
                            "seed_core_source": "judge_new_phase",
                            "must_terms": proposed_phase.get("must_terms", []),
                            "avoid_terms": proposed_phase.get("avoid_terms", []),
                            "time_hint": proposed_phase.get("time_hint", {}),
                            "source_bias": proposed_phase.get("source_bias", []),
                            "evidence_goal": proposed_phase.get("evidence_goal", {}),
                            "lang_bias": proposed_phase.get("lang_bias", []),
                            "geo_bias": proposed_phase.get("geo_bias", []),
                            "accept_if_any_of": [
                                f"Info sobre {proposed_phase.get('objective', '')}"
                            ],
                        }
                        self._last_contract["fases"].append(new_phase)

                        yield f"**[judge]** üÜï new_phase ‚Üí {proposed_phase.get('name', 'Nova Fase')}\n"
                        if reasoning:
                            yield f"**[judge]** üí≠ {reasoning}\n"
                        if unexpected_findings:
                            yield f"**[judge]** üîç Descobertas inesperadas: {', '.join(unexpected_findings[:3])}\n"
                        yield f"**[judge]** üìã Nova fase: {proposed_phase.get('objective', '')}\n"
                        yield f"**[judge]** üå± Seed: {new_phase.get('seed_query', 'N/A')}\n"
                        break  # Sair do loop atual para processar nova fase
                    else:
                        yield f"**[judge]** ‚úÖ done\n"
                        if reasoning:
                            yield f"**[judge]** üí≠ {reasoning}\n"
                        if unexpected_findings:
                            yield f"**[judge]** üîç Descobertas inesperadas: {', '.join(unexpected_findings[:3])}\n"
                        break

                # Only append if not already added (prevents duplication when new_phase created)
                if res is not None and not res_already_added:
                    phase_results.append(res)

                # Finalizar telemetria da fase
                phase_end_time = time.time()
                phase_telemetry["end_time"] = phase_end_time
                phase_telemetry["duration"] = phase_end_time - phase_start_time
                phase_telemetry["total_loops"] = len(phase_telemetry["loops"])
                telemetry_data["phases"].append(phase_telemetry)

            # Finalizar telemetria geral
            execution_end_time = time.time()
            telemetry_data["end_time"] = execution_end_time
            telemetry_data["total_duration"] = (
                execution_end_time - telemetry_data["start_time"]
            )
            telemetry_data["total_phases"] = len(telemetry_data["phases"])

            # Emitir telemetria estruturada
            if self.valves.DEBUG_LOGGING:
                yield f"\n**[TELEMETRIA]** üìä Dados estruturados da execu√ß√£o:\n"
                yield f"```json\n{json.dumps(telemetry_data, indent=2, ensure_ascii=False)}\n```\n"

            yield f"\n**[S√çNTESE FINAL]**\n"
            async for chunk in self._synthesize_final(
                phase_results, orch, user_msg, body, __event_emitter__=__event_emitter__
            ):
                yield chunk

            # üîì UNLOCK contexto ap√≥s conclus√£o para permitir nova detec√ß√£o
            self._last_contract = None
            self._context_locked = False
            logger.info("[PIPE] Context unlocked after completion")
            return

        # Otherwise, build a contract using PlannerLLM
        if not self.valves.USE_PLANNER:
            raise ValueError("USE_PLANNER desabilitado")

        requested_phases = _extract_phase_count(user_msg)
        phases = (
            requested_phases if requested_phases else self.valves.DEFAULT_PHASE_COUNT
        )

        yield f"**[PLANNER]** At√© {phases} fases (conforme necess√°rio)...\n\n"

        # Check if there's a previous plan in history to allow refinement
        previous_plan_text = None
        try:
            messages = body.get("messages", [])
            for msg in reversed(messages):
                if msg.get("role") == "assistant":
                    content = msg.get("content", "")
                    # Look for rendered plan
                    if (
                        "üìã Plano" in content or "Fase 1/" in content
                    ) and "Objetivo:" in content:
                        previous_plan_text = content
                        break
        except Exception:
            pass

        planner = PlannerLLM(self.valves)
        out = await planner.run(
            user_prompt=user_msg,
            phases=phases,
            current_date=getattr(self, "_current_date", None),
            previous_plan=previous_plan_text,
            detected_context=self._detected_context,
        )
        self._last_contract = out["contract"]
        self._last_hash = out["contract_hash"]

        # üîó SINCRONIZAR contract Manual com contexto detectado
        # v4.4 FIX: CONTEXT DETECTION √© a fonte de verdade (foi feito para isso)
        if self._detected_context:
            detected_profile = self._detected_context.get("perfil", "company_profile")
            contract_profile = self._last_contract.get("intent_profile", "")

            # Se profiles divergem, CONTEXT DETECTION tem raz√£o (fonte de verdade)
            if contract_profile != detected_profile:
                logger.warning(
                    f"[SYNC] Profile mismatch: planner={contract_profile}, detected={detected_profile}. Using CONTEXT DETECTION (source of truth)."
                )
                # Contract deve seguir detected_context (fonte de verdade)
                self._last_contract["intent_profile"] = detected_profile
                # Recomputar hash ap√≥s sincroniza√ß√£o
                self._last_hash = _hash_contract(self._last_contract)

                # Se mismatch persistente, pode indicar problema no Context Detection
                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEBUG] Profile corrected: {contract_profile} ‚Üí {detected_profile}"
                    )
                    print(
                        f"[DEBUG] If this seems wrong, Context Detection LLM may need better prompt"
                    )

        # Emit detected intent/profile for validation before rendering contract
        try:
            detected_intent = (
                self._last_contract.get("intent")
                or self._last_contract.get("objetivo")
                or ""
            )
            detected_profile = (
                self._last_contract.get("intent_profile") or self._intent_profile or ""
            )
            if detected_intent:
                yield f"**[PLANNER] Intent detectado:** {detected_intent}\n"
            if detected_profile:
                yield f"**[PLANNER] Perfil:** {detected_profile}\n"
        except Exception:
            pass
        # üîí LOCK contexto para prevenir re-detec√ß√£o no pr√≥ximo "siga"
        self._context_locked = True
        logger.info("[PLANNER] Context locked for SIGA consistency")

        yield _render_contract(self._last_contract)

    # ===== SYNTHESIS HELPERS =====
    
    async def _synthesize_final(
        self,
        phase_results: List[Dict],
        orch: Orchestrator,
        user_msg: str = "",
        body: dict = None,
        __event_emitter__=None,
    ):
        """S√≠ntese final adaptativa com Context Reducer ou deduplica√ß√£o + LLM

        FLUXO:
        1. **Context Reducer** (se habilitado): Redu√ß√£o global com todas as queries
        2. **Fallback** (se CR desabilitado/falhar):
           - Deduplica√ß√£o MMR-lite (preserva ordem ou ordena por tamanho)
           - Truncamento ao MAX_CONTEXT_CHARS
           - Detec√ß√£o de contexto unificado (usa _detected_context ou detecta)
           - S√≠ntese adaptativa com UMA chamada LLM (prompt din√¢mico)

        ADAPTIVE SYNTHESIS:
        - Usa _detected_context para determinar setor, tipo, perfil
        - Gera prompt com instru√ß√µes espec√≠ficas para o contexto
        - Estrutura de relat√≥rio adaptada (se√ß√µes, estilo, foco)
        - Substituiu hardcoding de HPPC por template gen√©rico

        Args:
            phase_results: Lista de resultados de cada fase executada
            orch: Orchestrator com contexto acumulado e cache de URLs
            user_msg: Query original do usu√°rio (para detec√ß√£o de contexto)
            body: Body da requisi√ß√£o (para hist√≥rico de mensagens)
        """
        # Try Context Reducer first (inline to avoid async generator complexities)
        if self.valves.ENABLE_CONTEXT_REDUCER:
            try:
                yield "**[S√çNTESE]** Context Reducer global...\n"
                mode = self.valves.CONTEXT_MODE
                final = await orch.finalize_global_context(mode=mode)

                if final:
                    yield f"\n{final}\n\n"

                    total_urls = len(orch.scraped_cache)
                    total_phases = len(phase_results)
                    yield f"\n---\n**üìä Estat√≠sticas:**\n"
                    yield f"- Fases: {total_phases}\n"
                    yield f"- URLs √∫nicas scraped: {total_urls}\n"
                    yield f"- Contexto acumulado: {len(orch.filtered_accumulator)} chars\n"
                    return
            except Exception as e:
                yield f"**[ERRO]** Context Reducer: {e}\n"

        # Fallback: deduplicar (merge+dedupe+MMR-lite) e depois sintetizar com UMA √öNICA chamada ao LLM
        yield "**[S√çNTESE]** S√≠ntese completa e detalhada (sem Context Reducer)...\n"

        def _paragraphs(text: str) -> List[str]:
            """Extrai par√°grafos do texto, suportando m√∫ltiplos formatos de separa√ß√£o

            Detecta automaticamente o formato baseado na densidade de par√°grafos:
            - Densidade baixa (>1000 chars/par√°grafo m√©dio) ‚Üí markdown com \n √∫nico
            - Densidade alta (<500 chars/par√°grafo m√©dio) ‚Üí formato normal com \n\n
            """
            if not text:
                return []

            # Tentar primeiro com duplo newline (formato padr√£o do accumulator)
            parts = [p.strip() for p in text.split("\n\n") if p.strip()]

            # Calcular densidade de par√°grafos (chars por par√°grafo)
            avg_paragraph_size = len(text) / max(len(parts), 1)

            # Se densidade √© muito baixa (par√°grafos muito grandes), provavelmente √© markdown com \n √∫nico
            # Threshold: >1000 chars/par√°grafo m√©dio indica blocos gigantes, n√£o par√°grafos reais
            if avg_paragraph_size > 1000:
                # Markdown do scraper/Context Reducer usa \n √∫nico
                # Agrupar linhas n√£o vazias em blocos (par√°grafos)
                lines = text.split("\n")
                paragraphs = []
                current_block = []

                for line in lines:
                    line_stripped = line.strip()
                    if line_stripped:
                        current_block.append(line_stripped)
                    else:
                        # Linha vazia = fim de par√°grafo
                        if current_block:
                            paragraph = " ".join(current_block)
                            if len(paragraph) > 20:  # Filtrar par√°grafos muito curtos
                                paragraphs.append(paragraph)
                            current_block = []

                # Adicionar √∫ltimo bloco
                if current_block:
                    paragraph = " ".join(current_block)
                    if len(paragraph) > 20:
                        paragraphs.append(paragraph)

                if getattr(self.valves, "VERBOSE_DEBUG", False):
                    print(
                        f"[DEDUP] Densidade baixa detectada ({avg_paragraph_size:.0f} chars/par√°grafo)"
                    )
                    print(
                        f"[DEDUP] Usando extra√ß√£o linha-por-linha: {len(parts)} ‚Üí {len(paragraphs)} par√°grafos"
                    )

                # ‚úÖ v4.8.1: Se ainda houver par√°grafos gigantes, quebrar por senten√ßas/tamanho m√°ximo
                max_paragraph_chars = getattr(self.valves, "DEDUP_MAX_PARAGRAPH_CHARS", 1200)
                final_paragraphs: List[str] = []
                sentence_splitter = re.compile(r"(?<=[.!?])\s+")

                for paragraph in paragraphs:
                    if len(paragraph) <= max_paragraph_chars:
                        final_paragraphs.append(paragraph)
                        continue

                    sentences = [s.strip() for s in sentence_splitter.split(paragraph) if s.strip()]
                    chunk: List[str] = []
                    chunk_len = 0

                    for sentence in sentences:
                        sentence_len = len(sentence)
                        if chunk and chunk_len + sentence_len > max_paragraph_chars:
                            final_paragraphs.append(" ".join(chunk))
                            chunk = [sentence]
                            chunk_len = sentence_len
                        else:
                            chunk.append(sentence)
                            chunk_len += sentence_len + 1

                    if chunk:
                        final_paragraphs.append(" ".join(chunk))

                if getattr(self.valves, "VERBOSE_DEBUG", False) and len(final_paragraphs) != len(paragraphs):
                    print(
                        f"[DEDUP] Fragmenta√ß√£o adicional aplicada: {len(paragraphs)} ‚Üí {len(final_paragraphs)} par√°grafos"
                    )

                return [p for p in final_paragraphs if len(p) > 20]

            # Densidade normal: usar split padr√£o
            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[DEDUP] Densidade normal ({avg_paragraph_size:.0f} chars/par√°grafo)"
                )
                print(f"[DEDUP] Usando split por \\n\\n: {len(parts)} par√°grafos")

            return [p for p in parts if len(p) > 20]

        # Note: _shingles, _jaccard, _mmr_select are now global functions (defined at module level)

        # Build context (with optional deduplication and size limit)
        raw_context = orch.filtered_accumulator
        yield f"**[S√çNTESE]** Contexto bruto: {len(raw_context)} chars\n"

        if self.valves.ENABLE_DEDUPLICATION:
            raw_paragraphs = _paragraphs(raw_context)

            # v4.4: Usar Deduplicator centralizado (mesmo do Orchestrator)
            # S√≠ntese: SEM shuffle (fases n√£o s√£o cronol√≥gicas, ordem √© estrutural)
            deduplicator = Deduplicator(self.valves)
            
            # Usar estrat√©gia espec√≠fica da Synthesis
            algorithm = getattr(self.valves, "SYNTHESIS_DEDUP_ALGORITHM", "mmr")
            model_name = getattr(self.valves, "SYNTHESIS_DEDUP_MODEL", "sentence-transformers/paraphrase-MiniLM-L3-v2")
            threshold = getattr(self.valves, "DEDUP_SIMILARITY_THRESHOLD", 0.85)
            print(f"[S√çNTESE DEDUP] üß† Algoritmo: {algorithm.upper()}")
            print(f"[S√çNTESE DEDUP] üìè Threshold: {threshold}")
            print(f"[S√çNTESE DEDUP] üìä Input: {len(raw_paragraphs)} par√°grafos ‚Üí Target: {self.valves.MAX_DEDUP_PARAGRAPHS}")
            print(f"[S√çNTESE DEDUP] üîç Valves: ENABLE_DEDUPLICATION={self.valves.ENABLE_DEDUPLICATION}")
            print(f"[S√çNTESE DEDUP] üîç MAX_DEDUP_PARAGRAPHS: {self.valves.MAX_DEDUP_PARAGRAPHS}")
            print(f"[S√çNTESE DEDUP] üîç Type: {type(self.valves.MAX_DEDUP_PARAGRAPHS)}")
            
            # Extrair must_terms do contexto para context-aware dedup
            extracted_must_terms = []
            if hasattr(self, 'contract') and self.contract:
                # Tentar extrair must_terms do contract
                entities = self.contract.get("entities", {}).get("canonical", [])
                extracted_must_terms = entities[:5]  # Limitar a 5 termos mais relevantes
            
            dedupe_result = deduplicator.dedupe(
                chunks=raw_paragraphs,
                max_chunks=self.valves.MAX_DEDUP_PARAGRAPHS,
                algorithm=algorithm,
                threshold=threshold,
                preserve_order=self.valves.PRESERVE_PARAGRAPH_ORDER,  # Respeita valve
                preserve_recent_pct=0.0,  # S√≠ntese n√£o preserva recent (processa tudo igual)
                shuffle_older=False,  # SEM shuffle (ordem estrutural, n√£o cronol√≥gica)
                reference_first=False,  # SEM refer√™ncia (processa tudo igual)
                # NOVO: Context-aware parameters
                must_terms=extracted_must_terms,
                enable_context_aware=self.valves.ENABLE_CONTEXT_AWARE_DEDUP,
            )

            deduped_paragraphs = dedupe_result["chunks"]
            deduped_context = "\n\n".join(deduped_paragraphs)

            order_mode = (
                "ordem preservada"
                if self.valves.PRESERVE_PARAGRAPH_ORDER
                else "ordenado por tamanho"
            )
            yield f"**[S√çNTESE]** Deduplica√ß√£o ativa ({order_mode}, {dedupe_result['algorithm_used']}): {dedupe_result['original_count']} ‚Üí {dedupe_result['deduped_count']} par√°grafos ({dedupe_result['reduction_pct']:.1f}% redu√ß√£o)\n"
            yield f"**[S√çNTESE]** Tokens economizados: ~{dedupe_result['tokens_saved']}\n"
        else:
            deduped_context = raw_context
            yield f"**[S√çNTESE]** Deduplica√ß√£o desabilitada: usando todo o contexto\n"

        # Aplicar limite de tamanho
        max_chars = self.valves.MAX_CONTEXT_CHARS
        if len(deduped_context) > max_chars:
            # Truncar mantendo par√°grafos completos
            truncated = deduped_context[:max_chars]
            last_paragraph = truncated.rfind("\n\n")
            if last_paragraph > max_chars * 0.8:  # Se n√£o perder muito
                deduped_context = truncated[:last_paragraph]
            else:
                deduped_context = truncated
            yield f"**[S√çNTESE]** Contexto truncado: {len(deduped_context)} chars (limite: {max_chars})\n"
        else:
            yield f"**[S√çNTESE]** Contexto dentro do limite: {len(deduped_context)} chars\n"
        try:
            # Log do contexto que ser√° usado
            if self.valves.DEBUG_LOGGING:
                yield f"**[DEBUG]** Contexto para s√≠ntese: {len(deduped_context)} chars\n"
                yield f"**[DEBUG]** Primeiros 200 chars: {deduped_context[:200]}...\n"

            # Coletar estat√≠sticas para incluir no prompt
            total_urls = len(orch.scraped_cache)
            total_phases = len(phase_results)
            domains = set()
            for url in orch.scraped_cache:
                try:
                    domain = url.split("/")[2]
                    domains.add(domain)
                except:
                    pass

            # Compactar HINTS dos Analistas (por fase)
            def _txt(x):
                if isinstance(x, dict):
                    return (
                        x.get("texto")
                        or x.get("text")
                        or x.get("claim")
                        or x.get("descricao")
                        or str(x)
                    )
                return str(x)

            hints_lines = []
            for idx, ph in enumerate(phase_results, 1):
                analysis = ph.get("analysis", {}) or {}
                summary = (analysis.get("summary") or "").strip()
                facts = analysis.get("facts", []) or []
                lacunas = analysis.get("lacunas", []) or []
                judgement = ph.get("judgement", {}) or {}
                verdict = judgement.get("verdict") or ph.get("verdict")
                reasoning = judgement.get("reasoning") or ph.get("reasoning")

                hints_lines.append(f"[FASE {idx}] {ph.get('query','')}")
                if summary:
                    hints_lines.append(f"- Resumo: {summary}")
                if facts:
                    # pegar at√© 3
                    for f in facts[:3]:
                        hints_lines.append(f"- Fato: {_txt(f)}")
                if lacunas:
                    for l in lacunas[:3]:
                        hints_lines.append(f"- Lacuna: {_txt(l)}")
                if verdict:
                    hints_lines.append(f"- Veredito: {verdict}")
                if reasoning:
                    hints_lines.append(f"- Justificativa: {reasoning}")
                hints_lines.append("")
            analyst_hints = "\n".join(hints_lines)[
                :4000
            ]  # limitar tamanho para seguran√ßa

            # USAR CONTEXTO CENTRALIZADO j√° detectado no in√≠cio do pipe
            if not self._detected_context:
                self._detected_context = await self._detect_unified_context(
                    user_msg, body
                )
            research_context = self._detected_context

            # Extrair KEY_QUESTIONS e RESEARCH_OBJECTIVES do detected_context
            key_questions = research_context.get("key_questions", [])
            research_objectives = research_context.get("research_objectives", [])

            # Extrair informa√ß√µes do contract (entidades, objetivos de fase)
            contract_entities = []
            phase_objectives = []
            if self._last_contract:
                entities = self._last_contract.get("entities", {})
                canonical = entities.get("canonical", [])
                aliases = entities.get("aliases", [])
                contract_entities = list(
                    dict.fromkeys(canonical + aliases)
                )  # Remove duplicatas

                # Coletar objetivos de cada fase
                for idx, phase in enumerate(self._last_contract.get("fases", []), 1):
                    phase_name = phase.get("name", f"Fase {idx}")
                    phase_obj = phase.get("objetivo", "")
                    if phase_obj:
                        phase_objectives.append(f"{idx}. {phase_name}: {phase_obj}")

            # REFACTORED (v4.3.1 - P1D): Usar fun√ß√£o consolidada para construir se√ß√µes
            sections = _build_synthesis_sections(
                key_questions=key_questions,
                research_objectives=research_objectives,
                contract_entities=contract_entities,
                phase_objectives=phase_objectives,
            )

            key_questions_section = sections["key_questions"]
            research_objectives_section = sections["research_objectives"]
            entities_section = sections["entities"]
            phase_objectives_section = sections["phase_objectives"]

            # UMA √öNICA chamada ao LLM com prompt adaptativo baseado no contexto
            synthesis_prompt = f"""Voc√™ √© um analista executivo especializado em criar relat√≥rios executivos completos e narrativos.

**QUERY ORIGINAL DO USU√ÅRIO:**
{user_msg}

**PERFIL ADAPTATIVO:** {research_context['perfil_descricao']}
**OBJETIVO ADAPTATIVO:** Criar um relat√≥rio executivo profissional no estilo {research_context['estilo']}, rico em {research_context['foco_detalhes']}, baseado no contexto de pesquisa fornecido sobre {research_context['tema_principal']}.
{key_questions_section}{research_objectives_section}{entities_section}{phase_objectives_section}
‚ö†Ô∏è **INSTRU√á√ïES CR√çTICAS DE S√çNTESE:**
1. **RESPONDA √ÄS KEY QUESTIONS**: O relat√≥rio DEVE responder diretamente √†s perguntas decis√≥rias listadas acima. Estruture se√ß√µes para responder cada uma.
2. **ALCANCE OS RESEARCH OBJECTIVES**: Cada objetivo de pesquisa final deve ser explicitamente endere√ßado com an√°lise e evid√™ncias.
3. **CUBRA TODAS AS ENTIDADES**: O relat√≥rio DEVE analisar TODAS as entidades espec√≠ficas listadas acima. Crie se√ß√µes/subse√ß√µes dedicadas para cada uma.
4. **ENTREGUE OS OBJETIVOS DAS FASES**: Cada objetivo de fase deve ser claramente respondido com evid√™ncias do contexto.
3. **AN√ÅLISE PROFUNDA**: Examine TODO o contexto fornecido (evid√™ncias, URLs, trechos) - identifique {research_context['foco_detalhes']}
4. **INTEGRA√á√ÉO ESTRAT√âGICA**: Integre os HINTS dos analistas (resumos, fatos e lacunas por fase) com o contexto principal
5. **NARRATIVA ESPEC√çFICA**: Crie um relat√≥rio {research_context['estilo']} sobre {research_context['tema_principal']}
6. **DADOS ESPEC√çFICOS**: Inclua n√∫meros, m√©tricas, projetos, tecnologias e indicadores relevantes para {research_context['tema_principal']}
7. **COBERTURA COMPLETA**: Para cada entidade espec√≠fica (empresa, produto, pessoa), detalhe:
   - Hist√≥rico e presen√ßa no mercado
   - Escopo de servi√ßos/produtos
   - Posicionamento e diferenciais
   - M√©tricas e indicadores (quando dispon√≠veis)
   - Cita√ß√µes e fontes (URLs)
8. **ESTRUTURA ESPECIALIZADA**: Use as se√ß√µes sugeridas: {', '.join(research_context.get('secoes_sugeridas', ['Resumo', 'An√°lise', 'Conclus√µes']))}
9. **FONTES ESPEC√çFICAS**: Cite fontes oficiais e t√©cnicas quando relevante (URLs entre par√™nteses)
10. **S√çNTESE ESTRAT√âGICA**: Integre informa√ß√µes sem repeti√ß√£o, focando em aspectos √∫nicos e {research_context['foco_detalhes']}
11. **FORMATO PROFISSIONAL**: Use Markdown narrativo com se√ß√µes bem estruturadas no estilo {research_context['estilo']}
12. **PRIORIZE DETALHAMENTO SOBRE BREVIDADE**: Prefira um relat√≥rio rico e detalhado a um gen√©rico e curto; use TODO o contexto dispon√≠vel

**ESTAT√çSTICAS DA PESQUISA:**
- Fases executadas: {total_phases}
- URLs analisadas: {total_urls}
- Dom√≠nios consultados: {len(domains)}
- Contexto processado: {len(deduped_context):,} caracteres

**HINTS DOS ANALISTAS (por fase):**
{analyst_hints}

**ESTRUTURA ADAPTATIVA BASEADA NO CONTEXTO DETECTADO:**

# üìã Relat√≥rio Executivo - {research_context['tema_principal']}

## üéØ Resumo Executivo
[Par√°grafo {research_context['estilo']} com vis√£o {research_context['foco_detalhes']} sobre {research_context['tema_principal']}]

## üîç Principais Descobertas
[An√°lise {research_context['estilo']} integrando as descobertas mais importantes sobre {research_context['tema_principal']}]

**DIRETRIZES ADAPTATIVAS PARA {research_context['tema_principal'].upper()}:**
- **FOCO**: {research_context['foco_detalhes']}
- **ESTILO**: {research_context['estilo']}
- **SE√á√ïES SUGERIDAS**: {', '.join(research_context.get('secoes_sugeridas', ['Resumo', 'An√°lise', 'Conclus√µes']))}
- **TOM**: Use linguagem apropriada para {research_context['perfil_descricao']}
- **N√çVEL DE DETALHE**: Seja espec√≠fico sobre dados, m√©tricas e evid√™ncias relevantes para {research_context['tema_principal']}
- **CONTEXTO**: Relacione descobertas com tend√™ncias e aspectos espec√≠ficos do setor

Agora, crie o relat√≥rio executivo completo baseado no contexto abaixo:

---

**CONTEXTO DE PESQUISA:**

{deduped_context}

---

**RELAT√ìRIO EXECUTIVO:**"""

            # P1: Exemplo de BOA vs M√Å s√≠ntese para calibrar sa√≠da do LLM
            synthesis_prompt += """

üí° EXEMPLO DE BOA vs M√Å S√çNTESE:

Query: "Volume de mercado de headhunting Brasil"
Key_question: "Qual volume anual?"

‚ùå M√Å s√≠ntese (gen√©rica):
"O mercado de headhunting no Brasil √© significativo e tem crescido nos √∫ltimos anos."

‚úÖ BOA s√≠ntese (espec√≠fica):
"O mercado brasileiro de executive search movimentou R$450-500M em 2023 (fonte: Relat√≥rio ABRH),
crescimento de 12% vs 2022. Spencer Stuart lidera com ~25% de participa√ß√£o (fonte: Valor Econ√¥mico),
seguida por Heidrick (18%) e Flow Executive (15%)."

‚Üí Diferen√ßa: n√∫meros concretos, fontes, nomes de players
"""

            # ‚úÖ GATE PREVENTIVO: Avisar sobre prompt gigante
            prompt_chars = len(synthesis_prompt)
            prompt_tokens_est = prompt_chars // 4  # Estimativa conservadora

            if prompt_tokens_est > 40000:  # ~160k chars
                yield f"**[‚ö†Ô∏è AVISO]** Prompt muito grande ({prompt_tokens_est:,} tokens estimados)!\n"
                yield f"**[SUGEST√ÉO]** S√≠ntese pode levar 5-10 minutos. Aguarde...\n"
                yield f"**[CONFIG]** Se houver timeout, aumente nas Valves:\n"
                yield f"   - LLM_TIMEOUT_SYNTHESIS (atual: {self.valves.LLM_TIMEOUT_SYNTHESIS}s)\n"
                yield f"   - HTTPX_READ_TIMEOUT (atual: {self.valves.HTTPX_READ_TIMEOUT}s)\n"
                yield f"**[ALTERNATIVA]** Reduza MAX_DEDUP_PARAGRAPHS (atual: {self.valves.MAX_DEDUP_PARAGRAPHS})\n"
                yield f"\n"

            if self.valves.DEBUG_LOGGING or self.valves.VERBOSE_DEBUG:
                yield f"**[DEBUG]** Prompt de s√≠ntese: {prompt_chars:,} chars (~{prompt_tokens_est:,} tokens estimados)\n"
                if prompt_tokens_est > 12000:
                    yield f"**[AVISO]** Prompt grande (>{prompt_tokens_est:,} tokens) pode causar truncamento ou resposta gen√©rica!\n"

            # Fazer UMA √∫nica chamada ao LLM para gerar o relat√≥rio completo
            # Usar modelo espec√≠fico para s√≠ntese se configurado (pode ser mais capaz)
            synthesis_model = self.valves.LLM_MODEL_SYNTHESIS or self.valves.LLM_MODEL
            llm = _get_llm(self.valves, model_name=synthesis_model)

            # Par√¢metros seguros para GPT-5/O1
            base_synthesis_params = {"temperature": 0.3}
            generation_kwargs = get_safe_llm_params(
                synthesis_model, base_synthesis_params
            )
            timeout_synthesis = self.valves.LLM_TIMEOUT_SYNTHESIS
            
            # üîß AUTO-ADJUST timeout for large context
            context_size = len(deduped_context)
            if context_size > 100000:  # >100k chars
                # Scale timeout based on context size
                min_timeout = 600  # 10 minutes minimum for large context
                max_timeout = 1800  # 30 minutes maximum
                # Linear scaling: 100k chars = 10min, 200k chars = 20min, 300k+ chars = 30min
                scaled_timeout = min(max_timeout, min_timeout + int((context_size - 100000) / 10000 * 600))
                timeout_synthesis = max(timeout_synthesis, scaled_timeout)
                if self.valves.DEBUG_LOGGING:
                    yield f"**[DEBUG]** Auto-ajuste timeout: {self.valves.LLM_TIMEOUT_SYNTHESIS}s ‚Üí {timeout_synthesis}s (contexto: {context_size:,} chars)\n"

            # Log do modelo sendo usado
            if self.valves.DEBUG_LOGGING:
                yield f"**[DEBUG]** Modelo de s√≠ntese: {synthesis_model} (params: {generation_kwargs})\n"

            out = await _safe_llm_run_with_retry(
                llm,
                synthesis_prompt,
                generation_kwargs,
                timeout=timeout_synthesis,
                max_retries=1,
            )
            if not out or not out.get("replies"):
                raise ValueError("LLM vazio na s√≠ntese final")
            report = (out["replies"][0] or "").strip()
            if not report:
                raise ValueError("Relat√≥rio vazio na s√≠ntese final")
            yield f"\n{report}\n"

            # ‚úÖ AUTO-EXPORT PDF (AP√ìS GERAR RELAT√ìRIO)
            if getattr(self.valves, "AUTO_EXPORT_PDF", False) and self._export_pdf_tool:
                try:
                    yield f"\n**[EXPORT]** üìÑ Gerando PDF...\n"

                    # Preparar conte√∫do
                    export_full = getattr(self.valves, "EXPORT_FULL_CONTEXT", True)
                    if export_full:
                        pdf_content = f"""# Pesquisa Completa - {self._detected_context.get('tema_principal', 'N/A')}

## Metadata
- Data: {getattr(self, '_current_date', 'N/A')}
- Fases: {len(phase_results)}
- URLs: {len(orch.scraped_cache)}
- Dom√≠nios: {len(set(url.split('/')[2] for url in orch.scraped_cache if '/' in url))}
- Tamanho: {len(orch.filtered_accumulator):,} chars

---

## üìã Relat√≥rio Final

{report}

---

## üìä Contexto Bruto (Todas as Fases)

{orch.filtered_accumulator}

---

## üîó URLs Scraped

{chr(10).join([f"- {url}" for url in sorted(orch.scraped_cache.keys())])}
"""
                    else:
                        pdf_content = f"""# Relat√≥rio Executivo - {self._detected_context.get('tema_principal', 'Pesquisa')}

## Metadata
- Data: {getattr(self, '_current_date', 'N/A')}
- Fases: {len(phase_results)}
- URLs: {len(orch.scraped_cache)}
- Contexto: {len(orch.filtered_accumulator):,} chars

---

{report}
"""

                    # Chamar tool via wrapper seguro
                    from datetime import datetime

                    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                    result_dict = await self._safe_export_pdf(
                        content=pdf_content,
                        filename=f"pesquisa_{ts}.pdf",
                        title=f"Relat√≥rio - {self._detected_context.get('tema_principal', 'Pesquisa')}",
                        __event_emitter__=__event_emitter__,  # ‚úÖ Passar event emitter para gerar data URI
                    )

                    if result_dict.get("success"):
                        pdf_url = result_dict.get("url")
                        pdf_data_uri = result_dict.get("data_uri")
                        pdf_filename = result_dict.get("filename", "relatorio.pdf")
                        pdf_size_bytes = result_dict.get("size_bytes", 0)
                        pdf_size_mb = (
                            pdf_size_bytes / (1024 * 1024) if pdf_size_bytes else 0
                        )

                        yield f"\n**[EXPORT]** ‚úÖ PDF gerado com sucesso!\n"

                        # ‚úÖ Exibir ambos os links: data URI (base64) e URL HTTP (se dispon√≠veis)
                        if pdf_data_uri:
                            # Data URI (base64) - funciona sempre, sem depender de servidor
                            yield f"üìÑ [**Baixar {pdf_filename}** ({pdf_size_mb:.1f} MB) - Link Direto]({pdf_data_uri})\n"

                        if pdf_url:
                            # URL HTTP - requer servidor configurado
                            yield f"üîó [**Baixar via HTTP** - {pdf_filename}]({pdf_url})\n"

                        if not pdf_data_uri and not pdf_url:
                            # Sem links p√∫blicos (diret√≥rio n√£o servido)
                            pdf_path = result_dict.get("path", "N/A")
                            yield f"**[EXPORT]** ‚úÖ PDF salvo localmente: `{pdf_path}` ({pdf_size_mb:.1f} MB)\n"
                            yield f"**[AVISO]** ‚ö†Ô∏è PDF n√£o est√° acess√≠vel via HTTP (diret√≥rio n√£o servido)\n"
                            yield f"**[DICA]** Configure `pdf_output_dir` nas valves para `/app/backend/data/uploads`\n"
                        else:
                            yield f"\nüí° **Dica**: Clique no link acima para baixar o relat√≥rio completo\n"

                        # Se houver warning (fallback para texto plano)
                        if result_dict.get("warning"):
                            yield f"**[EXPORT]** ‚ö†Ô∏è {result_dict['warning']}\n"
                    else:
                        error_msg = result_dict.get("error", "Erro desconhecido")
                        yield f"**[EXPORT]** ‚ùå Falha ao gerar PDF: {error_msg}\n"

                except Exception as e:
                    # N√£o falhar a s√≠ntese por erro de exporta√ß√£o
                    yield f"**[EXPORT]** ‚ö†Ô∏è Erro ao exportar PDF: {e}\n"
            elif getattr(self.valves, "AUTO_EXPORT_PDF", False):
                # Tool n√£o dispon√≠vel - apenas avisar
                yield f"\n**[INFO]** üí° Export PDF Tool n√£o est√° dispon√≠vel. Para habilitar:\n"
                yield f"   1. Instale a tool em Workspace ‚Üí Tools\n"
                yield f"   2. Habilite para este modelo em Workspace ‚Üí Models\n"

            # Estat√≠sticas avan√ßadas
            total_urls = len(orch.scraped_cache)
            total_phases = len(phase_results)
            domains = set()
            for url in orch.scraped_cache:
                try:
                    domain = url.split("/")[2]
                    domains.add(domain)
                except:
                    pass

            yield f"\n---\n**üìä Estat√≠sticas da Pesquisa:** Fases={total_phases}, URLs √∫nicas={total_urls}, Dom√≠nios={len(domains)}, Contexto={len(orch.filtered_accumulator):,} chars\n"

        except Exception as e:
            error_msg = str(e)
            is_timeout = (
                "timeout" in error_msg.lower() or "exceeded" in error_msg.lower()
            )

            if is_timeout:
                # üîß FIX: Calcular timeout HTTP real usado (n√£o mostrar PLANNER_REQUEST_TIMEOUT que √© irrelevante)
                effective_http_timeout = max(60, int(timeout_synthesis - 30))

                yield f"**[ERRO]** S√≠ntese completa falhou: {e}\n"
                yield f"**[DICA]** Contexto muito grande ({len(deduped_context):,} chars). Sugest√µes:\n"
                # Get max timeout value safely (Pydantic v1/v2 compatibility)
                try:
                    max_timeout = getattr(self.valves.__fields__['LLM_TIMEOUT_SYNTHESIS'], 'field_info', {}).get('extra', {}).get('le', 1800)
                except (AttributeError, KeyError):
                    max_timeout = 1800  # fallback
                yield f"  - Aumente LLM_TIMEOUT_SYNTHESIS nas valves (atual: {timeout_synthesis}s, m√°x: {max_timeout}s)\n"
                yield f"  - üîç **Diagn√≥stico atual:**\n"
                yield f"    ‚Ä¢ timeout_synthesis (asyncio): {timeout_synthesis}s\n"
                yield f"    ‚Ä¢ request_timeout (HTTP): {effective_http_timeout}s (margem de 30s)\n"
                yield f"    ‚Ä¢ HTTPX_READ_TIMEOUT (base): {self.valves.HTTPX_READ_TIMEOUT}s (n√£o usado na s√≠ntese)\n"
                yield f"  - ‚ö†Ô∏è **Se a resposta apareceu na OpenAI mas n√£o aqui:** pode ser timeout de conex√£o HTTP. Verifique logs para '[LLM_CALL]'.\n"
                yield f"  - Ou reduza MAX_DEDUP_PARAGRAPHS (atual: {self.valves.MAX_DEDUP_PARAGRAPHS}) para diminuir contexto\n"
                yield f"  - Ou aumente DEDUP_SIMILARITY_THRESHOLD (atual: {self.valves.DEDUP_SIMILARITY_THRESHOLD}) para deduplicar mais agressivamente\n"
            else:
                yield f"**[ERRO]** S√≠ntese completa falhou: {e}\n"

            yield f"**[FALLBACK]** Contexto completo ({len(orch.filtered_accumulator):,} chars) dispon√≠vel para an√°lise manual.\n"

    async def _detect_unified_context(
        self, user_query: str, body: dict
    ) -> Dict[str, Any]:
        """DETEC√á√ÉO UNIFICADA DE CONTEXTO - Apenas LLM (heur√≠stica removida)

        Analisa a consulta do usu√°rio e hist√≥rico de mensagens para determinar:
        - Setor/ind√∫stria (10+ setores: sa√∫de, tech, finan√ßas, direito, etc.)
        - Tipo de pesquisa (acad√™mica, regulat√≥ria, t√©cnica, estrat√©gica, not√≠cias)
        - Perfil apropriado (company_profile, regulation_review, technical_spec, etc.)
        - Metadados adaptativos (estilo, foco, se√ß√µes sugeridas)

        ‚úÖ SIMPLIFICADO: Usa apenas LLM (heur√≠stica removida - era marginal)

        Returns:
            Dict com: setor, tipo, perfil, perfil_descricao, estilo, foco_detalhes,
                     tema_principal, secoes_sugeridas, detec√ß√£o_confianca, fonte_deteccao
        """

        # Preparar contexto do hist√≥rico
        text_sample = user_query.lower()
        messages = body.get("messages", [])
        if messages:
            for msg in messages[:-1]:  # Excluir √∫ltima mensagem (query atual)
                content = msg.get("content", "")
                if content:
                    text_sample += " " + content.lower()

        # ===== LLM √öNICO (heur√≠stica removida) =====
        contexto_enriquecido = None
        try:
            from datetime import datetime

            current_date = datetime.now().strftime("%Y-%m-%d")

            # Prompt JSON-only sem CoT exposto (anti-recusa/anti-disclaimer)
            detect_prompt = f"""Voc√™ √© um consultor de estrat√©gia s√™nior.

Pense passo a passo INTERNAMENTE, mas N√ÉO exponha o racioc√≠nio.
Retorne SOMENTE JSON v√°lido no schema abaixo.

‚ö†Ô∏è IMPORTANTE:
- N√ÉO use markdown ou c√≥digo fence (```json)
- N√ÉO escreva nada fora do JSON
- N√ÉO inclua pedidos de desculpa, men√ß√µes a pol√≠ticas ou resumos narrativos
- Apenas JSON v√°lido conforme schema

CONSULTA: {user_query}

CONTEXTO DO HIST√ìRICO:
{text_sample[:1000]}

Data atual: {current_date}

TAREFA:
Analise a consulta e produza:
- setor_principal (espec√≠fico, n√£o "geral")
- tipo_pesquisa (acad√™mica, mercado, t√©cnica, regulat√≥ria, not√≠cias)
- perfil_sugerido: CRITICAL - escolha baseado no OBJETIVO PRINCIPAL:
  * company_profile: an√°lise de MERCADO/EMPRESAS/COMPETI√á√ÉO/NEG√ìCIOS (ex: "estudo de mercado", "an√°lise competitiva", "players", "reputa√ß√£o")
  * regulation_review: an√°lise REGULAT√ìRIA/LEGAL/COMPLIANCE (ex: "marco legal", "normas", "regulamenta√ß√£o")
  * technical_spec: an√°lise T√âCNICA/OPERACIONAL/IMPLEMENTA√á√ÉO (ex: "arquitetura", "stack t√©cnico", "processos operacionais")
  * literature_review: revis√£o ACAD√äMICA/CIENT√çFICA (ex: "estado da arte", "revis√£o sistem√°tica", "papers")
  * history_review: an√°lise HIST√ìRICA/TEMPORAL (ex: "evolu√ß√£o hist√≥rica", "contexto cultural")
  
  ‚ö†Ô∏è ATEN√á√ÉO CR√çTICA - EXEMPLOS DE CLASSIFICA√á√ÉO:
  
  ‚úÖ company_profile:
     - "Estudo de mercado de X"
     - "An√°lise competitiva dos players A, B, C"
     - "Reputa√ß√£o e posicionamento de empresas"
     - "Volume de mercado e market share"
     - "Perfis de boutiques vs internacionais"
  
  ‚úÖ technical_spec:
     - "Arquitetura t√©cnica do sistema X"
     - "Stack tecnol√≥gico e implementa√ß√£o"
     - "Especifica√ß√µes de API e protocolos"
  
  ‚úÖ literature_review:
     - "Estado da arte de X"
     - "Panorama atual de Y"
     - "Evolu√ß√£o tecnol√≥gica de Z"
     - "Avan√ßos recentes em W"
     - "Situa√ß√£o atual do mercado de V"
  
  ‚ö†Ô∏è N√ÉO CONFUNDA: "Estudo sobre empresas" = company_profile (N√ÉO technical_spec!)
  ‚ö†Ô∏è "Estado de AI Agentica" = literature_review (estado da arte, N√ÉO mercado!)
  
  üéØ EXEMPLO ESPEC√çFICO - Headhunting/Executive Search:
  Query: "Estudo sobre mercado de headhunting no Brasil, players Spencer e Heidrick"
  ‚Üí setor_principal: "rh_talento_headhunting" (ou "servicos_profissionais")
  ‚Üí tipo_pesquisa: "analise_mercado" (N√ÉO "academica" ou "tecnica")
  ‚Üí perfil_sugerido: "company_profile" (√â ESTUDO DE MERCADO/COMPETI√á√ÉO!)
  ‚Üí entities_mentioned: [{{"canonical": "Spencer Stuart", "aliases": ["Spencer"]}}, {{"canonical": "Heidrick & Struggles", "aliases": ["Heidrick"]}}]
  ‚ö†Ô∏è N√ÉO incluir "Brasil" em entities_mentioned (√© contexto geogr√°fico, n√£o entidade espec√≠fica)
  
- 5-10 key_questions (perguntas de DECIS√ÉO que precisam resposta, n√£o queries de busca)
- entities_mentioned (APENAS empresas/produtos/pessoas/marcas espec√≠ficas mencionadas EXPLICITAMENTE, incluir aliases)
  ‚ö†Ô∏è N√ÉO incluir termos geogr√°ficos (pa√≠ses, regi√µes, c√≥digos como "Brasil", "BR", "global", "mundial")
  ‚ö†Ô∏è N√ÉO incluir termos gen√©ricos ("mercado", "setor", "nacional", "internacional")
  ‚ö†Ô∏è FOCAR em entidades espec√≠ficas: nomes de empresas, produtos, pessoas, marcas
- research_objectives (objetivos finais: entender/analisar/comparar o qu√™?)

SCHEMA JSON:
{{
  "setor_principal": "setor espec√≠fico da pesquisa",
  "tipo_pesquisa": "tipo espec√≠fico da pesquisa",
  "perfil_sugerido": "perfil mais apropriado",
  "confianca_deteccao": "alta|m√©dia|baixa",
  "justificativa": "breve explica√ß√£o da classifica√ß√£o (‚â§60 palavras)",
  "key_questions": [
    "Pergunta decis√≥ria 1",
    "Pergunta decis√≥ria 2",
    "..."
  ],
  "entities_mentioned": [
    {{"canonical": "Spencer Stuart", "aliases": ["Spencer", "SS"]}},
    {{"canonical": "Heidrick & Struggles", "aliases": ["Heidrick", "H&S"]}},
    {{"canonical": "Flow Executive", "aliases": ["Flow", "Flow Exec"]}}
  ],
  "research_objectives": [
    "Objetivo 1 (entender/analisar/comparar o qu√™)",
    "Objetivo 2",
    "..."
  ]
}}

FORMATO DE RESPOSTA:
Apenas JSON v√°lido, sem qualquer texto adicional."""

            llm = _get_llm(self.valves, model_name=self.valves.LLM_MODEL)
            if llm:
                # Par√¢metros base (podem ser filtrados para GPT-5)
                base_params = {
                    "temperature": 0.2,
                    "response_format": {"type": "json_object"},
                }
                # Filtrar par√¢metros incompat√≠veis com GPT-5/O1
                llm_params = get_safe_llm_params(self.valves.LLM_MODEL, base_params)
                detect_result = await _safe_llm_run_with_retry(
                    llm, detect_prompt, llm_params, timeout=60, max_retries=1
                )
                if detect_result and detect_result.get("replies"):
                    # Usar parser resiliente para Context Detection
                    try:
                        detect_json = parse_llm_json_strict(detect_result["replies"][0])
                    except ContractValidationError:
                        # Fallback: usar parser legacy
                        detect_json = _extract_json_from_text(
                            detect_result["replies"][0]
                        )

                    if detect_json and detect_json.get("setor_principal"):
                        contexto_enriquecido = detect_json
                        logger.info(
                            f"[PIPE] Contexto detectado por LLM: {contexto_enriquecido}"
                        )
        except Exception as e:
            logger.warning(f"[PIPE] Erro na detec√ß√£o LLM: {e}")

        # S√çNTESE FINAL DO CONTEXTO
        if contexto_enriquecido:
            # LLM dispon√≠vel - usar EXCLUSIVAMENTE as classifica√ß√µes do LLM
            setor_final = contexto_enriquecido.get("setor_principal", "geral")
            tipo_final = contexto_enriquecido.get("tipo_pesquisa", "geral")
            perfil_final = contexto_enriquecido.get(
                "perfil_sugerido", "company_profile"
            )
            confianca = contexto_enriquecido.get("confianca_deteccao", "alta")
            fonte_deteccao = "LLM"

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[CONTEXT DETECTION] LLM: setor={setor_final}, tipo={tipo_final}, perfil={perfil_final}"
                )
        else:
            # LLM falhou - fallback simples (n√£o heur√≠stica complexa)
            setor_final = "geral"
            tipo_final = "geral"
            perfil_final = "company_profile"
            confianca = "baixa"
            fonte_deteccao = "fallback"

            if getattr(self.valves, "VERBOSE_DEBUG", False):
                print(
                    f"[CONTEXT DETECTION] LLM falhou, usando fallback simples: setor={setor_final}, tipo={tipo_final}, perfil={perfil_final}"
                )

        # GERAR METADADOS ADAPTATIVOS
        contexto_map = {
            "company_profile": {
                "descricao": "an√°lise estrat√©gica de empresas e mercado",
                "estilo": "estrat√©gico e de neg√≥cios",
                "foco": "an√°lise de mercado e oportunidades",
                "secoes": [
                    "Resumo Executivo",
                    "An√°lise de Mercado",
                    "Posicionamento Competitivo",
                    "Oportunidades Estrat√©gicas",
                ],
            },
            "regulation_review": {
                "descricao": "an√°lise regulat√≥ria e compliance",
                "estilo": "regulat√≥rio e jur√≠dico",
                "foco": "aspectos legais e regulat√≥rios",
                "secoes": [
                    "Marco Regulat√≥rio",
                    "An√°lise de Compliance",
                    "Riscos Jur√≠dicos",
                    "Recomenda√ß√µes",
                ],
            },
            "technical_spec": {
                "descricao": "especifica√ß√µes t√©cnicas e implementa√ß√£o",
                "estilo": "t√©cnico e operacional",
                "foco": "detalhes t√©cnicos e implementa√ß√£o",
                "secoes": [
                    "Especifica√ß√µes T√©cnicas",
                    "Arquitetura do Sistema",
                    "Processos Operacionais",
                    "Requisitos",
                ],
            },
            "literature_review": {
                "descricao": "revis√£o acad√™mica e cient√≠fica",
                "estilo": "acad√™mico e cient√≠fico",
                "foco": "dados cient√≠ficos e metodologia de pesquisa",
                "secoes": [
                    "Revis√£o da Literatura",
                    "Metodologia Cient√≠fica",
                    "An√°lise de Dados",
                    "Conclus√µes Acad√™micas",
                ],
            },
            "history_review": {
                "descricao": "an√°lise hist√≥rica e contextual",
                "estilo": "hist√≥rico e contextual",
                "foco": "evolu√ß√£o hist√≥rica e contexto cultural",
                "secoes": [
                    "Contexto Hist√≥rico",
                    "Evolu√ß√£o Temporal",
                    "An√°lise Comparativa",
                    "Li√ß√µes Hist√≥ricas",
                ],
            },
        }

        perfil_info = contexto_map.get(perfil_final, contexto_map["company_profile"])

        # Extrair key_questions, entities e objectives do LLM (se dispon√≠veis)
        key_questions = []
        entities_mentioned = []
        research_objectives = []

        if contexto_enriquecido:
            key_questions = contexto_enriquecido.get("key_questions", [])
            entities_mentioned = contexto_enriquecido.get("entities_mentioned", [])
            research_objectives = contexto_enriquecido.get("research_objectives", [])

        return {
            "setor": setor_final,
            "tipo": tipo_final,
            "perfil": perfil_final,
            "perfil_descricao": perfil_info["descricao"],
            "estilo": perfil_info["estilo"],
            "foco_detalhes": perfil_info["foco"],
            "tema_principal": setor_final.replace("_", " ").title(),
            "secoes_sugeridas": perfil_info["secoes"],
            "detec√ß√£o_confianca": confianca,
            "fonte_deteccao": fonte_deteccao,
            # CoT: key questions, entities, objectives (do LLM se dispon√≠vel)
            "key_questions": key_questions,
            "entities_mentioned": entities_mentioned,
            "research_objectives": research_objectives,
        }


# ==================== SELF-TESTS (FASES 1 E 2) ====================


def _selftest_phase1():
    """Self-test da Fase 1: valida funcionalidades b√°sicas"""
    print("=== SELF-TEST FASE 1 ===")

    ok = True

    # 1) Entity coverage soft/hard
    try:
        fases = [
            {"must_terms": ["empresa A", "Brasil"]},
            {"must_terms": ["empresa B", "Brasil"]},
            {"must_terms": ["Brasil"]},  # Sem entidades
        ]
        entities = ["empresa A", "empresa B"]

        coverage = _calc_entity_coverage(fases, entities)
        expected = 2 / 3  # 66.7%

        if abs(coverage - expected) < 0.01:
            print("‚úÖ Entity coverage calculation OK")
        else:
            print(f"‚ùå Entity coverage: esperado {expected}, got {coverage}")
            ok = False

    except Exception as e:
        print(f"‚ùå Entity coverage test falhou: {e}")
        ok = False

    # 2) News telemetry
    try:
        telemetry = {"attempted": True, "reason": "skipped_exceed_limit"}
        if telemetry["reason"] == "skipped_exceed_limit":
            print("‚úÖ News telemetry OK")
        else:
            print("‚ùå News telemetry falhou")
            ok = False
    except Exception as e:
        print(f"‚ùå News telemetry test falhou: {e}")
        ok = False

    # 3) Seed patch
    try:
        # Mock valves
        class MockValves:
            SEED_VALIDATION_STRICT = False

        valves = MockValves()
        phase = {
            "seed_query": "teste Brasil",
            "objective": "participa√ß√£o mercado empresas brasileiras",
        }
        metrics = {}

        _patch_seed_if_needed(phase, valves.SEED_VALIDATION_STRICT, metrics, logger)

        # Verificar se o patch foi aplicado
        if phase["seed_query"] != "teste Brasil":
            print("‚úÖ Seed patch OK")
        else:
            print(
                f"‚ùå Seed patch n√£o funcionou (seed_query ainda: {phase['seed_query']})"
            )
            ok = False
    except Exception as e:
        print(f"‚ùå Seed patch test falhou: {e}")
        ok = False

    # 4) Judge JSON log
    try:
        decision = {
            "decision": "done",
            "reason": "teste",
            "coverage": 0.8,
            "domains": 5,
            "evidence": 0.9,
            "staleness_ok": True,
            "loops": "2/3",
        }

        log_str = f"[JUDGE]{json.dumps(decision, ensure_ascii=False)}"
        if "[JUDGE]" in log_str and "decision" in log_str:
            print("‚úÖ Judge log JSON OK")
        else:
            print("‚ùå Judge log JSON falhou")
            ok = False
    except Exception as e:
        print(f"‚ùå Judge log JSON test falhou: {e}")
        ok = False

    print(f"=== FASE 1 SELF-TEST: {'OK' if ok else 'FAIL'} ===")
    return ok


def _selftest_phase2():
    """Self-test da Fase 2: valida funcionalidades incrementais"""
    print("=== SELF-TEST FASE 2 ===")

    ok = True

    # 1) MECE b√°sico
    try:
        fases = [{"objetivo": "volume mercado Brasil"}, {"objetivo": "perfis empresas"}]
        key_questions = [
            "Qual volume anual?",
            "Quais empresas atuam?",
            "Pergunta √≥rf√£ sem cobertura",
        ]

        uncovered = _check_mece_basic(fases, key_questions)
        expected = ["Pergunta √≥rf√£ sem cobertura"]

        if uncovered == expected:
            print("‚úÖ MECE b√°sico OK")
        else:
            print(f"‚ùå MECE b√°sico: esperado {expected}, got {uncovered}")
            ok = False
    except Exception as e:
        print(f"‚ùå MECE b√°sico test falhou: {e}")
        ok = False

    # 2) Append phase
    try:
        contract = {"fases": []}
        candidate = {
            "name": "Nova Fase",
            "phase_type": "news",
            "objective": "not√≠cias recentes",
            "seed_query": "noticias recentes Brasil",
            "seed_core": "busca noticias recentes Brasil",
            "must_terms": ["Brasil"],
            "time_hint": {"recency": "1y", "strict": True},
        }

        _append_phase(contract, candidate)

        if len(contract["fases"]) == 1 and contract["fases"][0]["name"] == "Nova Fase":
            print("‚úÖ Append phase OK")
        else:
            print("‚ùå Append phase falhou")
            ok = False
    except Exception as e:
        print(f"‚ùå Append phase test falhou: {e}")
        ok = False

    print(f"=== FASE 2 SELF-TEST: {'OK' if ok else 'FAIL'} ===")
    return ok


# ==================== ECONOMY SELF-TEST (Commit 7) ====================


def _selftest_economy():
    """Self-test para valida√ß√£o de economia e overlap detection"""
    print("=== SELF-TEST ECONOMIA ===")
    ok = True

    # Mock de valves
    class MockValves:
        PLANNER_ECONOMY_THRESHOLD = 0.75
        PLANNER_OVERLAP_THRESHOLD = 0.70
        VERBOSE_DEBUG = False

    # Test 1: Economy logging (sem overlap)
    print("Test 1: Economy logging...")
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.metrics.pairwise import cosine_similarity

        # Simular validated_phases com objectives distintos
        validated_phases = [
            {"objetivo": "Mapear panorama do mercado de executive search no Brasil"},
            {"objetivo": "Identificar tend√™ncias e drivers de crescimento do setor"},
            {
                "objetivo": "Analisar not√≠cias e eventos recentes sobre players principais"
            },
        ]

        phase_objectives = [p.get("objetivo", "") for p in validated_phases]
        actual_count = len(validated_phases)
        phases = 6
        economy_threshold = 0.75

        # Log (simulado)
        budget_pct = actual_count / phases * 100
        assert budget_pct == 50.0, f"Expected 50%, got {budget_pct}%"
        assert (
            actual_count <= phases * economy_threshold
        ), "N√£o deveria disparar warning"

        print("‚úÖ Economy logging OK")
    except Exception as e:
        print(f"‚ùå Economy logging FAIL: {e}")
        ok = False

    # Test 2: Overlap detection (detectar similaridade alta)
    print("Test 2: Overlap detection...")
    try:
        # Simular fases com overlap MUITO alto (quase id√™nticas)
        validated_phases_overlap = [
            {
                "objetivo": "Mapear receita faturamento resultados financeiros players executive search Brasil 2023"
            },
            {
                "objetivo": "Mapear receita faturamento resultados financeiros empresas executive search Brasil 2023"
            },  # Quase id√™ntica!
            {"objetivo": "Analisar not√≠cias eventos recentes mercado executive search"},
        ]

        phase_objectives = [p.get("objetivo", "") for p in validated_phases_overlap]
        overlap_threshold = 0.70

        if len(phase_objectives) >= 2:
            vectorizer = TfidfVectorizer()
            vectors = vectorizer.fit_transform(phase_objectives)
            sim_matrix = cosine_similarity(vectors)

            # Fases 0 e 1 devem ter >70% similaridade
            overlap_detected = sim_matrix[0][1] > overlap_threshold
            assert (
                overlap_detected
            ), f"Esperava overlap, mas similaridade={sim_matrix[0][1]:.2f}"

        print("‚úÖ Overlap detection OK")
    except Exception as e:
        print(f"‚ùå Overlap detection FAIL: {e}")
        ok = False

    # Test 3: Valve configurability
    print("Test 3: Valve configurability...")
    try:
        mock_valves = MockValves()
        assert mock_valves.PLANNER_ECONOMY_THRESHOLD == 0.75
        assert mock_valves.PLANNER_OVERLAP_THRESHOLD == 0.70

        # Simular threshold ajustado
        mock_valves.PLANNER_ECONOMY_THRESHOLD = 0.50
        actual_count = 4
        phases = 6
        should_warn = actual_count > phases * mock_valves.PLANNER_ECONOMY_THRESHOLD
        assert should_warn, f"Deveria disparar warning com threshold 50% (4/6 = 66%)"

        print("‚úÖ Valve configurability OK")
    except Exception as e:
        print(f"‚ùå Valve configurability FAIL: {e}")
        ok = False

    # Test 4: Layer 2 - Campos opcionais (infer√™ncia)
    print("Test 4: Layer 2 - Campos opcionais (infer√™ncia)...")
    try:
        # Simular obj sem total_phases_used
        obj_no_counter = {"phases": [{"objetivo": "A"}, {"objetivo": "B"}]}
        actual_count = len(obj_no_counter.get("phases", []))
        declared_count = obj_no_counter.get("total_phases_used", actual_count)

        assert (
            declared_count == actual_count
        ), f"Infer√™ncia falhou: declared={declared_count}, actual={actual_count}"
        assert declared_count == 2, "Esperava 2 fases"

        print("‚úÖ Layer 2 - Campos opcionais OK")
    except Exception as e:
        print(f"‚ùå Layer 2 - Campos opcionais FAIL: {e}")
        ok = False

    # Test 5: Layer 2 - Valida√ß√£o de consist√™ncia (declared != actual)
    print("Test 5: Layer 2 - Valida√ß√£o de consist√™ncia...")
    try:
        # Simular obj COM total_phases_used inconsistente
        obj_inconsistent = {
            "total_phases_used": 5,  # Declara 5
            "phases": [{"objetivo": "A"}, {"objetivo": "B"}],  # Mas cria 2
        }
        actual_count = len(obj_inconsistent.get("phases", []))
        declared_count = obj_inconsistent.get("total_phases_used", actual_count)

        # Deveria detectar inconsist√™ncia
        is_inconsistent = (
            "total_phases_used" in obj_inconsistent and declared_count != actual_count
        )
        assert is_inconsistent, "N√£o detectou inconsist√™ncia declared(5) != actual(2)"

        print("‚úÖ Layer 2 - Valida√ß√£o de consist√™ncia OK")
    except Exception as e:
        print(f"‚ùå Layer 2 - Valida√ß√£o de consist√™ncia FAIL: {e}")
        ok = False

    # Test 6: Layer 2 - Warning se ‚â•80% budget sem justificativa
    print("Test 6: Layer 2 - Warning ‚â•80% budget sem justificativa...")
    try:
        obj_high_budget = {
            "phases": [{"objetivo": f"Fase {i}"} for i in range(5)],  # 5 fases
            "phases_justification": "Plano gen√©rico",  # SEM keywords de economia
        }
        actual_count = len(obj_high_budget["phases"])
        phases = 6

        # 5/6 = 83% (‚â•80%)
        is_high_budget = actual_count >= int(0.8 * phases)
        justification = obj_high_budget.get("phases_justification", "").lower()
        economy_keywords = [
            "economia",
            "combinar",
            "comparativa",
            "suficiente",
            "necess√°rio",
            "econ√¥mico",
        ]
        has_economy_mention = any(kw in justification for kw in economy_keywords)

        # Deve disparar warning (‚â•80% mas sem keywords)
        should_warn = is_high_budget and not has_economy_mention
        assert (
            should_warn
        ), "N√£o disparou warning para 83% budget sem keywords de economia"

        print("‚úÖ Layer 2 - Warning ‚â•80% budget OK")
    except Exception as e:
        print(f"‚ùå Layer 2 - Warning ‚â•80% budget FAIL: {e}")
        ok = False

    # Test 7: Layer 2 - Overlap warnings armazenados no contract
    print("Test 7: Layer 2 - Overlap warnings no contract...")
    try:
        # Simular detec√ß√£o de overlap e armazenamento
        contract_dict = {}
        overlap_info = {
            "phase_i": 1,
            "phase_j": 2,
            "similarity": 0.85,
            "objective_i": "Receita empresas executive search Brasil 2023",
            "objective_j": "Faturamento empresas executive search Brasil 2023",
        }

        # Simular armazenamento
        overlaps_found = [overlap_info]
        if overlaps_found:
            contract_dict["_overlap_warnings"] = overlaps_found

        # Validar
        assert "_overlap_warnings" in contract_dict, "Overlap warnings n√£o armazenadas"
        assert len(contract_dict["_overlap_warnings"]) == 1, "Esperava 1 overlap"
        assert (
            contract_dict["_overlap_warnings"][0]["similarity"] == 0.85
        ), "Similaridade incorreta"

        print("‚úÖ Layer 2 - Overlap warnings no contract OK")
    except Exception as e:
        print(f"‚ùå Layer 2 - Overlap warnings FAIL: {e}")
        ok = False

    print(f"=== ECONOMIA SELF-TEST: {'OK' if ok else 'FAIL'} ===")
    return ok


# ==================== MAIN SELF-TEST ====================


def run_self_tests():
    """Executa todos os self-tests"""
    print("üöÄ EXECUTANDO SELF-TESTS DO PIPEMANUAL")
    print("=" * 50)

    results = []
    results.append(("FASE 1", _selftest_phase1()))
    results.append(("FASE 2", _selftest_phase2()))
    results.append(("ECONOMIA", _selftest_economy()))

    print("=" * 50)
    all_ok = all(result[1] for result in results)

    print(f"üèÅ SELF-TESTS: {'TODOS OK' if all_ok else 'ALGUNS FALHARAM'}")

    for name, result in results:
        status = "‚úÖ OK" if result else "‚ùå FAIL"
        print(f"  {name}: {status}")

    return all_ok


# ===== LINE-BUDGET GUARD EXECUTION =====
# Executar valida√ß√£o de tamanho de fun√ß√µes cr√≠ticas
try:
    _warn_if_too_long(Orchestrator.run_iteration)
    _warn_if_too_long(Pipe.pipe)
    _warn_if_too_long(Pipe._synthesize_final)
    _warn_if_too_long(_build_planner_prompt)
    _warn_if_too_long(_build_analyst_prompt)
    _warn_if_too_long(_build_judge_prompt)
except Exception as e:
    logger.debug(f"Line-budget guard execution failed: {e}")

# ===== OpenWebUI Pipe Export =====
# The Pipe class above is automatically discovered by OpenWebUI
# No get_tools() function needed for Manifold pipes
