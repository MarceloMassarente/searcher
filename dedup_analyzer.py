#!/usr/bin/env python3
"""
üîç Ferramenta de An√°lise de Deduplica√ß√£o

Analisa fragmenta√ß√£o de par√°grafos e ajuda diagnosticar problemas.
"""

def analyze_fragmentation(
    total_chars: int,
    num_paragraphs: int,
    max_target_paragraphs: int,
    individual_sizes: list = None
) -> dict:
    """
    Analisa se a fragmenta√ß√£o √© apropriada
    
    Args:
        total_chars: total de caracteres originais
        num_paragraphs: n√∫mero de par√°grafos extra√≠do
        max_target_paragraphs: target ap√≥s deduplica√ß√£o
        individual_sizes: lista com tamanho de cada par√°grafo (opcional)
    
    Returns:
        dict com diagn√≥stico
    """
    
    avg_size = total_chars / num_paragraphs if num_paragraphs > 0 else 0
    reduction_factor = num_paragraphs / max_target_paragraphs if max_target_paragraphs > 0 else 0
    final_avg_size = total_chars / max_target_paragraphs if max_target_paragraphs > 0 else 0
    
    # Calcular percentis se temos dados individuais
    stats = {
        "total_chars": total_chars,
        "num_paragraphs": num_paragraphs,
        "target_paragraphs": max_target_paragraphs,
        "avg_size": avg_size,
        "reduction_factor": reduction_factor,
        "final_avg_size": final_avg_size,
    }
    
    if individual_sizes:
        sorted_sizes = sorted(individual_sizes)
        n = len(sorted_sizes)
        stats.update({
            "min_size": sorted_sizes[0],
            "max_size": sorted_sizes[-1],
            "median_size": sorted_sizes[n // 2],
            "p25": sorted_sizes[int(n * 0.25)],
            "p75": sorted_sizes[int(n * 0.75)],
            "p95": sorted_sizes[int(n * 0.95)],
        })
    
    # Avalia√ß√£o
    health = "‚úÖ OK"
    warnings = []
    
    # Verifica√ß√µes
    if avg_size < 100:
        health = "‚ö†Ô∏è AVISO"
        warnings.append(f"Par√°grafos muito pequenos ({avg_size:.0f} chars avg)")
    
    if avg_size > 2000:
        health = "‚ö†Ô∏è AVISO"
        warnings.append(f"Par√°grafos gigantes ({avg_size:.0f} chars avg)")
    
    if reduction_factor > 40:
        health = "üî¥ CR√çTICO"
        warnings.append(f"Redu√ß√£o extremamente agressiva ({reduction_factor:.1f}x)")
    elif reduction_factor > 20:
        health = "‚ö†Ô∏è AVISO"
        warnings.append(f"Redu√ß√£o muito agressiva ({reduction_factor:.1f}x)")
    
    if final_avg_size < 50:
        health = "üî¥ CR√çTICO"
        warnings.append(f"Resultado final ser√° fragmentado ({final_avg_size:.0f} chars/par√°grafo)")
    elif final_avg_size < 100:
        health = "‚ö†Ô∏è AVISO"
        warnings.append(f"Resultado final pode ser fragmentado ({final_avg_size:.0f} chars/par√°grafo)")
    
    stats["health"] = health
    stats["warnings"] = warnings
    
    return stats


def print_analysis(stats: dict):
    """Imprime an√°lise formatada"""
    print("\n" + "="*60)
    print("üîç AN√ÅLISE DE FRAGMENTA√á√ÉO DE DEDUPLICA√á√ÉO")
    print("="*60 + "\n")
    
    # Status geral
    print(f"{stats['health']} Status: {len(stats.get('warnings', []))} aviso(s)")
    print()
    
    # N√∫meros principais
    print("üìä N√öMEROS PRINCIPAIS:")
    print(f"  ‚Ä¢ Total de caracteres:   {stats['total_chars']:,} chars")
    print(f"  ‚Ä¢ Par√°grafos extra√≠dos:  {stats['num_paragraphs']:,}")
    print(f"  ‚Ä¢ Target ap√≥s dedup:     {stats['target_paragraphs']:,}")
    print(f"  ‚Ä¢ Fator redu√ß√£o:         {stats['reduction_factor']:.1f}x")
    print()
    
    # Tamanhos
    print("üìê TAMANHO DE PAR√ÅGRAFOS:")
    print(f"  ‚Ä¢ M√©dia:                 {stats['avg_size']:.0f} chars")
    if 'median_size' in stats:
        print(f"  ‚Ä¢ Mediana:               {stats['median_size']:.0f} chars")
        print(f"  ‚Ä¢ Min/Max:               {stats['min_size']:.0f} / {stats['max_size']:.0f} chars")
        print(f"  ‚Ä¢ P25/P75:               {stats['p25']:.0f} / {stats['p75']:.0f} chars")
        print(f"  ‚Ä¢ P95:                   {stats['p95']:.0f} chars")
    print()
    
    # Resultado esperado
    print("üìà RESULTADO ESPERADO:")
    print(f"  ‚Ä¢ Tamanho m√©dio final:   {stats['final_avg_size']:.0f} chars/par√°grafo")
    print()
    
    # Avisos
    if stats['warnings']:
        print("‚ö†Ô∏è  AVISOS:")
        for i, warning in enumerate(stats['warnings'], 1):
            print(f"  {i}. {warning}")
        print()
    
    # Recomenda√ß√µes
    print("üí° RECOMENDA√á√ïES:")
    
    if stats['reduction_factor'] > 40:
        print("  1. ‚¨ÜÔ∏è  Aumentar MAX_DEDUP_PARAGRAPHS (atualmente agressivo demais)")
        suggested_target = int(stats['num_paragraphs'] / 20)  # Redu√ß√£o 20x em vez de 40x+
        print(f"     ‚Üí Sugest√£o: {suggested_target} em vez de {stats['target_paragraphs']}")
        print()
    
    if stats['avg_size'] > 1500:
        print("  2. üîç Split detectou markdown com \\n √∫nico (densidade baixa)")
        print("     ‚Üí Aumentar threshold: avg_paragraph_size > 2000 (era 1000)")
        print()
    
    if stats['final_avg_size'] < 100:
        print("  3. üîó Combinar par√°grafos pequenos p√≥s-dedup")
        print("     ‚Üí Implementar merge para min 100-150 chars/par√°grafo")
        print()
    
    if stats.get('p95', 0) > 3000:
        print("  4. üìè Ajustar DEDUP_MAX_PARAGRAPH_CHARS (par√°grafos muito grandes)")
        print("     ‚Üí P95 = {:.0f} chars, considere quebrar em {:.0f}")
        print()
    
    print("="*60 + "\n")


# ============================================================================
# EXEMPLOS
# ============================================================================

if __name__ == "__main__":
    print("üìã EXEMPLOS DE AN√ÅLISE\n")
    
    # Cen√°rio 1: Os n√∫meros dos logs atuais
    print("\n[CEN√ÅRIO 1] N√∫meros atuais dos logs:")
    print("Input: 11.433 chars ‚Üí 9.299 par√°grafos ‚Üí 200 final")
    
    stats1 = analyze_fragmentation(
        total_chars=11433,
        num_paragraphs=9299,
        max_target_paragraphs=200,
        individual_sizes=None
    )
    print_analysis(stats1)
    
    # Cen√°rio 2: Simula√ß√£o com dados individuais (distribui√ß√£o normal)
    print("\n[CEN√ÅRIO 2] Simula√ß√£o com distribui√ß√£o normal de tamanhos:")
    import random
    random.seed(42)
    simulated_sizes = [random.gauss(150, 50) for _ in range(1000)]
    simulated_sizes = [max(50, int(s)) for s in simulated_sizes]
    simulated_total = sum(simulated_sizes)
    
    stats2 = analyze_fragmentation(
        total_chars=simulated_total,
        num_paragraphs=len(simulated_sizes),
        max_target_paragraphs=200,
        individual_sizes=simulated_sizes
    )
    print_analysis(stats2)
    
    # Cen√°rio 3: Configura√ß√£o recomendada
    print("\n[CEN√ÅRIO 3] Configura√ß√£o melhor (target 500 em vez de 200):")
    stats3 = analyze_fragmentation(
        total_chars=11433,
        num_paragraphs=9299,
        max_target_paragraphs=500,
        individual_sizes=None
    )
    print_analysis(stats3)
    
    # Cen√°rio 4: Se split fosse melhor (menos par√°grafos iniciais)
    print("\n[CEN√ÅRIO 4] Se split fosse melhor (2.000 par√°grafos em vez de 9.299):")
    stats4 = analyze_fragmentation(
        total_chars=11433,
        num_paragraphs=2000,
        max_target_paragraphs=200,
        individual_sizes=None
    )
    print_analysis(stats4)
